import streamlit as st


sayfa_seÃ§enekleri = [
    "Ana Sayfa",
    "KeÅŸifsel Veri Analizi",
    "Z Testi",
    "T Testi",
    "Basit DoÄŸrusal Regresyon",
    "Ã‡oklu DoÄŸrusal Regresyon",
    "Fisher's Exact Testi",
    "Ki-Kare Testi",
    "Kruskal-Wallis Testi",
    "Wilcoxon Ä°ÅŸaretli SÄ±ralar Testi",
    "CART (Classification and Regression Trees)",
    "CatBoost",
    "Gaussian Naive Bayes",
    "Gradient Boosting Machines",
    "K-En YakÄ±n KomÅŸu (KNN)",
    "LightGBM",
    "Lojistik Regresyon",
    "Mann-Whitney U Testi",
    "Random Forest",
    "RBF SVM (Radial Basis Function Support Vector Machine)",
    "SVC (Support Vector Classification)",
    "XGBoost",
    "Yapay Sinir AÄŸlarÄ±"
]


page = st.sidebar.selectbox("Sayfa SeÃ§in", sayfa_seÃ§enekleri)


if page == "Ana Sayfa":
    st.title("Veri Analizi ve Makine Ã–ÄŸrenimi DÃ¼nyasÄ±na AdÄ±m AtÄ±n ğŸ“ˆ")
    
    st.subheader("HoÅŸ Geldiniz! ğŸŒŸ")
    st.write("""
             
Bu platform, veri analizi ve makine Ã¶ÄŸrenimi konularÄ±na yeni baÅŸlayanlar iÃ§in tasarlanmÄ±ÅŸtÄ±r. Burada, veri odaklÄ± kararlar almanÄ±za yardÄ±mcÄ± olacak temel araÃ§larÄ± ve teknikleri Ã¶ÄŸrenme fÄ±rsatÄ± bulacaksÄ±nÄ±z.
BaÅŸlangÄ±Ã§ seviyesindeki kullanÄ±cÄ±lar iÃ§in hazÄ±rlanmÄ±ÅŸ olan bu platform, Veri Ã¶n iÅŸleme adÄ±mlarÄ± yapÄ±lmÄ±ÅŸ veya basit veri setleri Ã¼zerinde yapÄ±lan iÅŸlemleri kapsar. 
             
             """)
    st.write(""" 
             Temel istatistik teknikleri, Hipotez testleri ve veri analizi yÃ¶ntemlerini keÅŸfedeceksiniz. Platformumuzda, her bir program ve algoritmanÄ±n kÄ±sa aÃ§Ä±klamalarÄ±nÄ± iÃ§eren bir liste bulunmaktadÄ±r. Bu liste, sizin iÃ§in uygun olan teknikleri belirlemenize ve keÅŸif yolculuÄŸunuzu daha verimli hale getirmenize yardÄ±mcÄ± olabilir.

HazÄ±r mÄ±sÄ±nÄ±z?ğŸ”¥ Ã–yleyse, veri analizi ve makine Ã¶ÄŸrenimi dÃ¼nyasÄ±na adÄ±m atÄ±n ve verilerinizin derinliklerine inmeye baÅŸlayÄ±n!
             
             """)
    st.write("Platformda bulunan yÃ¶ntemler hakkÄ±nda kÄ±sa bilgilere bir gÃ¶z atalÄ±m ğŸ§")
    
    st.text(" ")

    st.text("""
    Makine Ã–ÄŸrenmesi
    Test Train AyrÄ±mÄ±
    KeÅŸifsel Veri Analizi
    Basit DoÄŸrusal Regresyon
    Ã‡oklu DoÄŸrusal Regresyon
    Fisher's Exact
    Ki-Kare Testi
    Kruskal Wallis Testi
    Spearman Korelasyon KatsayÄ±sÄ±
    Pearson Korelasyon KatsayÄ±sÄ±
    T Testi
    Wilcoxon Ä°ÅŸaretli SÄ±ralar Testi
    Z Testi
    CART 
    Catboost
    Gaussian Naive Bayes
    Gradient Boosting Machine
    KNN 
    LightGBM
    Lojistik Regresyon
    Mann Whitney U Testi
    Random Forest
    RBF SVC
    SVC 
    XGBoost
    Yapay Sinir AÄŸlarÄ±

            
        
            
            """)

    headings_and_descriptions = {
        "makine Ã¶ÄŸrenmesi":"""
        Makine Ã¶ÄŸrenmesi, bilgisayar sistemlerinin veriye dayalÄ± olarak deneyimlerden Ã¶ÄŸrenmesini ve bu deneyimlerden yararlanarak belirli gÃ¶revleri gerÃ§ekleÅŸtirmesini saÄŸlayan bir yapay zeka dalÄ±dÄ±r. Bu algoritmalara, belirli bir gÃ¶revi gerÃ§ekleÅŸtirmek iÃ§in veri saÄŸlandÄ±ÄŸÄ±nda, bu veriyi analiz ederek desenleri ve iliÅŸkileri belirleme yeteneÄŸi verilir. Bu desenler ve iliÅŸkiler, gelecekteki benzer gÃ¶revleri gerÃ§ekleÅŸtirmek iÃ§in kullanÄ±labilir.

    Makine Ã¶ÄŸrenimi genellikle denetimli, denetimsiz ve pekiÅŸtirmeli Ã¶ÄŸrenme olmak Ã¼zere Ã¼Ã§ ana kategoriye ayrÄ±lÄ±r:

    1. Denetimli Ã–ÄŸrenme: Bu yaklaÅŸÄ±mda, algoritma eÄŸitim verileriyle beslenir, her bir veri noktasÄ±nÄ±n istenen Ã§Ä±ktÄ±sÄ± da (etiket) saÄŸlanÄ±r. Algoritma, giriÅŸler ile Ã§Ä±ktÄ±lar arasÄ±ndaki iliÅŸkiyi Ã¶ÄŸrenir ve yeni giriÅŸler iÃ§in doÄŸru Ã§Ä±ktÄ±larÄ± tahmin edebilir. Ã–rnekler arasÄ±nda sÄ±nÄ±flandÄ±rma ve regresyon problemleri bulunur.

    2. Denetimsiz Ã–ÄŸrenme: Bu tÃ¼rde, algoritma etiketlenmemiÅŸ verilerle eÄŸitilir, yani giriÅŸlerin etiketleri yoktur. Algoritma, veri iÃ§indeki desenleri ve iliÅŸkileri kendi baÅŸÄ±na keÅŸfetmeye Ã§alÄ±ÅŸÄ±r. Ã–rnekler arasÄ±nda kÃ¼meleme ve boyut azaltma bulunur.

    3. PekiÅŸtirmeli Ã–ÄŸrenme: Bu yaklaÅŸÄ±mda, algoritma bir ortamla etkileÅŸime girer ve belirli bir gÃ¶revi en iyi ÅŸekilde gerÃ§ekleÅŸtirmek iÃ§in Ã§eÅŸitli adÄ±mlar atar. Algoritma, yaptÄ±ÄŸÄ± adÄ±mlarÄ±n sonuÃ§larÄ±na gÃ¶re bir Ã¶dÃ¼l veya ceza alÄ±r ve bu geri bildirimleri kullanarak en iyi eylem stratejilerini Ã¶ÄŸrenir. Ã–rnekler arasÄ±nda oyun teorisi ve robotik kontrol bulunur.

    Makine Ã¶ÄŸrenimi, birÃ§ok farklÄ± alanÄ± etkilemiÅŸtir ve otomatik gÃ¶rÃ¼ntÃ¼ tanÄ±ma, doÄŸal dil iÅŸleme, tÄ±bbi teÅŸhis, finansal tahminler ve daha birÃ§ok alanda kullanÄ±lmaktadÄ±r.""",
        "test train ayrÄ±mÄ±":"""
        Test-train ayrÄ±mÄ±, makine Ã¶ÄŸrenimi ve istatistiksel modelleme sÃ¼reÃ§lerinde yaygÄ±n olarak kullanÄ±lan bir kavramdÄ±r. Bu kavram, bir modelin eÄŸitilmesi ve performansÄ±nÄ±n deÄŸerlendirilmesi iÃ§in veri setinin bÃ¶lÃ¼nmesini ifade eder.

    Genellikle veri seti iki ana bÃ¶lÃ¼me ayrÄ±lÄ±r:

    1. EÄŸitim Seti (Train Set): Modelin eÄŸitilmesi iÃ§in kullanÄ±lan veri setidir. Bu veri seti, modelin giriÅŸ-veri iliÅŸkilerini Ã¶ÄŸrenmesi iÃ§in kullanÄ±lÄ±r. Model, eÄŸitim veri setindeki Ã¶rneklerden desenler ve iliÅŸkiler Ã§Ä±kararak belirli bir gÃ¶revi gerÃ§ekleÅŸtirebilecek ÅŸekilde ayarlanÄ±r.

    2. Test Seti (Test Set): Modelin performansÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±lan baÄŸÄ±msÄ±z bir veri setidir. Model eÄŸitildikten sonra, test veri setindeki Ã¶rnekleri kullanarak modelin doÄŸruluÄŸunu, hassasiyetini ve genel performansÄ±nÄ± deÄŸerlendiririz. Bu, modelin eÄŸitim sÄ±rasÄ±nda gÃ¶rmediÄŸi veriler Ã¼zerinde nasÄ±l performans gÃ¶sterdiÄŸini belirlemek iÃ§in yapÄ±lÄ±r. 

    Test-train ayrÄ±mÄ±, modelin gerÃ§ek dÃ¼nya verileri Ã¼zerinde ne kadar iyi performans gÃ¶sterebileceÄŸini daha gÃ¼venilir bir ÅŸekilde Ã¶lÃ§mek iÃ§in kullanÄ±lÄ±r. AyrÄ±ca, aÅŸÄ±rÄ± uyum (overfitting) gibi problemlerin tespit edilmesine ve dÃ¼zeltilmesine yardÄ±mcÄ± olur. Bu yaklaÅŸÄ±m, modelin genelleme yeteneÄŸini test etmek iÃ§in Ã¶nemlidir; yani, eÄŸitim veri setinden Ã¶ÄŸrendiÄŸi desenleri, yeni ve gÃ¶rÃ¼lmemiÅŸ veri setlerine genellemesini saÄŸlamak iÃ§in kullanÄ±lÄ±r.
        """,
        
        "keÅŸifsel veri analizi": """KeÅŸifsel veri analizi (EDA), veri bilimi ve istatistikte, bir veri setinin doÄŸasÄ±nÄ± ve yapÄ±sÄ±nÄ± anlamak iÃ§in kullanÄ±lan bir sÃ¼reÃ§tir. EDA, veri setindeki desenleri, iliÅŸkileri, anormallikleri ve potansiyel sorunlarÄ± keÅŸfetmek iÃ§in Ã§eÅŸitli gÃ¶rselleÅŸtirme ve istatistiksel teknikler kullanÄ±r.

    EDA'nÄ±n temel amaÃ§larÄ± ÅŸunlardÄ±r:

    1. **Veri setinin YapÄ±sÄ±nÄ± Anlama**: Veri setindeki deÄŸiÅŸkenlerin tÃ¼rÃ¼nÃ¼, daÄŸÄ±lÄ±mÄ±nÄ± ve iliÅŸkilerini anlamak iÃ§in yapÄ±sal Ã¶zelliklerini incelemek.

    2. **Desenleri ve Ä°liÅŸkileri Belirleme**: Veri setindeki desenleri, iliÅŸkileri ve trendleri belirlemek iÃ§in grafikler, tablolar ve istatistiksel metotlar kullanarak veriye gÃ¶z atmaktÄ±r.

    3. **Anormallikleri ve SorunlarÄ± Tespit Etme**: Veri setindeki eksik deÄŸerler, aykÄ±rÄ± deÄŸerler, yanlÄ±ÅŸ veri giriÅŸleri gibi sorunlarÄ± belirlemek ve bunlarÄ± Ã§Ã¶zmek iÃ§in stratejiler geliÅŸtirmek.

    4. **VarsayÄ±mlarÄ± Test Etme**: Ä°leri analiz ve modelleme iÃ§in varsayÄ±mlarÄ±n geÃ§erliliÄŸini kontrol etmek.

    5. **Modelleme Stratejileri GeliÅŸtirme**: Veri setindeki desenleri ve iliÅŸkileri anlayarak, daha sonraki analizler veya modelleme iÅŸlemleri iÃ§in uygun stratejiler geliÅŸtirmek.

    EDA, veri bilimcilerin ve analistlerin veri setlerini anlamalarÄ±na, modelleme sÃ¼recine hazÄ±rlanmalarÄ±na ve doÄŸru analiz yÃ¶ntemlerini seÃ§melerine yardÄ±mcÄ± olur. Bu nedenle, veri analizi sÃ¼recinin Ã¶nemli bir adÄ±mÄ±dÄ±r ve veri tabanlÄ± karar alma sÃ¼recinde kritik bir rol oynar.
        
        
        """,
        "basit doÄŸrusal regresyon": """
        Basit doÄŸrusal regresyon, istatistik ve makine Ã¶ÄŸrenimi alanlarÄ±nda kullanÄ±lan temel bir regresyon analizi yÃ¶ntemidir. Bu yÃ¶ntem, baÄŸÄ±mlÄ± deÄŸiÅŸken ile bir tane baÄŸÄ±msÄ±z deÄŸiÅŸken arasÄ±ndaki iliÅŸkiyi modellemek iÃ§in kullanÄ±lÄ±r.

    Basit doÄŸrusal regresyon modeli, genellikle ÅŸu formÃ¼l ile ifade edilir:

    y= Î²0 + Î²1X + Ïµ

    Burada:

    - Y: BaÄŸÄ±mlÄ± deÄŸiÅŸkeni temsil eder.
    - X: BaÄŸÄ±msÄ±z deÄŸiÅŸkeni temsil eder.
    - Î²0: DoÄŸrunun y-eksenini kestiÄŸi yer ve regresyon sabitidir.
    - Î²1: DoÄŸrunun eÄŸimi veya regresyon katsayÄ±sÄ±dÄ±r.
    - Ïµ: hata terimini ifade eder.

    Basit doÄŸrusal regresyon, baÄŸÄ±mlÄ± deÄŸiÅŸkenin ve baÄŸÄ±msÄ±z deÄŸiÅŸkenin doÄŸrusal bir iliÅŸki iÃ§inde olduÄŸu durumlar iÃ§in uygundur. Ã–rneÄŸin, bir kiÅŸinin boyu (baÄŸÄ±mlÄ± deÄŸiÅŸken) ile kilosu (baÄŸÄ±msÄ±z deÄŸiÅŸken) arasÄ±ndaki iliÅŸkiyi modellemek iÃ§in kullanÄ±labilir.

    Model eÄŸitilirken, regresyon katsayÄ±larÄ± Î²0 ve Î²1 genellikle en kÃ¼Ã§Ã¼k kareler yÃ¶ntemiyle tahmin edilir. Bu, hatanÄ±n karelerinin toplamÄ±nÄ± (residual sum of squares) minimize eden katsayÄ±larÄ±n bulunmasÄ± anlamÄ±na gelir.

    Basit doÄŸrusal regresyon analizi, modelin uygunluÄŸunu deÄŸerlendirmek iÃ§in Ã§eÅŸitli istatistiksel metrikler kullanÄ±r. Bu metrikler arasÄ±nda R-kare (R-squared), ortalamadan sapma karelerinin (mean squared error) karekÃ¶kÃ¼ ve diÄŸerleri bulunur. Bu metrikler, modelin ne kadar iyi uyum saÄŸladÄ±ÄŸÄ±nÄ± ve baÄŸÄ±msÄ±z deÄŸiÅŸkenin baÄŸÄ±mlÄ± deÄŸiÅŸkendeki deÄŸiÅŸikliÄŸi ne kadar iyi aÃ§Ä±kladÄ±ÄŸÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±lÄ±r.
        
        
        """,
        "Ã§oklu doÄŸrusal regresyon": """
        Ã‡oklu doÄŸrusal regresyon, bir baÄŸÄ±mlÄ± deÄŸiÅŸken ile birden fazla baÄŸÄ±msÄ±z deÄŸiÅŸken arasÄ±ndaki iliÅŸkiyi modellemek iÃ§in kullanÄ±lan bir regresyon analizi yÃ¶ntemidir. Basit doÄŸrusal regresyon ile benzer bir prensibe sahiptir, ancak birden fazla baÄŸÄ±msÄ±z deÄŸiÅŸkeni iÃ§erir.

    Genel olarak, Ã§oklu doÄŸrusal regresyon modeli aÅŸaÄŸÄ±daki ÅŸekilde ifade edilir:

    Yi = Î²0 + Î²1X1 + Î²2X2 + â€¦â€¦+ Î²nXn  + â‚¬i 

    Burada:

    - Y: BaÄŸÄ±mlÄ± deÄŸiÅŸkeni temsil eder.
    - X1,X2,,Xn: Modeldeki baÄŸÄ±msÄ±z deÄŸiÅŸkenleri temsil eder.
    - Î²0,Î²1,Î²2,,Î²n: regresyon katsayÄ±larÄ±nÄ± temsil eder. Î²0 sabit terimi (intercept), Î²1,Î²2,,Î²n ise her bir baÄŸÄ±msÄ±z deÄŸiÅŸkenin eÄŸimini (slope) ifade eder.
    - â‚¬: Hata terimini ifade eder.

    Ã‡oklu doÄŸrusal regresyon, baÄŸÄ±mlÄ± deÄŸiÅŸken ile birden fazla baÄŸÄ±msÄ±z deÄŸiÅŸken arasÄ±ndaki iliÅŸkiyi aÃ§Ä±klamak ve tahmin etmek iÃ§in kullanÄ±lÄ±r. Ã–rneÄŸin, bir aracÄ±n fiyatÄ±nÄ± (baÄŸÄ±mlÄ± deÄŸiÅŸken) belirleyen faktÃ¶rleri incelemek istediÄŸimizi dÃ¼ÅŸÃ¼nelim. Bu durumda aracÄ±n yaÅŸÄ±nÄ±, kilometre durumunu, motor gÃ¼cÃ¼nÃ¼, yakÄ±t tÃ¼ketimini ve diÄŸer Ã¶zelliklerini baÄŸÄ±msÄ±z deÄŸiÅŸkenler olarak kullanarak fiyatÄ± tahmin etmeye Ã§alÄ±ÅŸabiliriz.

    Ã‡oklu doÄŸrusal regresyon analizi, her bir baÄŸÄ±msÄ±z deÄŸiÅŸkenin baÄŸÄ±mlÄ± deÄŸiÅŸkendeki varyansÄ± aÃ§Ä±klamadaki katkÄ±sÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±lÄ±r. AyrÄ±ca, modelin uygunluÄŸunu deÄŸerlendirmek ve istatistiksel olarak anlamlÄ± deÄŸiÅŸkenleri belirlemek iÃ§in Ã§eÅŸitli istatistiksel testler kullanÄ±lÄ±r.
        
        """,
        
        "fisher's exact": """
        Fisher'Ä±n kesin testi (Fisher's exact test), kÃ¼Ã§Ã¼k Ã¶rneklemler veya dÃ¼ÅŸÃ¼k hÃ¼cre sayÄ±sÄ± durumlarÄ±nda kullanÄ±lan bir istatistiksel testtir. Ã–zellikle 2x2 veya daha kÃ¼Ã§Ã¼k tablolarda gÃ¶zlenen frekanslar arasÄ±ndaki iliÅŸkiyi test etmek iÃ§in yaygÄ±n olarak kullanÄ±lÄ±r.

    Fisher'Ä±n kesin testi, birÃ§ok diÄŸer istatistiksel testten farklÄ± olarak, varsayÄ±mlara dayanmaz. Bu nedenle, Ã¶rneklemin bÃ¼yÃ¼klÃ¼ÄŸÃ¼nden baÄŸÄ±msÄ±z olarak gÃ¼venilir sonuÃ§lar Ã¼retebilir. Ã–zellikle kÃ¼Ã§Ã¼k Ã¶rneklemler veya nadir olaylarÄ±n incelendiÄŸi durumlarda tercih edilir.

    Fisher'Ä±n kesin testi genellikle kategorik verilerin analizi iÃ§in kullanÄ±lÄ±r. Ã–rneÄŸin, bir tedavi ve kontrol grubu arasÄ±ndaki baÅŸarÄ± oranlarÄ±, hastalÄ±k varlÄ±ÄŸÄ± ve yokluÄŸu ile belirli bir genin iliÅŸkisi gibi durumlarda kullanÄ±labilir.

    Fisher'Ä±n kesin testinin temel amacÄ±, iki kategorik deÄŸiÅŸken arasÄ±ndaki iliÅŸkiyi test etmektir. Testin null hipotezi, iki deÄŸiÅŸken arasÄ±nda bir iliÅŸkinin olmadÄ±ÄŸÄ±nÄ± ifade eder. Alternatif hipotez ise, iki deÄŸiÅŸken arasÄ±nda bir iliÅŸki olduÄŸunu Ã¶ne sÃ¼rer.

    Fisher'Ä±n kesin testi, Ã¶rneklem verilerini kullanarak bir p-deÄŸeri hesaplar. Bu p-deÄŸeri, null hipotezin reddedilmesi iÃ§in saÄŸlanan kanÄ±ttÄ±r. EÄŸer p-deÄŸeri belirli bir alfa dÃ¼zeyinden (genellikle 0.05 veya 0.01) daha kÃ¼Ã§Ã¼kse, null hipotez reddedilir ve iki deÄŸiÅŸken arasÄ±nda anlamlÄ± bir iliÅŸki olduÄŸu sonucuna varÄ±lÄ±r.
        """,
        
        "ki-kare testi": """
        Ki-kare testi, iki kategorik deÄŸiÅŸken arasÄ±ndaki iliÅŸkinin anlamlÄ±lÄ±ÄŸÄ±nÄ± test etmek iÃ§in kullanÄ±lan bir istatistiksel testtir. Bu test, gÃ¶zlenen ve beklenen frekanslar arasÄ±ndaki farklÄ±lÄ±klarÄ± deÄŸerlendirerek deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkiyi belirler.

    Ki-kare testi, Ã¶zellikle nominal Ã¶lÃ§ek dÃ¼zeyindeki verilerin analizi iÃ§in uygundur. Ã–rneÄŸin, iki kategorik deÄŸiÅŸken arasÄ±ndaki iliÅŸkiyi test etmek iÃ§in kullanÄ±labilir, Ã¶rneÄŸin, sigara iÃ§me alÄ±ÅŸkanlÄ±ÄŸÄ± ile cinsiyet arasÄ±ndaki iliÅŸkiyi belirlemek gibi.

    Ki-kare testinin temel adÄ±mlarÄ± ÅŸunlardÄ±r:

    1. **GÃ¶zlenen FrekanslarÄ±n Belirlenmesi**: Ä°lk olarak, analiz edilen veri setindeki gÃ¶zlenen frekanslar belirlenir. Bu, her bir kategorinin kaÃ§ kez gÃ¶zlemlendiÄŸinin sayÄ±lmasÄ± anlamÄ±na gelir.

    2. **Beklenen FrekanslarÄ±n HesaplanmasÄ±**: Ä°kinci adÄ±mda, baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin birbirine baÄŸlÄ± olmamasÄ± durumunda beklenen frekanslar hesaplanÄ±r. Bu, toplam Ã¶rnek sayÄ±sÄ±nÄ±n ve her bir kategorinin marjinal daÄŸÄ±lÄ±mÄ±nÄ±n kullanÄ±lmasÄ±yla yapÄ±lÄ±r.

    3. **Ki-kare Ä°statistiÄŸinin HesaplanmasÄ±**: GÃ¶zlenen ve beklenen frekanslar arasÄ±ndaki farklarÄ± Ã¶lÃ§mek iÃ§in ki-kare istatistiÄŸi hesaplanÄ±r. Bu, gÃ¶zlenen frekanslar ile beklenen frekanslar arasÄ±ndaki farklarÄ±n karelerinin toplamÄ±nÄ±n, beklenen frekanslara oranlanarak hesaplanÄ±r.

    4. **P-deÄŸeri HesaplanmasÄ±**: Elde edilen ki-kare istatistiÄŸi kullanÄ±larak p-deÄŸeri hesaplanÄ±r. Bu p-deÄŸeri, null hipotezinin (iki deÄŸiÅŸken arasÄ±nda bir iliÅŸki olmadÄ±ÄŸÄ± hipotezi) reddedilmesi iÃ§in saÄŸlanan kanÄ±ttÄ±r. 

    5. **SonuÃ§larÄ±n YorumlanmasÄ±**: Elde edilen p-deÄŸerinin belirlenen alfa dÃ¼zeyinden (genellikle 0.05 veya 0.01) daha kÃ¼Ã§Ã¼k olmasÄ± durumunda, null hipotez reddedilir ve deÄŸiÅŸkenler arasÄ±nda anlamlÄ± bir iliÅŸki olduÄŸu sonucuna varÄ±lÄ±r. Ancak, p-deÄŸeri belirli bir alfa dÃ¼zeyinden bÃ¼yÃ¼kse, null hipotezi reddedilmez ve deÄŸiÅŸkenler arasÄ±nda anlamlÄ± bir iliÅŸki olmadÄ±ÄŸÄ± sonucuna varÄ±lÄ±r.

    Ki-kare testi, iliÅŸkiyi deÄŸerlendirmenin yanÄ± sÄ±ra, kategorik verilerin homojenlik veya baÄŸÄ±msÄ±zlÄ±k gibi diÄŸer Ã¶zelliklerini test etmek iÃ§in de kullanÄ±labilir.
        
        """,
        
        "kruskal wallis testi": """
        Kruskal-Wallis testi, gruplar arasÄ±ndaki merkezi eÄŸilimlerin (ortalama, medyan vb.) eÅŸit olup olmadÄ±ÄŸÄ±nÄ± belirlemek iÃ§in kullanÄ±lan bir non-parametrik istatistik testidir. Bu test, gruplar arasÄ±ndaki farklÄ±lÄ±klarÄ± deÄŸerlendirmek iÃ§in kullanÄ±lÄ±r ve gruplar normal daÄŸÄ±lÄ±mÄ± saÄŸlamadÄ±ÄŸÄ±nda veya gruplar arasÄ±ndaki varyans homojenliÄŸi varsayÄ±mÄ± saÄŸlanmadÄ±ÄŸÄ±nda tercih edilir.

    Kruskal-Wallis testi, gruplarÄ±n ortanca deÄŸerlerini karÅŸÄ±laÅŸtÄ±rÄ±r. Gruplar arasÄ±nda anlamlÄ± bir fark olup olmadÄ±ÄŸÄ±nÄ± belirlemek iÃ§in sÄ±ralÄ± veriler kullanÄ±lÄ±r. Bu test, iki grup arasÄ±ndaki farklÄ±lÄ±klarÄ± deÄŸil, Ã¼Ã§ veya daha fazla grup arasÄ±ndaki farklÄ±lÄ±klarÄ± deÄŸerlendirir.

    Kruskal-Wallis testinin null hipotezi, tÃ¼m gruplarÄ±n popÃ¼lasyon daÄŸÄ±lÄ±mÄ±nda ortanca deÄŸerlerinin eÅŸit olduÄŸunu ifade eder. Alternatif hipotez ise, en az bir grup ortancasÄ±nÄ±n diÄŸerlerinden farklÄ± olduÄŸunu Ã¶ne sÃ¼rer.

    Kruskal-Wallis testi, Ã¶ncelikle sÄ±ralÄ± verilerle Ã§alÄ±ÅŸÄ±r. Veriler sÄ±ralanÄ±r ve her bir gÃ¶zlem, sÄ±ralandÄ±ÄŸÄ± konumunu belirtir. Daha sonra, her grup iÃ§in sÄ±ralÄ± deÄŸerlerin toplamÄ± hesaplanÄ±r. Bu toplamlarÄ±n kullanÄ±lmasÄ±yla bir test istatistiÄŸi hesaplanÄ±r.

    Elde edilen test istatistiÄŸi, Kruskal-Wallis daÄŸÄ±lÄ±mÄ± altÄ±nda bir p-deÄŸeri hesaplanmasÄ± iÃ§in kullanÄ±lÄ±r. Bu p-deÄŸeri, null hipotezin reddedilmesi iÃ§in saÄŸlanan kanÄ±ttÄ±r. EÄŸer p-deÄŸeri belirlenen alfa dÃ¼zeyinden (genellikle 0.05 veya 0.01) daha kÃ¼Ã§Ã¼kse, null hipotez reddedilir ve en az bir grup ortancasÄ±nÄ±n diÄŸerlerinden farklÄ± olduÄŸu sonucuna varÄ±lÄ±r. Ancak, p-deÄŸeri belirlenen alfa dÃ¼zeyinden bÃ¼yÃ¼kse, null hipotez reddedilmez ve gruplar arasÄ±nda anlamlÄ± bir fark olmadÄ±ÄŸÄ± sonucuna varÄ±lÄ±r.

    Kruskal-Wallis testi, Ã¶zellikle gruplarÄ±n normal daÄŸÄ±lÄ±mÄ± saÄŸlamadÄ±ÄŸÄ± veya varyans homojenliÄŸi varsayÄ±mÄ±nÄ±n saÄŸlanmadÄ±ÄŸÄ± durumlarda tercih edilir. Bu nedenle, parametrik testlerin varsayÄ±mlarÄ±nÄ±n saÄŸlanmadÄ±ÄŸÄ± durumlarda kullanÄ±ÅŸlÄ± bir alternatif sunar.
        
        """,
        
        "spearman korelasyon katsayÄ±sÄ±": """
        Spearman korelasyon katsayÄ±sÄ±, iki deÄŸiÅŸken arasÄ±ndaki iliÅŸkinin gÃ¼cÃ¼nÃ¼ ve yÃ¶nÃ¼nÃ¼ Ã¶lÃ§mek iÃ§in kullanÄ±lan bir istatistiksel yÃ¶ntemdir. Ã–zellikle, iki deÄŸiÅŸken arasÄ±ndaki iliÅŸki monotonic (sÃ¼rekli artan veya azalan) ancak lineer olmayan bir iliÅŸki olduÄŸunda kullanÄ±lÄ±r.

    Spearman korelasyon katsayÄ±sÄ±, Pearson korelasyon katsayÄ±sÄ±na benzer bir ÅŸekilde -1 ile +1 arasÄ±nda deÄŸer alÄ±r. Ancak, Pearson korelasyon katsayÄ±sÄ±, deÄŸiÅŸkenler arasÄ±ndaki lineer iliÅŸkiyi Ã¶lÃ§erken, Spearman korelasyon katsayÄ±sÄ±, deÄŸiÅŸkenler arasÄ±ndaki monotonic iliÅŸkiyi Ã¶lÃ§er.

    Spearman korelasyon katsayÄ±sÄ±nÄ±n hesaplanmasÄ± iÃ§in ÅŸu adÄ±mlar izlenir:

    1. Ä°lk olarak, her bir deÄŸiÅŸkenin deÄŸerleri sÄ±ralanÄ±r. EÄŸer iki deÄŸiÅŸkenin aynÄ± deÄŸere sahip birden fazla gÃ¶zlemi varsa, bu gÃ¶zlemler rastgele sÄ±ralanÄ±r.

    2. ArdÄ±ndan, her bir gÃ¶zlem iÃ§in sÄ±ralar arasÄ±ndaki farklar hesaplanÄ±r. Bu farklar, bir deÄŸiÅŸkenin sÄ±ralama pozisyonundan diÄŸer deÄŸiÅŸkenin sÄ±ralama pozisyonu Ã§Ä±karÄ±larak bulunur.

    3. Son olarak, sÄ±ralar arasÄ±ndaki farklarÄ±n Pearson korelasyon katsayÄ±sÄ± hesaplanÄ±r. Bu, sÄ±ralar arasÄ±ndaki farklarÄ±n Pearson korelasyon katsayÄ±sÄ±nÄ±n hesaplanmasÄ± iÃ§in kullanÄ±lmasÄ±na dayanÄ±r.

    Spearman korelasyon katsayÄ±sÄ±, deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkinin gÃ¼cÃ¼nÃ¼ ve yÃ¶nÃ¼nÃ¼ deÄŸerlendirmek iÃ§in kullanÄ±lÄ±r. Ã–zellikle, veri normal daÄŸÄ±lÄ±ma sahip deÄŸilse veya aykÄ±rÄ± deÄŸerler varsa tercih edilir. AyrÄ±ca, deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkinin doÄŸrusal olmadÄ±ÄŸÄ± durumlarda da kullanÄ±ÅŸlÄ±dÄ±r.
        """,
        
        "pearson korelasyon katsayÄ±sÄ±": """
        Pearson korelasyon katsayÄ±sÄ±, iki deÄŸiÅŸken arasÄ±ndaki iliÅŸkinin gÃ¼cÃ¼nÃ¼ ve yÃ¶nÃ¼nÃ¼ Ã¶lÃ§mek iÃ§in kullanÄ±lan bir istatistiksel yÃ¶ntemdir. Bu katsayÄ±, deÄŸiÅŸkenler arasÄ±ndaki doÄŸrusal iliÅŸkiyi ifade eder.

    Pearson korelasyon katsayÄ±sÄ±, genellikle "-1" ile "+1" arasÄ±nda bir deÄŸer alÄ±r:

    - +1: MÃ¼kemmel pozitif iliÅŸki. Bu, iki deÄŸiÅŸken arasÄ±nda tam bir doÄŸrusal iliÅŸki olduÄŸunu gÃ¶sterir. Bir deÄŸiÅŸken artarken, diÄŸer deÄŸiÅŸken de artar.
    - 0: Ä°liÅŸki yoktur. Ä°ki deÄŸiÅŸken arasÄ±nda herhangi bir iliÅŸki bulunmamaktadÄ±r.
    - -1: MÃ¼kemmel negatif iliÅŸki. Bu, iki deÄŸiÅŸken arasÄ±nda tam ters yÃ¶nlÃ¼ bir doÄŸrusal iliÅŸki olduÄŸunu gÃ¶sterir. Bir deÄŸiÅŸken artarken, diÄŸer deÄŸiÅŸken azalÄ±r.

    Pearson korelasyon katsayÄ±sÄ±, iki deÄŸiÅŸken arasÄ±ndaki iliÅŸkiyi doÄŸrusal olarak modellemek iÃ§in kullanÄ±lÄ±r. Ã–rneÄŸin, bir deÄŸiÅŸkenin diÄŸer deÄŸiÅŸkeni ne kadar iyi tahmin edebileceÄŸini veya iki deÄŸiÅŸkenin birlikte nasÄ±l deÄŸiÅŸtiÄŸini belirlemek iÃ§in kullanÄ±labilir.

    Pearson korelasyon katsayÄ±sÄ±nÄ±n hesaplanmasÄ± iÃ§in ÅŸu adÄ±mlar izlenir:

    1. Ä°lk olarak, iki deÄŸiÅŸken arasÄ±ndaki iliÅŸkinin gÃ¼cÃ¼nÃ¼ ve yÃ¶nÃ¼nÃ¼ Ã¶lÃ§mek iÃ§in bir kovaryans hesaplanÄ±r.

    2. ArdÄ±ndan, her bir deÄŸiÅŸkenin standart sapmasÄ± hesaplanÄ±r.

    3. Son olarak, kovaryans, iki deÄŸiÅŸkenin standart sapmalarÄ±nÄ±n Ã§arpÄ±mÄ±na bÃ¶lÃ¼nerek Pearson korelasyon katsayÄ±sÄ± elde edilir.

    Pearson korelasyon katsayÄ±sÄ±, genellikle birÃ§ok alanda kullanÄ±lÄ±r, Ã¶zellikle istatistik, bilim, mÃ¼hendislik ve sosyal bilimlerde. Ancak, iki deÄŸiÅŸken arasÄ±ndaki iliÅŸki doÄŸrusal deÄŸilse veya veri normal daÄŸÄ±lÄ±ma sahip deÄŸilse, diÄŸer korelasyon yÃ¶ntemleri (Ã¶rneÄŸin, Spearman korelasyon katsayÄ±sÄ±) kullanÄ±labilir.
        """,
        
        "t testi": """
        T-testi, bir grup ortalamasÄ± arasÄ±ndaki farkÄ±n anlamlÄ±lÄ±ÄŸÄ±nÄ± test etmek iÃ§in kullanÄ±lan istatistiksel bir testtir. T-testi, bir grup ile bir diÄŸer grup arasÄ±nda ortalamalar arasÄ±nda bir fark olup olmadÄ±ÄŸÄ±nÄ± belirlemek iÃ§in kullanÄ±lÄ±r.

    T-testi genellikle iki durumda kullanÄ±lÄ±r:

    1. BaÄŸÄ±msÄ±z Ä°ki Ã–rneklem T-testi: Ä°ki baÄŸÄ±msÄ±z grup arasÄ±nda ortalamalar arasÄ±ndaki farkÄ± test etmek iÃ§in kullanÄ±lÄ±r. Ã–rneÄŸin, bir tedavi grubu ile kontrol grubu arasÄ±nda bir tedavinin etkisini deÄŸerlendirmek iÃ§in kullanÄ±labilir.

    2. EÅŸleÅŸtirilmiÅŸ Ä°ki Ã–rneklem T-testi: Ä°ki grup arasÄ±nda eÅŸleÅŸtirilmiÅŸ Ã¶rnekler varsa ve ortalamalar arasÄ±ndaki farkÄ± test etmek istiyorsak kullanÄ±lÄ±r. Bu, aynÄ± kiÅŸilerin veya birimlerin iki farklÄ± koÅŸul altÄ±nda alÄ±nan Ã¶lÃ§Ã¼mlerini karÅŸÄ±laÅŸtÄ±rmak iÃ§in kullanÄ±ÅŸlÄ±dÄ±r.

    T-testi, genellikle parametrik bir test olarak kabul edilir, yani belirli varsayÄ±mlar altÄ±nda Ã§alÄ±ÅŸÄ±r:

    - DeÄŸiÅŸkenler normal daÄŸÄ±lÄ±ma sahip olmalÄ±dÄ±r.
    - DeÄŸiÅŸkenler homojen varyansa sahip olmalÄ±dÄ±r (gruplarÄ±n varyanslarÄ± benzer olmalÄ±dÄ±r).

    T-testi sonucunda elde edilen istatistiksel sonuÃ§lar, gruplar arasÄ±ndaki farklÄ±lÄ±klarÄ±n anlamlÄ±lÄ±ÄŸÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±lÄ±r. EÄŸer p-deÄŸeri belirli bir alfa dÃ¼zeyinden (genellikle 0.05 veya 0.01) daha kÃ¼Ã§Ã¼kse, null hipotez reddedilir ve gruplar arasÄ±nda anlamlÄ± bir fark olduÄŸu sonucuna varÄ±lÄ±r. Ancak, p-deÄŸeri belirlenen alfa dÃ¼zeyinden bÃ¼yÃ¼kse, null hipotez reddedilmez ve gruplar arasÄ±nda anlamlÄ± bir fark olmadÄ±ÄŸÄ± sonucuna varÄ±lÄ±r.
        """,
        
        "wilcoxon iÅŸaretli sÄ±ralar testi": """
        Wilcoxon iÅŸaretli sÄ±ralar testi, eÅŸleÅŸtirilmiÅŸ Ã¶rnekler Ã¼zerindeki medyan farkÄ±nÄ±n anlamlÄ±lÄ±ÄŸÄ±nÄ± test etmek iÃ§in kullanÄ±lan bir non-parametrik istatistik testidir. Ä°ki durum arasÄ±nda farkÄ±n medyan deÄŸerine dayalÄ± olarak deÄŸerlendirilmesini saÄŸlar. Ã–zellikle, veri normal daÄŸÄ±lÄ±ma sahip deÄŸilse veya varyans homojenliÄŸi varsayÄ±mÄ± saÄŸlanmadÄ±ÄŸÄ±nda tercih edilir.

    Wilcoxon iÅŸaretli sÄ±ralar testi, eÅŸleÅŸtirilmiÅŸ Ã¶rneklerin sÄ±ralÄ± deÄŸerlerini kullanarak Ã§alÄ±ÅŸÄ±r. Ä°lk olarak, iki durum arasÄ±ndaki farklar (farklÄ± koÅŸullar altÄ±nda alÄ±nan Ã¶lÃ§Ã¼mler) hesaplanÄ±r. ArdÄ±ndan, bu farklar sÄ±ralanÄ±r ve mutlak deÄŸerleri alÄ±nÄ±r. SÄ±ralÄ± mutlak deÄŸerler Ã¼zerindeki iÅŸaretler (pozitif veya negatif) korunur. Son olarak, sÄ±ralÄ± mutlak deÄŸerlerin iÅŸaretli sÄ±ralarÄ± toplanÄ±r ve test istatistiÄŸi hesaplanÄ±r.

    Wilcoxon iÅŸaretli sÄ±ralar testi, verilerin normal daÄŸÄ±lÄ±ma sahip olmadÄ±ÄŸÄ± veya parametrik testlerin varsayÄ±mlarÄ±nÄ±n saÄŸlanmadÄ±ÄŸÄ± durumlarda tercih edilir. Ã–zellikle, eÅŸleÅŸtirilmiÅŸ Ã¶rnekler Ã¼zerindeki ortalamalarÄ±n veya medyanlarÄ±n farklÄ± olup olmadÄ±ÄŸÄ±nÄ± belirlemek iÃ§in kullanÄ±lÄ±r.

    Wilcoxon iÅŸaretli sÄ±ralar testinin null hipotezi, iki durum arasÄ±nda medyan farkÄ±nÄ±n olmadÄ±ÄŸÄ±nÄ± ifade eder. Alternatif hipotez ise, iki durum arasÄ±nda medyan farkÄ±nÄ±n olduÄŸunu Ã¶ne sÃ¼rer. Test sonucunda elde edilen p-deÄŸeri, null hipotezin reddedilmesi iÃ§in saÄŸlanan kanÄ±ttÄ±r. EÄŸer p-deÄŸeri belirli bir alfa dÃ¼zeyinden (genellikle 0.05 veya 0.01) daha kÃ¼Ã§Ã¼kse, null hipotez reddedilir ve iki durum arasÄ±nda anlamlÄ± bir medyan farkÄ± olduÄŸu sonucuna varÄ±lÄ±r. Ancak, p-deÄŸeri belirlenen alfa dÃ¼zeyinden bÃ¼yÃ¼kse, null hipotez reddedilmez ve iki durum arasÄ±nda anlamlÄ± bir medyan farkÄ± olmadÄ±ÄŸÄ± sonucuna varÄ±lÄ±r.
        """,
        
        "z testi": """
        Z-testi, bir popÃ¼lasyon parametresi hakkÄ±nda yapÄ±lan bir Ã¶nermenin doÄŸruluÄŸunu test etmek iÃ§in kullanÄ±lan bir istatistiksel testtir. Ã–zellikle, popÃ¼lasyon ortalamasÄ± veya oranÄ± gibi parametreler hakkÄ±nda Ã¶nermeleri test etmek iÃ§in kullanÄ±lÄ±r.

    Z-testi, Ã¶rneklemlerden elde edilen verilere dayanarak popÃ¼lasyon hakkÄ±nda bir Ã¶nermenin doÄŸruluÄŸunu deÄŸerlendirir. Bu test, genellikle bÃ¼yÃ¼k Ã¶rneklem boyutlarÄ± veya popÃ¼lasyon standart sapmasÄ± bilindiÄŸinde kullanÄ±lÄ±r.

    Z-testi, Ã¶rneklem verilerinin standart hata ile standart normal daÄŸÄ±lÄ±ma gÃ¶re standart sapma kullanÄ±larak bir z-puanÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesini iÃ§erir. Bu z-puanÄ±, Ã¶rneklem verilerine dayalÄ± olarak popÃ¼lasyon parametresinin Ã¶nerilen deÄŸeri ile karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.

    Z-testinin temel adÄ±mlarÄ± ÅŸunlardÄ±r:

    1. Null ve alternatif hipotezlerin belirlenmesi: Test edilmek istenen Ã¶nermeleri belirler.

    2. Test istatistiÄŸinin hesaplanmasÄ±: Ã–rneklem verilerine dayalÄ± olarak bir test istatistiÄŸi hesaplanÄ±r. Bu istatistik, popÃ¼lasyon parametresinin Ã¶nerilen deÄŸeri ile karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.

    3. P-deÄŸeri hesaplanmasÄ±: Elde edilen test istatistiÄŸi kullanÄ±larak bir p-deÄŸeri hesaplanÄ±r. Bu p-deÄŸeri, null hipotezin reddedilmesi iÃ§in saÄŸlanan kanÄ±ttÄ±r.

    4. SonuÃ§larÄ±n yorumlanmasÄ±: Elde edilen p-deÄŸeri belirlenen alfa dÃ¼zeyinden (genellikle 0.05 veya 0.01) daha kÃ¼Ã§Ã¼kse, null hipotez reddedilir ve alternatif hipotez kabul edilir. Ancak, p-deÄŸeri belirlenen alfa dÃ¼zeyinden bÃ¼yÃ¼kse, null hipotez reddedilmez ve alternatif hipotez kabul edilmez.

    Z-testi, Ã¶zellikle bÃ¼yÃ¼k Ã¶rneklem boyutlarÄ± veya popÃ¼lasyon standart sapmasÄ± bilindiÄŸinde parametrik bir test olarak kullanÄ±labilir. Ã–te yandan, kÃ¼Ã§Ã¼k Ã¶rneklem boyutlarÄ± veya popÃ¼lasyon standart sapmasÄ± bilinmediÄŸinde, t-testi gibi alternatif non-parametrik testler tercih edilebilir.
        """,
        
        "cart": """
        CART (Classification and Regression Trees), sÄ±nÄ±flandÄ±rma ve regresyon iÃ§in kullanÄ±lan bir aÄŸaÃ§ yapÄ±sÄ±dÄ±r. Bu yÃ¶ntem, veri kÃ¼mesindeki iliÅŸkileri belirlemek ve Ã¶rÃ¼ntÃ¼leri tanÄ±mlamak iÃ§in kullanÄ±lÄ±r. SÄ±nÄ±flandÄ±rma aÄŸaÃ§larÄ±, kategorik hedef deÄŸiÅŸkenlerini tahmin etmek iÃ§in kullanÄ±lÄ±rken, regresyon aÄŸaÃ§larÄ± sÃ¼rekli hedef deÄŸiÅŸkenlerini tahmin etmek iÃ§in kullanÄ±lÄ±r.

    CART algoritmasÄ±, aÄŸaÃ§ yapÄ±sÄ±nÄ± oluÅŸtururken veri kÃ¼mesindeki en iyi bÃ¶lÃ¼nmeyi belirlemek iÃ§in bir dizi karar kuralÄ± kullanÄ±r. Her bir bÃ¶lÃ¼nme, veri kÃ¼mesini homojen alt gruplara bÃ¶ler. Bu bÃ¶lÃ¼nmeler, veri kÃ¼mesindeki Ã¶rÃ¼ntÃ¼leri daha iyi aÃ§Ä±klamak iÃ§in bir dizi karar kuralÄ± kullanÄ±larak tekrar tekrar uygulanÄ±r. SonuÃ§ olarak, bir aÄŸaÃ§ oluÅŸturulur; bu aÄŸaÃ§, veri kÃ¼mesindeki Ã¶rÃ¼ntÃ¼leri gÃ¶rsel olarak temsil eder ve hedef deÄŸiÅŸkenin tahmin edilmesine olanak saÄŸlar.

    SÄ±nÄ±flandÄ±rma aÄŸaÃ§larÄ±, bir sÄ±nÄ±flandÄ±rma problemindeki sÄ±nÄ±flarÄ± veya kategorik hedef deÄŸiÅŸkenleri tahmin etmek iÃ§in kullanÄ±lÄ±r. Ã–rneÄŸin, bir kiÅŸinin kredi baÅŸvurusunun onaylanÄ±p onaylanmayacaÄŸÄ±nÄ± tahmin etmek gibi. Regresyon aÄŸaÃ§larÄ± ise, bir regresyon problemi iÃ§in sÃ¼rekli hedef deÄŸiÅŸkenlerini tahmin etmek iÃ§in kullanÄ±lÄ±r. Ã–rneÄŸin, bir evin fiyatÄ±nÄ± tahmin etmek gibi.

    CART algoritmasÄ±, basit, esnek ve yÃ¼ksek performanslÄ± bir model oluÅŸturmak iÃ§in yaygÄ±n olarak kullanÄ±lÄ±r. AyrÄ±ca, aÄŸaÃ§ yapÄ±sÄ±nÄ±n yorumlanmasÄ± kolaydÄ±r, bu nedenle karar aÄŸaÃ§larÄ±nÄ± analiz etmek ve sonuÃ§larÄ±nÄ± yorumlamak oldukÃ§a sezgiseldir.
        """,
        
        "catboost": """
        CatBoost, kategorik deÄŸiÅŸkenleri etkili bir ÅŸekilde ele alan bir gradient boosting Ã§erÃ§evesidir. Gradient boosting, zayÄ±f Ã¶ÄŸrenicileri (genellikle karar aÄŸaÃ§larÄ±) bir araya getirerek gÃ¼Ã§lÃ¼ bir Ã¶ÄŸrenici oluÅŸturan bir makine Ã¶ÄŸrenimi tekniÄŸidir. CatBoost, kategorik deÄŸiÅŸkenleri otomatik olarak iÅŸler ve bu nedenle veri setindeki kategorik deÄŸiÅŸkenlerin dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi veya kodlanmasÄ± gerekmez.

    CatBoost, performansÄ± artÄ±rmak iÃ§in bir dizi yenilikÃ§i teknik kullanÄ±r. Ã–rneÄŸin, asimetrik aÄŸaÃ§ bÃ¼yÃ¼mesi, baÄŸlam duyarlÄ± hÃ¼cre seÃ§imi ve dinamik Ã¶ÄŸrenme oranÄ± gibi teknikler kullanarak aÄŸaÃ§larÄ±n oluÅŸturulmasÄ±nÄ± optimize eder. AyrÄ±ca, CatBoost, genellikle overfittingi Ã¶nlemek iÃ§in kullanÄ±lan bir dizi dÃ¼zenleme tekniÄŸi de iÃ§erir.

    CatBoost, bÃ¼yÃ¼k Ã¶lÃ§ekli veri setleri Ã¼zerinde yÃ¼ksek performans gÃ¶sterir ve genellikle sÄ±ralama, sÄ±nÄ±flandÄ±rma ve regresyon gibi Ã§eÅŸitli makine Ã¶ÄŸrenimi problemlerinde baÅŸarÄ±lÄ± sonuÃ§lar verir. AyrÄ±ca, CatBoost, Python, R, C++ gibi yaygÄ±n programlama dillerinde kullanÄ±labilir ve aÃ§Ä±k kaynaklÄ± bir projedir.
        
        """,
        
        "gaussian naive bayes": """
        Gaussian Naive Bayes, Naive Bayes sÄ±nÄ±flandÄ±rma algoritmasÄ±nÄ±n bir tÃ¼rÃ¼dÃ¼r ve Ã¶zellikle sÃ¼rekli Ã¶zelliklere sahip veri setleriyle Ã§alÄ±ÅŸÄ±r. Naive Bayes sÄ±nÄ±flandÄ±rma algoritmalarÄ±, Bayes teoremini kullanarak sÄ±nÄ±flandÄ±rma yaparlar. Gaussian Naive Bayes, sÄ±nÄ±flandÄ±rma problemlerini Ã§Ã¶zmek iÃ§in normal (Gaussian) daÄŸÄ±lÄ±mÄ± varsayarak Ã§alÄ±ÅŸÄ±r.

    Gaussian Naive Bayes algoritmasÄ±, her sÄ±nÄ±f iÃ§in veri setindeki her Ã¶zelliÄŸin normal daÄŸÄ±ldÄ±ÄŸÄ±nÄ± varsayar. Bu, her Ã¶zellik iÃ§in ortalama ve standart sapmanÄ±n hesaplanmasÄ±nÄ± gerektirir. ArdÄ±ndan, veri noktasÄ±nÄ±n her bir Ã¶zelliÄŸi iÃ§in normal daÄŸÄ±lÄ±m yoÄŸunluk fonksiyonlarÄ± kullanÄ±larak sÄ±nÄ±f etiketi belirlenir.

    Gaussian Naive Bayes'in "naive" (saf) olarak adlandÄ±rÄ±lmasÄ±nÄ±n nedeni, Ã¶zellikler arasÄ±ndaki baÄŸÄ±msÄ±zlÄ±k varsayÄ±mÄ±dÄ±r. Bu, her Ã¶zelliÄŸin sÄ±nÄ±f etiketi Ã¼zerindeki etkisinin birbirinden baÄŸÄ±msÄ±z olduÄŸu anlamÄ±na gelir. Bu varsayÄ±m gerÃ§ekte nadiren tam olarak doÄŸrudur, ancak Naive Bayes algoritmalarÄ± genellikle pratikte iyi performans gÃ¶sterirler.

    Gaussian Naive Bayes, Ã¶zellikle kÃ¼Ã§Ã¼k boyutlu veri setleri veya yÃ¼ksek boyutlu Ã¶zellik uzaylarÄ±yla Ã§alÄ±ÅŸÄ±rken etkilidir. AyrÄ±ca, kategorik veya nominal veri ile birlikte sÃ¼rekli veri kullanÄ±mÄ±na izin verir. Bununla birlikte, veri seti Ã¼zerinde bazÄ± varsayÄ±mlarÄ±n doÄŸru olmadÄ±ÄŸÄ± durumlarda performansÄ± dÃ¼ÅŸebilir.
        
        """,
        
        "gradient boosting machine": """
        Gradient Boosting Machine (GBM), bir makine Ã¶ÄŸrenimi tekniÄŸi olan Gradient Boosting'in uygulanmasÄ±yla oluÅŸturulan bir modeldir. Gradient Boosting, zayÄ±f tahmin edicilerin (genellikle karar aÄŸaÃ§larÄ±) bir araya getirilerek gÃ¼Ã§lÃ¼ bir tahmin edici oluÅŸturulmasÄ±na dayanan bir ensemble yÃ¶ntemidir. Gradient Boosting Machine, bu tekniÄŸi kullanarak karmaÅŸÄ±k iliÅŸkileri modellemek iÃ§in kullanÄ±lan bir modeldir.

    Gradient Boosting Machine, temel olarak aÅŸaÄŸÄ±daki adÄ±mlarÄ± takip eder:

    1. **Ä°lk Tahminin OluÅŸturulmasÄ±:** Ä°lk tahmin olarak basit bir model kullanÄ±lÄ±r. Genellikle veri setindeki ortalama deÄŸer veya sabit bir tahmin deÄŸeri kullanÄ±labilir.

    2. **Hata (ArtÄ±k) Hesaplama:** Ä°lk tahmin ile gerÃ§ek deÄŸerler arasÄ±ndaki farklar, modelin hata (artÄ±k) deÄŸerleri olarak hesaplanÄ±r.

    3. **Hata TabanlÄ± Yeni Tahminlerin OluÅŸturulmasÄ±:** Bir sonraki aÅŸamada, hata deÄŸerlerini tahmin etmek iÃ§in yeni bir model oluÅŸturulur. Bu, hatalarÄ±n tahmin edilmesini saÄŸlar ve bÃ¶ylece daha iyi tahminler elde etmek iÃ§in kullanÄ±lÄ±r.

    4. **Yeni Tahminlerin Entegrasyonu:** Yeni tahminler, Ã¶nceki tahminlere eklenerek birleÅŸtirilir. Bu, modelin doÄŸruluÄŸunu artÄ±rmak iÃ§in kullanÄ±lÄ±r.

    5. **Yeni Modelin Hata Analizi ve SÃ¼recin TekrarlanmasÄ±:** Yeni modelin hata analizi yapÄ±lÄ±r ve hatalarÄ±n bir sonraki model iÃ§in kullanÄ±lmasÄ±yla sÃ¼reÃ§ tekrarlanÄ±r. Bu adÄ±mlar, bir dizi tahmin edici oluÅŸturulana kadar devam eder.

    Gradient Boosting Machine, karmaÅŸÄ±k iliÅŸkileri modellemek ve yÃ¼ksek doÄŸruluklu tahminler yapmak iÃ§in etkili bir yÃ¶ntemdir. Ã–zellikle sÄ±nÄ±flandÄ±rma ve regresyon problemlerinde baÅŸarÄ±lÄ± sonuÃ§lar verir. Gradient Boosting Machine, aynÄ± zamanda Ã¶zelliklerin Ã¶nem sÄ±ralamasÄ±nÄ± elde etmek iÃ§in de kullanÄ±labilir, bÃ¶ylece hangi Ã¶zelliklerin modelin performansÄ±nÄ± etkilediÄŸi anlaÅŸÄ±labilir.
        """,
        
        "knn": """K-Nearest Neighbors (KNN), temel bir sÄ±nÄ±flandÄ±rma ve regresyon algoritmasÄ±dÄ±r. KNN, Ã¶rneklerin birbirine olan benzerliklerine dayalÄ± olarak sÄ±nÄ±flandÄ±rma veya tahmin yapar. Ã–zellikle basit, etkili ve kolay anlaÅŸÄ±labilir bir algoritmadÄ±r.

    KNN algoritmasÄ± ÅŸu adÄ±mlarÄ± izler:

    1. **Ã–rneklerin Benzerliklerinin HesaplanmasÄ±:** KNN, Ã¶rnekler arasÄ±ndaki benzerlikleri Ã¶lÃ§mek iÃ§in genellikle Ã–klid mesafesi veya diÄŸer benzer mesafe metriklerini kullanÄ±r.

    2. **K En YakÄ±n KomÅŸularÄ±n Belirlenmesi:** Verilen bir Ã¶rnek iÃ§in, KNN algoritmasÄ± en yakÄ±n k komÅŸuyu belirler. Bu komÅŸular, verilen Ã¶rneÄŸe en yakÄ±n olan K Ã¶rnektir.

    3. **SÄ±nÄ±flandÄ±rma veya Tahmin YapÄ±lmasÄ±:** SÄ±nÄ±flandÄ±rma problemleri iÃ§in, KNN sadece K en yakÄ±n komÅŸularÄ±n etiketlerine bakar ve Ã§oÄŸunluk sÄ±nÄ±fÄ±nÄ±n etiketini tahmin olarak kullanÄ±r. Ã–rneÄŸin, eÄŸer K = 3 ise ve bu 3 komÅŸudan 2'si "mavi" etiketine sahipse, tahmin "mavi" olacaktÄ±r. Regresyon problemleri iÃ§in, KNN K en yakÄ±n komÅŸunun ortalamasÄ±nÄ± veya aÄŸÄ±rlÄ±klÄ± ortalamasÄ±nÄ± kullanarak tahmin yapar.

    KNN algoritmasÄ±, eÄŸitim sÃ¼resi boyunca bir model oluÅŸturmaz; bunun yerine, eÄŸitim verilerini bellekte saklar ve tahmin yapmak iÃ§in bu verilere doÄŸrudan baÅŸvurur. Bu, modelin eÄŸitim sÃ¼recinin hÄ±zlÄ± olmasÄ±nÄ± saÄŸlar, ancak tahmin yapmak iÃ§in gerÃ§ek zamanlÄ± veriye eriÅŸim gerektirir.

    KNN'nin bir dezavantajÄ±, tahmin yapmak iÃ§in tÃ¼m eÄŸitim verilerini bellekte saklamasÄ±dÄ±r, bu da bÃ¼yÃ¼k veri setlerinde bellek ve hesaplama kaynaklarÄ±nÄ±n hÄ±zla tÃ¼kenmesine neden olabilir. AyrÄ±ca, K deÄŸerinin (komÅŸu sayÄ±sÄ±) doÄŸru bir ÅŸekilde seÃ§ilmesi Ã¶nemlidir; yanlÄ±ÅŸ bir K deÄŸeri modelin performansÄ±nÄ± olumsuz yÃ¶nde etkileyebilir.""",
        
        "lightgbm": """
        LightGBM (Light Gradient Boosting Machine), bÃ¼yÃ¼k veri setlerinde yÃ¼ksek performanslÄ± ve daÄŸÄ±tÄ±lmÄ±ÅŸ bir gradient boosting Ã§erÃ§evesidir. LightGBM, Microsoft tarafÄ±ndan geliÅŸtirilen ve aÃ§Ä±k kaynaklÄ± olarak yayÄ±nlanan bir makine Ã¶ÄŸrenimi kÃ¼tÃ¼phanesidir. 

    LightGBM, diÄŸer gradient boosting kÃ¼tÃ¼phanelerine kÄ±yasla Ã§eÅŸitli yenilikÃ§i teknikler kullanarak hÄ±z ve performans avantajlarÄ± saÄŸlar. Bu teknikler arasÄ±nda Ã¶zellikle Ã¶zellik parÃ§acÄ±klandÄ±rma, eksik deÄŸerlerin iÅŸlenmesi, katmanlÄ± karar aÄŸaÃ§larÄ± ve daha efektif histogram hesaplama yÃ¶ntemleri bulunmaktadÄ±r.

    LightGBM, bÃ¼yÃ¼k Ã¶lÃ§ekli veri setlerinde yÃ¼ksek performans gÃ¶sterir ve genellikle sÄ±nÄ±flandÄ±rma, regresyon ve sÄ±ralama gibi Ã§eÅŸitli makine Ã¶ÄŸrenimi problemlerinde kullanÄ±lÄ±r. AyrÄ±ca, LightGBM, CPU ve GPU Ã¼zerinde Ã§alÄ±ÅŸabilir, bu da iÅŸlem gÃ¼cÃ¼nÃ¼ artÄ±rarak model eÄŸitim sÃ¼resini optimize eder.

    LightGBM, kullanÄ±mÄ± kolay bir API saÄŸlar ve Python, R, Java, C++ gibi Ã§eÅŸitli programlama dillerinde kullanÄ±labilir. Ã–zellikle bÃ¼yÃ¼k veri setleri Ã¼zerinde yÃ¼ksek performanslÄ± makine Ã¶ÄŸrenimi uygulamalarÄ± geliÅŸtirmek isteyenler iÃ§in popÃ¼ler bir tercihtir.
        """,
        
        "lojistik regresyon": """
        Lojistik regresyon, bir sÄ±nÄ±flandÄ±rma algoritmasÄ±dÄ±r ve birÃ§ok makine Ã¶ÄŸrenimi probleminde kullanÄ±lÄ±r. Ã–zellikle, iki sÄ±nÄ±f arasÄ±nda sÄ±nÄ±flandÄ±rma yapmak iÃ§in kullanÄ±lÄ±r (binary sÄ±nÄ±flandÄ±rma). Ã–rneÄŸin, bir mÃ¼ÅŸterinin bir Ã¼rÃ¼nÃ¼ satÄ±n alÄ±p almama olasÄ±lÄ±ÄŸÄ±nÄ± tahmin etmek gibi.

    Lojistik regresyon, bir sigmoid fonksiyonu olarak adlandÄ±rÄ±lan Ã¶zel bir aktivasyon fonksiyonu kullanÄ±r. Bu sigmoid fonksiyonu, herhangi bir gerÃ§ek sayÄ±yÄ± 0 ile 1 arasÄ±nda bir deÄŸere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r ve sonuÃ§ olarak bir olasÄ±lÄ±k deÄŸeri verir. Lojistik regresyon modeli, girdi Ã¶zelliklerinin aÄŸÄ±rlÄ±klarÄ±nÄ± ve bir sapmayÄ± (bias) kullanarak bir doÄŸrusal kombinasyon oluÅŸturur ve bu kombinasyonu sigmoid fonksiyonuna geÃ§irerek sonuÃ§ olarak bir olasÄ±lÄ±k deÄŸeri elde eder.

    Lojistik regresyonun temel adÄ±mlarÄ± ÅŸunlardÄ±r:

    1. **Model Kurma:** Ã–ncelikle, veri seti Ã¼zerinde bir lojistik regresyon modeli kurulur. Bu, girdi Ã¶zelliklerinin aÄŸÄ±rlÄ±klarÄ±nÄ±n belirlenmesini ve bir sapmanÄ±n hesaplanmasÄ±nÄ± iÃ§erir.

    2. **EÄŸitim:** Model, veri setindeki Ã¶rneklerle eÄŸitilir. Bu, modelin parametrelerinin (aÄŸÄ±rlÄ±klar ve sapma) optimize edilmesini saÄŸlar.

    3. **Tahmin Yapma:** EÄŸitim tamamlandÄ±ktan sonra, model test veri seti Ã¼zerinde kullanÄ±larak tahminler yapabilir. Sigmoid fonksiyonuna giren doÄŸrusal kombinasyon, sÄ±nÄ±f etiketinin olasÄ±lÄ±ÄŸÄ± olarak yorumlanabilir.

    Lojistik regresyon, basit, yorumlanabilir ve hesaplama aÃ§Ä±sÄ±ndan hÄ±zlÄ±dÄ±r. AyrÄ±ca, sÄ±nÄ±flandÄ±rma problemleri iÃ§in geniÅŸ bir uygulama alanÄ±na sahiptir ve Ã¶zellikle binary sÄ±nÄ±flandÄ±rma problemlerinde yaygÄ±n olarak kullanÄ±lÄ±r.
        """,
        
        "mann whitney u testi": """Mann-Whitney U testi, iki baÄŸÄ±msÄ±z Ã¶rneklem grubu arasÄ±nda ortalamalar arasÄ±nda anlamlÄ± bir fark olup olmadÄ±ÄŸÄ±nÄ± belirlemek iÃ§in kullanÄ±lan bir non-parametrik istatistik testidir. Ã–zellikle, gruplar normal daÄŸÄ±lÄ±ma sahip deÄŸilse veya varyans homojenliÄŸi varsayÄ±mÄ± saÄŸlanmadÄ±ÄŸÄ±nda tercih edilir.

    Mann-Whitney U testi, Ã¶rneklemlerdeki sÄ±ralÄ± verilerin kullanÄ±lmasÄ±na dayanÄ±r. Ä°ki grup arasÄ±ndaki medyan farkÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±r ve bu farkÄ±n rastgele olup olmadÄ±ÄŸÄ±nÄ± deÄŸerlendirir. Bu test, gruplardaki sÄ±ralÄ± verilerin toplam sÄ±ralarÄ± arasÄ±ndaki farkÄ± kullanarak Ã§alÄ±ÅŸÄ±r.

    Mann-Whitney U testi, aÅŸaÄŸÄ±daki adÄ±mlarÄ± izler:

    1. **Ã–rneklerin BirleÅŸtirilmesi:** Ä°ki baÄŸÄ±msÄ±z Ã¶rneklem grubu birleÅŸtirilir ve sÄ±ralanÄ±r.

    2. **SÄ±ralÄ± Verilere GÃ¶re RÃ¼tbelerin AtanmasÄ±:** BirleÅŸtirilmiÅŸ Ã¶rneklemlere sÄ±ralÄ± olarak rÃ¼tbeler atanÄ±r. EÅŸit deÄŸerler iÃ§in ortalamalar kullanÄ±lÄ±r.

    3. **Toplam RÃ¼tbe Ä°statistiÄŸinin HesaplanmasÄ±:** Her grubun toplam rÃ¼tbesi hesaplanÄ±r. Bu, her grup iÃ§in sÄ±ralÄ± verilerin toplam sÄ±ralarÄ±nÄ±n kullanÄ±lmasÄ±yla yapÄ±lÄ±r.

    4. **U Ä°statistiÄŸinin HesaplanmasÄ±:** GruplarÄ±n toplam rÃ¼tbeleri arasÄ±ndaki fark olan U istatistiÄŸi hesaplanÄ±r.

    5. **Kritik DeÄŸerler veya p-deÄŸeri ile KarÅŸÄ±laÅŸtÄ±rma:** Hesaplanan U istatistiÄŸi, tablo deÄŸerleri veya p-deÄŸeri ile karÅŸÄ±laÅŸtÄ±rÄ±larak gruplar arasÄ±ndaki farkÄ±n anlamlÄ± olup olmadÄ±ÄŸÄ± belirlenir.

    Mann-Whitney U testi, parametrik olmayan bir test olduÄŸu iÃ§in belirli varsayÄ±mlar gerektirmez. Bu nedenle, verilerin daÄŸÄ±lÄ±mÄ± veya varyans homojenliÄŸi gibi Ã¶n koÅŸullar saÄŸlanmadÄ±ÄŸÄ±nda bile gÃ¼venle kullanÄ±labilir. Bu test, gruplar arasÄ±ndaki merkezi eÄŸilim farklarÄ±nÄ± belirlemek iÃ§in yaygÄ±n olarak kullanÄ±lÄ±r.""",
        
        "random forest": """
        Random Forest, ensemble Ã¶ÄŸrenme yÃ¶ntemlerinden biridir ve sÄ±nÄ±flandÄ±rma ve regresyon problemlerinde kullanÄ±lÄ±r. BirÃ§ok karar aÄŸacÄ±nÄ±n bir araya getirilmesiyle oluÅŸturulan gÃ¼Ã§lÃ¼ bir modeldir. 

    Random Forest algoritmasÄ± ÅŸu adÄ±mlarÄ± takip eder:

    1. **Rastgele Alt-Ã–rneklerin OluÅŸturulmasÄ±:** Veri seti Ã¼zerinde rastgele bir alt-Ã¶rneklem seÃ§ilir (bagging).

    2. **Karar AÄŸaÃ§larÄ±nÄ±n OluÅŸturulmasÄ±:** Her alt-Ã¶rneklem Ã¼zerinde bir karar aÄŸacÄ± oluÅŸturulur. Bu karar aÄŸaÃ§larÄ±, veri setindeki Ã¶zelliklerin rastgele alt kÃ¼meleri Ã¼zerinde eÄŸitilir.

    3. **Karar AÄŸaÃ§larÄ±nÄ±n BirleÅŸtirilmesi:** OluÅŸturulan karar aÄŸaÃ§larÄ± bir araya getirilir ve bir orman oluÅŸturulur. SÄ±nÄ±flandÄ±rma problemleri iÃ§in, her aÄŸaÃ§ sÄ±nÄ±f etiketi iÃ§in bir oylama yapar. Regresyon problemleri iÃ§in, her aÄŸaÃ§ tahminlerini bir araya getirir ve ortalamasÄ±nÄ± alÄ±r.

    Random Forest'in ana avantajlarÄ± ÅŸunlardÄ±r:

    - **YÃ¼ksek Performans:** Random Forest, birÃ§ok karar aÄŸacÄ±nÄ±n bir araya getirilmesiyle oluÅŸturulduÄŸu iÃ§in, genellikle yÃ¼ksek doÄŸruluk ve genelleme performansÄ± saÄŸlar.
    - **DeÄŸiÅŸken Ã–nem Derecelendirmesi:** Random Forest, her bir Ã¶zelliÄŸin modeldeki Ã¶nemini deÄŸerlendirmek iÃ§in de kullanÄ±labilir. Bu, hangi Ã¶zelliklerin modelde daha etkili olduÄŸunu anlamak iÃ§in faydalÄ± olabilir.
    - **Veri Setindeki GÃ¼rÃ¼ltÃ¼ye DirenÃ§:** Random Forest, veri setindeki gÃ¼rÃ¼ltÃ¼ye ve aÅŸÄ±rÄ± uyuma karÅŸÄ± oldukÃ§a direnÃ§lidir. AyrÄ±ca, genellikle overfitting'e karÅŸÄ± daha dayanÄ±klÄ±dÄ±r.

    Random Forest, genellikle sÄ±nÄ±flandÄ±rma ve regresyon problemlerinde yaygÄ±n olarak kullanÄ±lan gÃ¼Ã§lÃ¼ ve esnek bir makine Ã¶ÄŸrenimi modelidir.
        """,
        
        "rbf svc": """
        RBF SVC (Radial Basis Function Support Vector Classification), destek vektÃ¶r makineleri (Support Vector Machines - SVM) algoritmasÄ±nÄ±n bir tÃ¼rÃ¼dÃ¼r ve Ã¶zellikle sÄ±nÄ±flandÄ±rma problemlerinde kullanÄ±lÄ±r. SVM, bir veri kÃ¼mesini sÄ±nÄ±flandÄ±rmak iÃ§in kullanÄ±lan bir Ã¶ÄŸrenme algoritmasÄ±dÄ±r ve Ã¶zellikle doÄŸrusal olarak ayrÄ±lamayan veri setleri iÃ§in etkilidir.

    RBF SVC, SVM'in bir tÃ¼rÃ¼ olduÄŸu iÃ§in, SVM'in temel fikirleri ve prensipleri Ã¼zerine kurulmuÅŸtur. SVM, sÄ±nÄ±flar arasÄ±ndaki karar sÄ±nÄ±rlarÄ±nÄ± (decision boundaries) en iyi ÅŸekilde ayÄ±ran hiperdÃ¼zlemleri (hyperplanes) bulmaya Ã§alÄ±ÅŸÄ±r. Ancak, RBF SVC, bu hiperdÃ¼zlemi doÄŸrusal olmayan veri setlerinde bulmak iÃ§in Ã§ekirdek fonksiyonu olarak Radial Basis Function (RBF) kullanÄ±r.

    RBF, veri noktalarÄ±nÄ±n uzaklÄ±ÄŸÄ±na dayanan bir Ã§ekirdek fonksiyonudur. RBF fonksiyonu, iki veri noktasÄ± arasÄ±ndaki benzerlik Ã¶lÃ§Ã¼sÃ¼nÃ¼ hesaplamak iÃ§in kullanÄ±lÄ±r. Bu, veri noktalarÄ±nÄ±n uzayda nasÄ±l daÄŸÄ±ldÄ±ÄŸÄ±nÄ± dikkate alarak, veri noktalarÄ±nÄ±n birbirlerine ne kadar yakÄ±n veya uzak olduklarÄ±nÄ± belirler. RBF Ã§ekirdek fonksiyonu, doÄŸrusal olmayan karar sÄ±nÄ±rlarÄ±nÄ± tanÄ±mlamak iÃ§in kullanÄ±lÄ±r.

    RBF SVC'nin avantajlarÄ± ÅŸunlardÄ±r:

    1. **Esneklik:** RBF SVC, doÄŸrusal olarak ayrÄ±lamayan veri setlerini sÄ±nÄ±flandÄ±rmak iÃ§in oldukÃ§a esnektir ve karmaÅŸÄ±k sÄ±nÄ±flandÄ±rma problemlerine uygundur.

    2. **YÃ¼ksek Boyutlu Veri Setleriyle Ã‡alÄ±ÅŸma:** RBF SVC, yÃ¼ksek boyutlu ve bÃ¼yÃ¼k Ã¶lÃ§ekli veri setleriyle iyi Ã§alÄ±ÅŸÄ±r. Veri setinin boyutu arttÄ±kÃ§a, RBF SVC'nin performansÄ± genellikle dÃ¼ÅŸmez.

    3. **GÃ¼rÃ¼ltÃ¼ye DirenÃ§:** RBF SVC, gÃ¼rÃ¼ltÃ¼lÃ¼ veri setleri Ã¼zerinde iyi performans gÃ¶sterir ve aÅŸÄ±rÄ± uyuma karÅŸÄ± direnÃ§lidir.

    Ancak, RBF SVC'nin bir dezavantajÄ±, modelin karmaÅŸÄ±klÄ±ÄŸÄ± nedeniyle eÄŸitim sÃ¼resinin uzun olabilmesidir. AyrÄ±ca, RBF SVC'nin hiperparametre ayarÄ±nÄ±n doÄŸru ÅŸekilde yapÄ±lmasÄ± Ã¶nemlidir; Ã¶zellikle, C ve gamma gibi parametrelerin dikkatlice ayarlanmasÄ± gerekebilir.
        """,
        
        "svc": """
        SVC (Support Vector Classification), destek vektÃ¶r makineleri (Support Vector Machines - SVM) algoritmasÄ±nÄ±n sÄ±nÄ±flandÄ±rma problemleri iÃ§in bir uygulamasÄ±dÄ±r. SVM, Ã¶zellikle doÄŸrusal ve doÄŸrusal olmayan sÄ±nÄ±flandÄ±rma problemlerinde etkili olan bir makine Ã¶ÄŸrenimi algoritmasÄ±dÄ±r.

    SVC, bir veri setini sÄ±nÄ±flandÄ±rmak iÃ§in bir karar sÄ±nÄ±rlÄ±ÄŸÄ± (decision boundary) oluÅŸturur. Temel amacÄ±, sÄ±nÄ±flar arasÄ±ndaki bu karar sÄ±nÄ±rlÄ±ÄŸÄ±nÄ± en iyi ÅŸekilde ayÄ±ran bir hiperdÃ¼zlemi (hyperplane) bulmaktÄ±r. Ancak, sÄ±nÄ±flar genellikle doÄŸrusal olarak ayrÄ±lamaz. Bu durumda, SVC, veri noktalarÄ±nÄ± uzayda dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in bir Ã§ekirdek fonksiyonu kullanÄ±r ve bu dÃ¶nÃ¼ÅŸÃ¼m sonucu veri setinin daha yÃ¼ksek boyutlu bir uzayda doÄŸrusal olarak ayrÄ±labilir hale gelmesini saÄŸlar.

    SVC'nin temel Ã¶zellikleri ÅŸunlardÄ±r:

    1. **Esneklik:** SVC, doÄŸrusal ve doÄŸrusal olmayan sÄ±nÄ±flandÄ±rma problemlerinde etkili bir ÅŸekilde Ã§alÄ±ÅŸabilir. Bu, farklÄ± tÃ¼rdeki veri setlerine uyum saÄŸlama esnekliÄŸi saÄŸlar.

    2. **KÃ¼Ã§Ã¼k Veri Setleriyle Ã‡alÄ±ÅŸma:** SVC, kÃ¼Ã§Ã¼k boyutlu veri setlerinde de etkili bir ÅŸekilde Ã§alÄ±ÅŸabilir.

    3. **DeÄŸiÅŸken Ã–nem Derecelendirmesi:** SVC, sÄ±nÄ±flandÄ±rma iÅŸlemi sÄ±rasÄ±nda kullanÄ±lan Ã¶zelliklerin Ã¶nemini belirlemek iÃ§in kullanÄ±labilir.

    SVC'nin bazÄ± dezavantajlarÄ± da vardÄ±r:

    1. **Hesaplama YoÄŸunluÄŸu:** SVC, bÃ¼yÃ¼k veri setleri Ã¼zerinde eÄŸitilirken ve tahmin yapÄ±lÄ±rken hesaplama yoÄŸun olabilir.

    2. **Hiperparametre AyarÄ±:** SVC'nin bazÄ± hiperparametreleri vardÄ±r (Ã¶rneÄŸin, C ve Ã§ekirdek tipi), bu parametrelerin doÄŸru ÅŸekilde ayarlanmasÄ± modelin performansÄ±nÄ± etkileyebilir.

    SVC, genellikle sÄ±nÄ±flandÄ±rma problemleri iÃ§in etkili bir seÃ§enektir ve Ã¶zellikle veri setinin boyutu kÃ¼Ã§Ã¼k olduÄŸunda veya sÄ±nÄ±flar arasÄ±nda doÄŸrusal bir ayrÄ±m yoksa tercih edilir.
        """,
        
        "xgboost": """
        XGBoost (Extreme Gradient Boosting), sÄ±nÄ±flandÄ±rma, regresyon ve sÄ±ralama problemleri iÃ§in kullanÄ±lan bir gradient boosting Ã§erÃ§evesidir. Gradient boosting, zayÄ±f tahmin edicilerin (genellikle karar aÄŸaÃ§larÄ±) bir araya getirilerek gÃ¼Ã§lÃ¼ bir tahmin edici oluÅŸturulmasÄ±na dayanan bir makine Ã¶ÄŸrenimi tekniÄŸidir.

    XGBoost, diÄŸer gradient boosting kÃ¼tÃ¼phanelerine kÄ±yasla bir dizi yenilikÃ§i teknik kullanarak hÄ±z ve performans avantajlarÄ± saÄŸlar. Bu teknikler arasÄ±nda dÃ¼zenlileÅŸtirme (regularization), Ã¶zellik Ã¶nem sÄ±ralamasÄ±, eksik deÄŸerlerin ele alÄ±nmasÄ± ve Ã¶zel sayÄ±sal optimizasyon algoritmalarÄ± gibi teknikler bulunur. XGBoost, bu tekniklerin yanÄ± sÄ±ra paralel hesaplama yeteneklerini kullanarak Ã§ok bÃ¼yÃ¼k veri setleri Ã¼zerinde yÃ¼ksek performanslÄ± modelleme saÄŸlar.

    XGBoost'un bazÄ± avantajlarÄ± ÅŸunlardÄ±r:

    1. **YÃ¼ksek Performans:** XGBoost, hÄ±z ve Ã¶lÃ§eklenebilirlik aÃ§Ä±sÄ±ndan yÃ¼ksek performans sunar. Genellikle diÄŸer boosting yÃ¶ntemlerine kÄ±yasla daha hÄ±zlÄ± eÄŸitilir ve daha iyi sonuÃ§lar verir.

    2. **DeÄŸiÅŸken Ã–nem Derecelendirmesi:** XGBoost, modelin Ã¶zelliklerin Ã¶nem sÄ±ralamasÄ±nÄ± belirlemek iÃ§in kullanÄ±labilir. Bu, hangi Ã¶zelliklerin modelin performansÄ±nÄ± etkilediÄŸini anlamak iÃ§in faydalÄ±dÄ±r.

    3. **Esneklik:** XGBoost, birÃ§ok farklÄ± makine Ã¶ÄŸrenimi probleminde kullanÄ±labilir. SÄ±nÄ±flandÄ±rma, regresyon, sÄ±ralama gibi Ã§eÅŸitli problemleri Ã§Ã¶zebilir.

    XGBoost, Ã¶zellikle Kaggle yarÄ±ÅŸmalarÄ± gibi veri bilimi yarÄ±ÅŸmalarÄ±nda ve endÃ¼striyel uygulamalarda yaygÄ±n olarak kullanÄ±lan bir makine Ã¶ÄŸrenimi aracÄ±dÄ±r. AyrÄ±ca, Python, R, Java, C++ gibi Ã§eÅŸitli programlama dillerinde kullanÄ±labilir ve aÃ§Ä±k kaynaklÄ± bir projedir.
        """,
        
        "yapay sinir aÄŸlarÄ±": """
        Yapay sinir aÄŸlarÄ± (YSA), insan beyninin sinir aÄŸlarÄ±ndan esinlenerek oluÅŸturulan matematiksel modeldir. Yapay sinir aÄŸlarÄ±, birÃ§ok baÄŸlÄ± nÃ¶ron veya "hÃ¼cre" adÄ± verilen basit iÅŸlem birimlerinden oluÅŸur. Bu nÃ¶ronlar, gelen veri ve aÄŸÄ±rlÄ±klarÄ± kullanarak belirli bir Ã§Ä±ktÄ± Ã¼retirler.

    Yapay sinir aÄŸlarÄ± genellikle katmanlar halinde dÃ¼zenlenir. Bir yapay sinir aÄŸÄ± genellikle Ã¼Ã§ ana katmandan oluÅŸur:

    1. **GiriÅŸ KatmanÄ± (Input Layer):** Verinin modelin iÃ§ine girdiÄŸi katmandÄ±r. GiriÅŸ katmanÄ±nda, her bir nÃ¶ron, modele giren her bir Ã¶zelliÄŸi (feature) temsil eder.

    2. **Gizli Katmanlar (Hidden Layers):** GiriÅŸ katmanÄ±nÄ±n ardÄ±ndan bir veya daha fazla gizli katman gelir. Bu katmanlarda, veri setindeki karmaÅŸÄ±k iliÅŸkilerin Ã¶ÄŸrenilmesi iÃ§in bir dizi iÅŸlem yapÄ±lÄ±r. Her bir gizli katmandaki nÃ¶ronlar, giriÅŸlerinden gelen verileri alÄ±r, aÄŸÄ±rlÄ±klarla Ã§arpar ve bir aktivasyon fonksiyonundan geÃ§irir.

    3. **Ã‡Ä±kÄ±ÅŸ KatmanÄ± (Output Layer):** En son katmandÄ±r ve modelin Ã§Ä±ktÄ±sÄ±nÄ± Ã¼retir. SÄ±nÄ±flandÄ±rma problemleri iÃ§in genellikle Ã§Ä±ktÄ± katmanÄ±nda softmax aktivasyon fonksiyonu kullanÄ±lÄ±rken, regresyon problemleri iÃ§in doÄŸrudan bir Ã§Ä±ktÄ± Ã¼retilir.

    Yapay sinir aÄŸlarÄ±, eÄŸitim sÃ¼recinde aÄŸÄ±rlÄ±klarÄ±n ayarlanmasÄ±yla Ã¶ÄŸrenirler. GerÃ§ek Ã§Ä±ktÄ± ile modelin tahmin ettiÄŸi Ã§Ä±ktÄ± arasÄ±ndaki fark, bir kayÄ±p fonksiyonu kullanÄ±larak hesaplanÄ±r ve bu farkÄ± minimize etmek iÃ§in geriye doÄŸru yayÄ±lÄ±m (backpropagation) algoritmasÄ± kullanÄ±larak aÄŸÄ±rlÄ±klar gÃ¼ncellenir.

    Yapay sinir aÄŸlarÄ±, geniÅŸ bir uygulama yelpazesine sahiptir. SÄ±nÄ±flandÄ±rma, regresyon, sinirsel dil modelleri, gÃ¶rÃ¼ntÃ¼ tanÄ±ma, ses tanÄ±ma, doÄŸal dil iÅŸleme gibi birÃ§ok alan iÃ§in baÅŸarÄ±lÄ± bir ÅŸekilde kullanÄ±lmaktadÄ±r.
        """
        }

    user_input = st.text_input("HakkÄ±nda bilgi edinmek istediÄŸiniz algoritma veya tekniÄŸin adÄ±nÄ± yazÄ±nÄ±z.").lower()

    if user_input in headings_and_descriptions:
        st.write(headings_and_descriptions[user_input])
    

    if st.button("HazÄ±rlayan"):
        st.write("Deniz ÃœNLÃœ")
        st.write("Ä°letiÅŸim: denizstatistics@gmail.com")
        st.write("Linkedin: www.linkedin.com/in/deniz-Ã¼nlÃ¼-5a5036244")
        st.write("Github: https://github.com/denizzunlu")
        st.write("Kaggle: https://www.kaggle.com/denizzunlu")
    
    
    
    
elif page == "KeÅŸifsel Veri Analizi":
    import streamlit as st
    import pandas as pd
    import numpy as np
    from contextlib import redirect_stdout
    import io
    import seaborn as sns
    import matplotlib.pyplot as plt
    import functions as functions
    from scipy.stats import norm, uniform, binom, poisson, expon, skewnorm, lognorm
    from scipy.stats import skewnorm
    import plotly.express as px
    from scipy import stats
    import statsmodels.api as sm
    from scipy.stats import shapiro, kstest
    import scipy.stats as stats
    from scipy.stats import pearsonr, spearmanr


    def perform_normality_tests(data, selected_column):
        # Shapiro-Wilk testi
        shapiro_stat, shapiro_p_value = shapiro(data[selected_column])
        # Kolmogorov-Smirnov testi
        ks_stat, ks_p_value = kstest(data[selected_column], 'norm')
        
        return shapiro_p_value, ks_p_value


    st.header("KeÅŸifsel Veri Analizi ğŸ”")

    # Veri setini yÃ¼kle
    allowed_formats = ["csv", "txt", "xls", "xlsx"]
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

    if upload is not None:
        if "csv" in upload.name.lower():
            data = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            data = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            data = pd.read_excel(upload)

        # Tam veriyi gÃ¶ster
        st.subheader("YÃ¼klenilen Veri Seti")
        st.write(data)

        st.markdown(f"*Veri Seti:* {data.shape[0]} satÄ±r, {data.shape[1]} sÃ¼tun'dan oluÅŸmaktadÄ±r.")

        # Genel Bilgileri GÃ¶ster
        if st.checkbox("Veri HakkÄ±nda Genel Bilgileri GÃ¶ster"):
            info_buffer = io.StringIO()
            with redirect_stdout(info_buffer):
                data.info()
            info_str = info_buffer.getvalue()
            st.text(info_str)

        # DeÄŸiÅŸken AdlarÄ±
        if st.checkbox("DeÄŸiÅŸken AdlarÄ±nÄ± GÃ¶ster"):
            all_columns = data.columns.to_list()
            st.write("TÃ¼m DeÄŸiÅŸkenler:", all_columns)

        # Ä°lk BeÅŸ SatÄ±r Butonu
        if st.checkbox("Ä°lk BeÅŸ SatÄ±rÄ± GÃ¶ster"):
            st.write("Ä°lk BeÅŸ SatÄ±r:")
            st.write(data.head())

        # Sondan 5 satÄ±rÄ± gÃ¶ster
        if st.checkbox("Sondan 5 SatÄ±rÄ± GÃ¶ster"):
            st.write(data.tail())

        # Eksik deÄŸerleri gÃ¶sterme
        if st.checkbox("Eksik DeÄŸerleri GÃ¶ster"):
            st.subheader("Eksik DeÄŸerler")
            st.write(data.isnull().sum())
    

        # Betimsel Ä°statistikler Butonu
        if st.checkbox("Betimsel Ä°statistikleri GÃ¶ster"):
            st.write(data.describe().T)
        

        # DaÄŸÄ±lÄ±m KontrolÃ¼
        if st.checkbox("DaÄŸÄ±lÄ±m KontrolÃ¼"):
            numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns
            selected_column = st.selectbox("Ä°ncelemek istediÄŸiniz sayÄ±sal deÄŸiÅŸkeni seÃ§in.", numerical_columns)

            if st.button("Histogram"):
                # Histogram Ã§izimi
                fig, ax = plt.subplots(figsize=(8, 6))
                sns.histplot(data[selected_column], kde=True, color='blue', bins=30, line_kws={'color': 'red'}, ax=ax)
                plt.title('Histogram')
                st.pyplot(fig)

            if st.button("Q-Q Plot"):
                # Q-Q plot Ã§izimi
                fig, ax = plt.subplots(figsize=(8, 6))
                stats.probplot(data[selected_column], dist="norm", plot=ax)
                plt.title('Q-Q Plot')
                st.pyplot(fig)

            if st.button("Normal DaÄŸÄ±lÄ±ma Uygunluk Testleri"):
                shapiro_p_value, ks_p_value = perform_normality_tests(data, selected_column)
                if shapiro_p_value >= 0.05:
                    st.write(f"Shapiro-Wilk testi sonucu P deÄŸeri {shapiro_p_value} olduÄŸundan veri normal daÄŸÄ±lÄ±ma uymaktadÄ±r.")
                else:
                    st.write(f"Shapiro-Wilk testi sonucu P deÄŸeri {shapiro_p_value} olduÄŸundan veri normal daÄŸÄ±lÄ±ma uymamaktadÄ±r.")
                
                if ks_p_value >= 0.05:
                    st.write(f"Kolmogorov-Smirnov testi sonucu P deÄŸeri {ks_p_value} olduÄŸundan veri normal daÄŸÄ±lÄ±ma uymaktadÄ±r.")
                else:
                    st.write(f"Kolmogorov-Smirnov testi sonucu P deÄŸeri {ks_p_value} olduÄŸundan veri normal daÄŸÄ±lÄ±ma uymamaktadÄ±r.")
                
                st.write("---")
    # Checkbox ile kategorik deÄŸiÅŸken grafik seÃ§eneklerini gÃ¶sterme
        show_categorical_plots = st.checkbox("Kategorik DeÄŸiÅŸkenler iÃ§in Grafikler")

        if show_categorical_plots:
            # Kategorik deÄŸiÅŸkenleri seÃ§me
            categorical_columns = data.select_dtypes(include='object').columns
            selected_categorical_column = st.selectbox("Ä°ncelemek istediÄŸiniz kategorik deÄŸiÅŸkeni seÃ§iniz.", categorical_columns)

            # SeÃ§enekleri belirle
            categorical_plot_options = ["Bar Plot", "Pie Chart"]
            categorical_plot_option = st.selectbox("Grafik TÃ¼rÃ¼nÃ¼ SeÃ§in.", categorical_plot_options)

            if categorical_plot_option in ["Bar Plot", "Pie Chart"]:
                if categorical_plot_option == "Bar Plot":
                    fig = px.histogram(data, x=selected_categorical_column, title=f"{selected_categorical_column} DeÄŸiÅŸkeni - Bar Plot",
                                    marginal=None, hover_data=data.columns)
                
                elif categorical_plot_option == "Pie Chart":
                    fig = px.pie(data, names=selected_categorical_column, title=f"{selected_categorical_column} DeÄŸiÅŸkeni - Pie Chart")

                st.plotly_chart(fig, theme="streamlit")

            

            st.write("---")  # DeÄŸiÅŸkenler arasÄ±nda ayÄ±rÄ±cÄ± bir Ã§izgi ekleyelim


        # Checkbox ile grafik seÃ§eneklerini gÃ¶sterme
        show_plots = st.checkbox("SayÄ±sal DeÄŸiÅŸkenler iÃ§in Grafikler")

        if show_plots:
            #SayÄ±sal deÄŸiÅŸkenleri seÃ§me
            numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns
            selected_column = st.selectbox("Ä°ncelemek istediÄŸiniz deÄŸiÅŸkeni seÃ§iniz.", numerical_columns)
            
            # SeÃ§enekleri belirle
            options = ["Box plot", "Violin plot", "Scatter plot", "Line plot"]
            option = st.selectbox("Grafik TÃ¼rÃ¼nÃ¼ SeÃ§in.", options)

            if option in ["Box plot", "Violin plot", "Scatter plot", "Line plot"]:
                
                if option == "Box plot":
                    fig = px.box(data, y=selected_column, title=f'Box Plot for {selected_column}')
                    fig.update_layout(width=1000, height=600)  # GeniÅŸlik ve yÃ¼ksekliÄŸi artÄ±rma
                    st.write(fig)

                elif option == "Violin plot":
                    fig = px.violin(data, y=selected_column, box=True, points="all", title=f'Violin Plot for {selected_column}')
                    fig.update_layout(width=1000, height=600)  # GeniÅŸlik ve yÃ¼ksekliÄŸi artÄ±rma
                    st.write(fig)

                elif option == "Scatter plot":
                    fig = px.scatter(data, x=data.index, y=selected_column, title=f'Scatter Plot for {selected_column}')
                    fig.update_layout(width=1000, height=600)  # GeniÅŸlik ve yÃ¼ksekliÄŸi artÄ±rma
                    st.write(fig)

                elif option == "Line plot":
                    fig = px.line(data, x=data.index, y=selected_column, title=f'Line Plot for {selected_column}')
                    fig.update_layout(width=1000, height=600)  # GeniÅŸlik ve yÃ¼ksekliÄŸi artÄ±rma
                    st.write(fig)
                
                    
            st.write("---")  # DeÄŸiÅŸkenler arasÄ±nda ayÄ±rÄ±cÄ± bir Ã§izgi ekleyelim
        
        
        
            # SayÄ±sal deÄŸiÅŸkenlerin korelasyon matrisi
            if st.checkbox("SayÄ±sal DeÄŸiÅŸkenler ArasÄ± Korelasyon Matrisi"):
                correlation_matrix = data.select_dtypes(include=['float64', 'int64']).corr(method='pearson')
                spearman_corr_matrix = data.select_dtypes(include=['float64', 'int64']).corr(method='spearman')

                # Korelasyon matrisini gÃ¶ster
                st.subheader("Pearson Korelasyon Matrisi")
                st.write(correlation_matrix)

                st.subheader("Spearman Korelasyon Matrisi")
                st.write(spearman_corr_matrix)

                numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns
                
                options = ["Pairplot", "Heatmap"]
                option = st.selectbox("Grafik TÃ¼rÃ¼nÃ¼ SeÃ§in.", options)
                
                if option == "Pairplot":
                    pair_plot_data = data[numerical_columns]
                    pair_plot = sns.pairplot(pair_plot_data)
                    plt.suptitle("SayÄ±sal DeÄŸiÅŸkenler iÃ§in PairPlot", y=1.02)
                    st.pyplot(pair_plot.fig)

                elif option == "Heatmap":
                    fig, ax = plt.subplots(figsize=(12, 8))
                    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", ax=ax)
                    plt.title("SayÄ±sal DeÄŸiÅŸkenlerin Pearson Korelasyon Matrisi Heatmap")
                    st.pyplot(fig)



                # SayÄ±sal deÄŸiÅŸkenleri seÃ§
                numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns

                # BaÄŸÄ±msÄ±z deÄŸiÅŸkeni seÃ§
                independent_variable = st.selectbox("BaÄŸÄ±msÄ±z DeÄŸiÅŸkeni SeÃ§iniz", numerical_columns)

                # BaÄŸÄ±mlÄ± deÄŸiÅŸkeni seÃ§
                dependent_variable = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§iniz", numerical_columns)

                # Scatter plot ve lineer regresyon Ã§izimi
                plt.figure(figsize=(10, 6))
                scatter_plot = sns.lmplot(x=independent_variable, y=dependent_variable, data=data, height=6, aspect=1.5, line_kws={'color': 'red'})
                plt.title(f"{dependent_variable} vs {independent_variable} - Scatter Plot with Regression Line")
                st.pyplot(scatter_plot.fig)

    
    
    
elif page == "Z Testi":
    import streamlit as st
    import pandas as pd
    import numpy as np
    from scipy.stats import norm
    import requests
    from io import BytesIO


    def main():
        st.title("Z Testi ğŸ“Š")

        # Veri setini yÃ¼kle
        allowed_formats = ["csv", "txt", "xls", "xlsx"]
        upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz", type=allowed_formats)

        if upload is not None:
            if "csv" in upload.name.lower():
                data = pd.read_csv(upload)
            elif "txt" in upload.name.lower():
                data = pd.read_csv(upload, delimiter='\t')
            elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
                data = pd.read_excel(upload)

            st.write("Veri Ã–rneÄŸi:")
            st.write(data)

            # Z-testi iÃ§in gereken bilgilerin giriÅŸi
            st.subheader("Z-Testi Parametreleri")
            if not data.empty:
                mu_default = float(data.mean().values[0])
                sigma_default = float(data.std().values[0])
                sample_mean_min = float(data.min().values[0])
                sample_mean_max = float(data.max().values[0])
                n_default = min(max(30, len(data)), 100)
            else:
                mu_default = 0.0
                sigma_default = 1.0
                sample_mean_min = None
                sample_mean_max = None
                n_default = 30
            
            mu = st.number_input("PopÃ¼lasyon OrtalamasÄ± (Î¼)", value=mu_default)
            sigma = st.number_input("PopÃ¼lasyon Standart SapmasÄ± (Ïƒ)", value=sigma_default)
            sample_mean = st.number_input("Ã–rneklem OrtalamasÄ±", value=mu_default)
            n = st.number_input("Ã–rneklem BÃ¼yÃ¼klÃ¼ÄŸÃ¼ (n)", value=n_default)

            # Z-testi istatistiÄŸinin hesaplanmasÄ±
            z_stat = (sample_mean - mu) / (sigma / np.sqrt(n))

            # P-deÄŸeri hesaplanmasÄ±
            p_value = 2 * (1 - norm.cdf(np.abs(z_stat)))

            # SonuÃ§larÄ±n gÃ¶sterilmesi
            st.subheader("Z-Testi SonuÃ§larÄ±")
            st.write("Z-istatistiÄŸi:", z_stat)
            st.write("P-deÄŸeri:", p_value)

    if __name__ == "__main__":
        main()

    


    
elif page == "T Testi":
    import streamlit as st
    import pandas as pd
    import numpy as np
    import plotly.express as px
    import plotly.graph_objects as go
    from scipy import stats
    import numpy as np




    def perform_normality_tests_independent(data, dependent_variable, independent_variable):
        group_names = data[independent_variable].unique()
        shapiro_p_values = {}
        ks_p_values = {}
        for group in group_names:
            group_data = data[data[independent_variable] == group][dependent_variable]
            _, shapiro_p_value = stats.shapiro(group_data)
            _, ks_p_value = stats.kstest(group_data, 'norm')
            shapiro_p_values[group] = shapiro_p_value
            ks_p_values[group] = ks_p_value
        return shapiro_p_values, ks_p_values


    def perform_normality_tests(data, independent_variables):
        shapiro_p_values = {}
        ks_p_values = {}
        for variable in independent_variables:
            _, shapiro_p_value = stats.shapiro(data[variable])
            _, ks_p_value = stats.kstest(data[variable], 'norm')
            shapiro_p_values[variable] = shapiro_p_value
            ks_p_values[variable] = ks_p_value
        return shapiro_p_values, ks_p_values

    def perform_one_sample_t_test(data, column, null_hypothesis_value):
        t_statistic, p_value = stats.ttest_1samp(data[column], null_hypothesis_value)
        return t_statistic, p_value

    def perform_independent_t_test(data, test_variables, grouping_variable, group1, group2, confidence_level):
        group1_data = data[data[grouping_variable] == group1][test_variables]
        group2_data = data[data[grouping_variable] == group2][test_variables]
        
        statistic, levene_p_value = stats.levene(group1_data.squeeze(), group2_data.squeeze())
        
        alpha = 1 - confidence_level / 100
        if levene_p_value > alpha:
            t_statistic, p_value = stats.ttest_ind(group1_data.squeeze(), group2_data.squeeze(), equal_var=True)
            var_assumption = "Homojen"
        else:
            t_statistic, p_value = stats.ttest_ind(group1_data.squeeze(), group2_data.squeeze(), equal_var=False)
            var_assumption = "Homojen DeÄŸil"
        return t_statistic, p_value, var_assumption, levene_p_value

    def perform_dependent_t_test(data, variable1, variable2, confidence_level):
        t_statistic, p_value = stats.ttest_rel(data[variable1], data[variable2])
        return t_statistic, p_value

    def descriptive_statistics(data):
        return data.describe()

    st.title("T Testi ğŸ“Š")
    st.subheader("Tek Ã–rneklem T Testi")
    st.write("Tek Ã¶rneklem t-testi, bir popÃ¼lasyonun ortalamasÄ± hakkÄ±nda bir tahmin yapmak veya karÅŸÄ±laÅŸtÄ±rmak iÃ§in kullanÄ±lÄ±r.")

    st.subheader("Ä°ki Ã–rneklem BaÄŸÄ±msÄ±z T Testi")
    st.write(" Ä°ki Ã¶rneklem baÄŸÄ±msÄ±z t-testi, iki farklÄ± grup arasÄ±ndaki ortalama farkÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmak iÃ§in kullanÄ±lÄ±r. Bu gruplar birbirinden baÄŸÄ±msÄ±zdÄ±r, yani bir gruptaki gÃ¶zlemler diÄŸer gruptaki gÃ¶zlemlerden baÄŸÄ±msÄ±zdÄ±r.")

    st.subheader("Ä°ki Ã–rneklem BaÄŸÄ±mlÄ± T Testi")
    st.write(" Ä°ki Ã¶rneklem baÄŸÄ±mlÄ± t-testi, aynÄ± bireylerin iki farklÄ± zaman noktasÄ±nda alÄ±nan Ã¶lÃ§Ã¼mleri arasÄ±ndaki ortalama farkÄ± karÅŸÄ±laÅŸtÄ±rmak iÃ§in kullanÄ±lÄ±r. Bu Ã¶lÃ§Ã¼mler arasÄ±ndaki iliÅŸki dolayÄ±sÄ±yla baÄŸÄ±mlÄ±lÄ±k vardÄ±r.")




    # Veri setini yÃ¼kle
    allowed_formats = ["csv", "txt", "xls", "xlsx"]
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz", type=allowed_formats)

    if upload is not None:
        if "csv" in upload.name.lower():
            data = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            data = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            data = pd.read_excel(upload)

        if data is not None:  # Veri yÃ¼klenirse devam et
            # Verinin Ã¶nizlemesini gÃ¶ster
            st.subheader("YÃ¼klenilen Veri Seti")
            st.write(data)

            # Betimsel Ä°statistikler
            st.subheader("Betimsel Ä°statistikler")
            st.write(data.describe())

            
            # Hipotez testi seÃ§imi
            test_type = st.selectbox('Hipotez Testi TÃ¼rÃ¼ SeÃ§in:', ['-', 'Tek Ã–rneklem T Testi', 'BaÄŸÄ±msÄ±z Ã–rneklem T Testi', 'BaÄŸÄ±mlÄ± Ã–rneklem T Testi'])
            
            if test_type != '-':
                # GÃ¼venilirlik dÃ¼zeyini al
                confidence_level = st.slider("GÃ¼venilirlik DÃ¼zeyini SeÃ§in:", min_value=1, max_value=99, value=95, step=1)

                if test_type == 'Tek Ã–rneklem T Testi':
                    st.header('Tek Ã–rneklem T Testi')
                    sample_column = st.selectbox('Ã–rnek veri sÃ¼tunu seÃ§in:', data.columns)
                    null_hypothesis_value = st.number_input('Test deÄŸerini girin:')
                    t_statistic, p_value = perform_one_sample_t_test(data, sample_column, null_hypothesis_value)
                    st.write('T Ä°statistiÄŸi:', t_statistic)
                    st.write('P DeÄŸeri(Significance):', p_value)
                    alpha = 1 - confidence_level / 100
                    if p_value < alpha:
                        st.write("H0 reddedilir.")
                    else:
                        st.write("H0 kabul edilir.")


                
                if test_type == 'BaÄŸÄ±msÄ±z Ã–rneklem T Testi':
                    st.subheader('BaÄŸÄ±msÄ±z Ã–rneklem T Testi')
                    
                    # Test deÄŸiÅŸkenlerini seÃ§
                    test_variables = st.multiselect('Test Variable(s) seÃ§in:', options=data.columns)
                    grouping_variable = st.selectbox('Grouping Variable seÃ§in:', options=data.select_dtypes(include=['object']).columns)

                    # GruplarÄ± otomatik olarak belirle
                    group_names = data[grouping_variable].unique().tolist()
                    group1 = group_names[0]
                    group2 = group_names[1]

                    # Normal daÄŸÄ±lÄ±ma uygunluk testleri yap
                    shapiro_p_values, ks_p_values = perform_normality_tests_independent(data, test_variables, grouping_variable)

                    # SonuÃ§larÄ± gÃ¶ster
                    st.subheader("Normal DaÄŸÄ±lÄ±ma Uygunluk Testi")
                    st.write("BaÄŸÄ±mlÄ± DeÄŸiÅŸken:", test_variables[0])
                    st.write("BaÄŸÄ±mlÄ± DeÄŸiÅŸken BakÄ±mÄ±ndan Ä°ncelenen DeÄŸiÅŸken:", grouping_variable)
                    st.write("---")
                    st.write("Shapiro-Wilk Testi P DeÄŸerleri:")
                    for group, p_value in shapiro_p_values.items():
                        st.write(f"{group}: {np.format_float_positional(p_value, precision=4)}")
                        
                    st.write("---")
                    
                    st.write("Kolmogorov-Smirnov Testi P DeÄŸerleri:")
                    for group, p_value in ks_p_values.items():
                        st.write(f"{group}: {float(p_value):.4f}")
                    st.write("---")
                    st.write("Shapiro-Wilk testi, Ã¶rneklem bÃ¼yÃ¼klÃ¼ÄŸÃ¼ yaklaÅŸÄ±k 50 veya daha az olduÄŸunda daha gÃ¼venilir sonuÃ§lar verir. ")
                    st.write("Kolmogorov-Smirnov testi, Ã¶rneklem bÃ¼yÃ¼klÃ¼ÄŸÃ¼ 50'den bÃ¼yÃ¼kse daha gÃ¼venilir sonuÃ§lar verir.") 
                    st.write("---")
                    # BaÄŸÄ±msÄ±z Ã–rnekler T Testi
                    t_statistic, p_value, var_assumption, levene_p_value = perform_independent_t_test(data, test_variables, grouping_variable, group1, group2, confidence_level)
                    if levene_p_value > 0.05:
                        st.write('Levene testi p deÄŸeri:', np.format_float_positional(levene_p_value, precision=4), 'olduÄŸundan varyanslar homojen.')
                        st.write("---")
                        st.write('BaÄŸÄ±msÄ±z Ã–rnekler T Testi Ä°statistiÄŸi:', np.format_float_positional(t_statistic, precision=4))
                        st.write('P DeÄŸeri:', np.format_float_positional(p_value, precision=4))
                    else:
                        st.write('Levene Testi p deÄŸeri:', np.format_float_positional(levene_p_value, precision=4), 'olduÄŸundan varyanslar homojen deÄŸil.')
                        st.write('Welch\'s T Testi Ä°statistiÄŸi ve P DeÄŸeri:', np.format_float_positional(t_statistic, precision=4), np.format_float_positional(p_value, precision=4))
                    
                    st.write("---")
                    
                    # Grafiksel sunumlar
                    fig = px.box(data, x=grouping_variable, y=test_variables[0], title='Gruplar ArasÄ±ndaki DaÄŸÄ±lÄ±m')
                    fig.update_layout(width=1000, height=600)  # GeniÅŸlik ve yÃ¼ksekliÄŸi artÄ±rma
                    st.plotly_chart(fig)




                elif test_type == 'BaÄŸÄ±mlÄ± Ã–rneklem T Testi':
                    st.subheader('BaÄŸÄ±mlÄ± Ã–rneklem T Testi')
                    variable1 = st.selectbox('DeÄŸiÅŸken 1 seÃ§in:', options=data.columns)
                    variable2 = st.selectbox('DeÄŸiÅŸken 2 seÃ§in:', options=data.columns)

                    # Kolmogorov-Smirnov ve Shapiro-Wilk testlerini gerÃ§ekleÅŸtir
                    independent_variables = [variable1, variable2]
                    shapiro_p_values, ks_p_values = perform_normality_tests(data, independent_variables)

                    st.write("Ä°ncelenen DeÄŸiÅŸkenler:", independent_variables)
                    st.write("Shapiro-Wilk Testi P DeÄŸerleri:")
                    for variable, p_value in shapiro_p_values.items():
                        st.write(f"{variable}: {p_value:.4f}")
                    st.write("---")
                    st.write("Kolmogorov-Smirnov Testi P DeÄŸerleri:")
                    for variable, p_value in ks_p_values.items():
                        st.write(f"{variable}: {p_value:.4f}")
                    st.write("---")
                    st.write("Shapiro-Wilk testi, Ã¶rneklem bÃ¼yÃ¼klÃ¼ÄŸÃ¼ yaklaÅŸÄ±k 50 veya daha az olduÄŸunda daha gÃ¼venilir sonuÃ§lar verir. ")
                    st.write("Kolmogorov-Smirnov testi, Ã¶rneklem bÃ¼yÃ¼klÃ¼ÄŸÃ¼ 50'den bÃ¼yÃ¼kse daha gÃ¼venilir sonuÃ§lar verir.")
                    st.write("---")
                    st.write(data.describe())
                    st.write("---")
                    # BaÄŸÄ±mlÄ± Ã–rneklem T Testi
                    t_statistic, p_value = perform_dependent_t_test(data, variable1, variable2, confidence_level)
                    st.write('T Ä°statistiÄŸi:', t_statistic)
                    st.write('P DeÄŸeri(Significance):', p_value)
                    alpha = 1 - confidence_level / 100
                    if p_value < alpha:
                        st.write("H0 reddedilir.")
                    else:
                        st.write("H0 kabul edilir.")

    
    

    
elif page == "Basit DoÄŸrusal Regresyon":
    import streamlit as st
    import pandas as pd
    import matplotlib.pyplot as plt
    import numpy as np
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import mean_squared_error, r2_score
    import statsmodels.formula.api as smf

    # Streamlit baÅŸlÄ±ÄŸÄ±
    st.title("Basit DoÄŸrusal Regresyon ğŸ“ˆ")

    # Veri yÃ¼kleme iÅŸlemi
    import streamlit as st
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import mean_squared_error, mean_absolute_error
    import statsmodels.formula.api as smf

    # Veri yÃ¼kleme iÅŸlemi
    allowed_formats = ["csv", "txt", "xls", "xlsx"]
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

    if upload is not None:
        if "csv" in upload.name.lower():
            df = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            df = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            df = pd.read_excel(upload)

        st.write(df)
        st.write("---")
        # BaÄŸÄ±mlÄ± ve baÄŸÄ±msÄ±z deÄŸiÅŸken seÃ§imi
        st.subheader("BaÄŸÄ±mlÄ± ve BaÄŸÄ±msÄ±z DeÄŸiÅŸken SeÃ§imi")
        X_col = st.selectbox("BaÄŸÄ±msÄ±z DeÄŸiÅŸkeni SeÃ§in", options=df.columns)
        y_col = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§in", options=df.columns)

        # EÄŸitim-test veri seti bÃ¶lme oranÄ±
        test_size = st.slider("Test Veri Seti Boyutu (%)", 0.1, 0.5, 0.2, 0.05)

        # Random state deÄŸerini kullanÄ±cÄ±dan al
        random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
        st.write("---")
        # Model eÄŸitimi
        X = df[[X_col]].values
        y = df[y_col].values
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

        lr = LinearRegression()
        lr.fit(X_train, y_train)

        # Tahminlerin hesaplanmasÄ±
        y_pred = lr.predict(X_test)

        # Model performansÄ± Ã¶lÃ§Ã¼mleri (MSE, RMSE, MAE)
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        
        # Model performansÄ± Ã¶lÃ§Ã¼mlerinin gÃ¶rÃ¼ntÃ¼lenmesi
        st.subheader("Model PerformansÄ±")
        st.write(f"Mean Squared Error (MSE): {mse}")
        st.write(f"Root Mean Squared Error (RMSE): {rmse}")
        st.write(f"Mean Absolute Error (MAE): {mae}")
        st.write("---")

        # Model performansÄ±
        reg_summary = smf.ols(f"{y_col} ~ {X_col}", df).fit()
        st.write(reg_summary.summary())
        st.write("---")
        # Model parametrelerinin denklemi
        st.subheader("Tahmin Edilen Modelin Denklemi")
        st.latex(rf"Y = {lr.intercept_} + {lr.coef_[0]} \times X")

        # Model parametreleri
        st.subheader("Tahmin Edilen Modelin Parametreleri")
        st.write(f"Sabit KatsayÄ± (B0): {lr.intercept_}")
        st.write(f"EÄŸim KatsayÄ±sÄ± (B1): {lr.coef_[0]}")
        st.write("---")
        
        # Tahmin
        st.subheader("Tahmin")
        input_value = st.number_input("Tahmin etmek istediÄŸiniz deÄŸeri girin:")
        prediction = lr.predict([[input_value]])
        st.write("Tahmini DeÄŸer:", prediction)

            
       
       
    
elif page == "Ã‡oklu DoÄŸrusal Regresyon":
    import streamlit as st
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import mean_squared_error, r2_score
    import statsmodels.formula.api as smf

    # Streamlit baÅŸlÄ±ÄŸÄ±
    st.title("Ã‡oklu DoÄŸrusal Regresyon ğŸ“ŠğŸ“ˆ")

    # Veri yÃ¼kleme iÅŸlemi
    allowed_formats = ["csv", "txt", "xls", "xlsx"]
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

    if upload is not None:
        if "csv" in upload.name.lower():
            df = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            df = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            df = pd.read_excel(upload)

        st.write(df)
        st.write("---")
        # BaÄŸÄ±mlÄ± ve baÄŸÄ±msÄ±z deÄŸiÅŸken seÃ§imi
        st.subheader("BaÄŸÄ±mlÄ± ve BaÄŸÄ±msÄ±z DeÄŸiÅŸken SeÃ§imi")
        X_cols = st.multiselect("BaÄŸÄ±msÄ±z DeÄŸiÅŸkenleri SeÃ§in", options=df.columns)
        y_col = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§in", options=df.columns)

        # EÄŸitim-test veri seti bÃ¶lme oranÄ±
        test_size = st.slider("Test Veri Seti Boyutu (%)", 0.1, 0.5, 0.2, 0.05)

        # Random state deÄŸerini kullanÄ±cÄ±dan al
        random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
        st.write("---")
        # Model eÄŸitimi
        X = df[X_cols].values
        y = df[y_col].values
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

        lr = LinearRegression()
        lr.fit(X_train, y_train)

        # Model performansÄ± (CV Ã¶ncesi)
        st.subheader("Model PerformansÄ± (CV Ã–ncesi)")
        train_rmse = np.sqrt(mean_squared_error(y_train, lr.predict(X_train)))
        test_rmse = np.sqrt(mean_squared_error(y_test, lr.predict(X_test)))
        train_r2_score = lr.score(X_train, y_train)
        st.write("EÄŸitim Seti RMSE:", train_rmse)
        st.write("Test Seti RMSE:", test_rmse)
        st.write("EÄŸitim Seti R^2 Score:", train_r2_score)
        st.write("---")

        # Ã‡apraz doÄŸrulama sonrasÄ± skorlarÄ± hesapla
        cv_r2_scores = cross_val_score(lr, X_train, y_train, cv=10, scoring='r2')
        cv_rmse_train_scores = np.sqrt(-cross_val_score(lr, X_train, y_train, cv=10, scoring='neg_mean_squared_error'))
        cv_rmse_test_scores = np.sqrt(-cross_val_score(lr, X_test, y_test, cv=10, scoring='neg_mean_squared_error'))

        cv_r2_score = cv_r2_scores.mean()
        cv_rmse_train = cv_rmse_train_scores.mean()
        cv_rmse_test = cv_rmse_test_scores.mean()

        # CV Ã¶ncesi ve sonrasÄ± sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±rma
        st.subheader("CV Ã–ncesi ve SonrasÄ± KarÅŸÄ±laÅŸtÄ±rma")

        # Tabloyu oluÅŸturmak iÃ§in verileri birleÅŸtirme
        comparison_data = {
            "": ["EÄŸitim Ã–ncesi CV", "EÄŸitim SonrasÄ± CV"],
            "RMSE (EÄŸitim Seti)": [train_rmse, cv_rmse_train],
            "RMSE (Test Seti)": [test_rmse, cv_rmse_test],
            "R^2 Score (EÄŸitim Seti)": [train_r2_score, cv_r2_score]
        }

        # DataFrame oluÅŸturma
        comparison_df = pd.DataFrame(comparison_data)

        # SonuÃ§larÄ± tablo ÅŸeklinde gÃ¶sterme
        st.write(comparison_df)

        # Model performansÄ±
        st.subheader("Model PerformansÄ±")
        reg_summary = smf.ols(f"{y_col} ~ {' + '.join(X_cols)}", df).fit()
        st.write(reg_summary.summary())
        st.write("---")
        # Model parametrelerinin denklemi
        st.subheader("Tahmin Edilen Modelin Denklemi")
        equation = f"{lr.intercept_}"
        for i, col in enumerate(X_cols):
            equation += f" + ({lr.coef_[i]} * {col})"
        st.latex(rf"Y = {equation}")

        # Model parametreleri
        st.subheader("Tahmin Edilen Modelin Parametreleri")
        st.write(f"Sabit KatsayÄ± (B0): {lr.intercept_}")
        for i, col in enumerate(X_cols):
            st.write(f"EÄŸim KatsayÄ±sÄ± ({col}): {lr.coef_[i]}")
        st.write("---")
        # Tahmin
        st.subheader("Tahmin")
        input_values = []
        for col in X_cols:
            input_val = st.number_input(f"{col} deÄŸerini girin:")
            input_values.append(input_val)
        prediction = lr.predict([input_values])
        st.write("Tahmini DeÄŸer:", prediction[0])

    
    
    
elif page == "Fisher's Exact Testi":
    import streamlit as st
    import pandas as pd
    from scipy.stats import fisher_exact

    def main():
        st.title("Fisher's Exact ğŸ“")

        allowed_formats = ["csv", "txt", "xls", "xlsx"]
        upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

        if upload is not None:
            if "csv" in upload.name.lower():
                data = pd.read_csv(upload)
            elif "txt" in upload.name.lower():
                data = pd.read_csv(upload, delimiter='\t')
            elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
                data = pd.read_excel(upload)


            st.write("YÃ¼klenen Veri Seti:")
            st.write(data)

            # KullanÄ±cÄ±dan kategorik deÄŸiÅŸken seÃ§imi al
            st.subheader("Fisher's Exact Testi iÃ§in DeÄŸiÅŸkenlerin SeÃ§imi")
            variable1 = st.selectbox("LÃ¼tfen birinci kategorik deÄŸiÅŸkeni seÃ§in:", data.columns)
            variable2 = st.selectbox("LÃ¼tfen ikinci kategorik deÄŸiÅŸkeni seÃ§in:", data.columns)

            # Fisher's Exact testinin yapÄ±lmasÄ± iÃ§in uygun tabloyu oluÅŸtur
            contingency_table = pd.crosstab(data[variable1], data[variable2])

            if contingency_table.shape == (2, 2):
                # Fisher's Exact testi sonuÃ§larÄ±nÄ± gÃ¶ster
                st.subheader("Fisher's Exact Testi SonuÃ§larÄ±")
                oddsratio, p_value = fisher_exact(contingency_table)
                st.write("Odds Ratio:", oddsratio)
                st.write("P-deÄŸeri:", p_value)

                # SonuÃ§larÄ±n yorumlanmasÄ±
                if p_value < 0.05:
                    st.write("P-deÄŸeri 0.05 anlamlÄ±lÄ±k dÃ¼zeyinden kÃ¼Ã§Ã¼k olduÄŸu iÃ§in, deÄŸiÅŸkenler arasÄ±nda istatistiksel olarak anlamlÄ± bir iliÅŸki vardÄ±r.")
                else:
                    st.write("P-deÄŸeri 0.05 anlamlÄ±lÄ±k dÃ¼zeyinden bÃ¼yÃ¼k olduÄŸu iÃ§in, deÄŸiÅŸkenler arasÄ±nda istatistiksel olarak anlamlÄ± bir iliÅŸki yoktur.")
            else:
                st.write("Fisher's Exact Testi iÃ§in uygun tablo oluÅŸturulamadÄ±. LÃ¼tfen verilerinizi kontrol edin ve tekrar deneyin.")

    if __name__ == "__main__":
        main()

    
    
    
elif page == "Ki-Kare Testi":
    import streamlit as st
    import pandas as pd
    from scipy.stats import chi2_contingency

    def main():
        st.title("Ki-Kare Testi ğŸ“Š")

        # Veri setini yÃ¼kle
        allowed_formats = ["csv", "txt", "xls", "xlsx"]
        upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

        if upload is not None:
            if "csv" in upload.name.lower():
                data = pd.read_csv(upload)
            elif "txt" in upload.name.lower():
                data = pd.read_csv(upload, delimiter='\t')
            elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
                data = pd.read_excel(upload)

            st.write("Veri Seti")
            st.write(data)
        
            
            # Ki-kare testi iÃ§in kategorik sÃ¼tunlarÄ±n seÃ§imi
            st.subheader("Ki-kare Testi iÃ§in Kategorik SÃ¼tunlar")
            categorical_columns = st.multiselect("LÃ¼tfen kategorik sÃ¼tunlarÄ± seÃ§in:", data.columns)

            if len(categorical_columns) > 1:
                # Frekans tablosunu oluÅŸtur
                contingency_table = pd.crosstab(data[categorical_columns[0]], data[categorical_columns[1]])

                # Ki-kare testinin yapÄ±lmasÄ±
                st.subheader("Ki-kare Testi SonuÃ§larÄ±")
                chi2_result = chi2_contingency(contingency_table)
                st.write("Ki-kare Ä°statistiÄŸi:", chi2_result[0])
                st.write("P-deÄŸeri:", chi2_result[1])
            else:
                st.write("LÃ¼tfen en az 2 kategorik sÃ¼tun seÃ§in.")

    if __name__ == "__main__":
        main()

    
    
    
elif page == "Kruskal-Wallis Testi":
    import streamlit as st
    import pandas as pd
    from scipy.stats import kruskal

    def main():
        st.title("Kruskal Wallis Testi ğŸ“Š")

        # Veri setini yÃ¼kle
        allowed_formats = ["csv", "txt", "xls", "xlsx"]
        upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

        if upload is not None:
            if "csv" in upload.name.lower():
                data = pd.read_csv(upload)
            elif "txt" in upload.name.lower():
                data = pd.read_csv(upload, delimiter='\t')
            elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
                data = pd.read_excel(upload)

            st.write("Veri Ã–rneÄŸi:")
            st.write(data)

            # Kruskal-Wallis testi iÃ§in grup seÃ§imi
            st.subheader("Kruskal-Wallis Testi iÃ§in Gruplar")
            groups = st.multiselect("LÃ¼tfen gruplarÄ± seÃ§in:", data.columns)

            if len(groups) >= 3:
                # Kruskal-Wallis testinin yapÄ±lmasÄ±
                st.subheader("Kruskal-Wallis Testi SonuÃ§larÄ±")
                stat, p_value = kruskal(*[data[group] for group in groups])
                st.write("Test Ä°statistiÄŸi:", stat)
                st.write("P-deÄŸeri:", p_value)

                # SonuÃ§larÄ±n yorumlanmasÄ±
                if p_value < 0.05:
                    st.write("P-deÄŸeri 0.05 anlamlÄ±lÄ±k dÃ¼zeyinden kÃ¼Ã§Ã¼k olduÄŸu iÃ§in, gruplar arasÄ±nda istatistiksel olarak anlamlÄ± bir fark vardÄ±r.")
                else:
                    st.write("P-deÄŸeri 0.05 anlamlÄ±lÄ±k dÃ¼zeyinden bÃ¼yÃ¼k olduÄŸu iÃ§in, gruplar arasÄ±nda istatistiksel olarak anlamlÄ± bir fark yoktur.")
            else:
                st.write("LÃ¼tfen en az Ã¼Ã§ grup seÃ§in.")

    if __name__ == "__main__":
        main()

    
    
elif page == "Wilcoxon Ä°ÅŸaretli SÄ±ralar Testi":
    import streamlit as st
    import pandas as pd
    from scipy.stats import wilcoxon

    def main():
        st.title("Wilcoxon Ä°ÅŸaretli SÄ±ralar Testi ğŸ“ˆ")

        # Veri setini yÃ¼kle
        allowed_formats = ["csv", "txt", "xls", "xlsx"]
        upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

        if upload is not None:
            if "csv" in upload.name.lower():
                data = pd.read_csv(upload)
            elif "txt" in upload.name.lower():
                data = pd.read_csv(upload, delimiter='\t')
            elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
                data = pd.read_excel(upload)

            st.write("Veri Ã–rneÄŸi:")
            st.write(data.head())

            # Wilcoxon testi iÃ§in grup seÃ§imi
            st.subheader("Wilcoxon Testi iÃ§in Gruplar")
            group1 = st.selectbox("LÃ¼tfen birinci grubu seÃ§in:", data.columns)
            group2 = st.selectbox("LÃ¼tfen ikinci grubu seÃ§in:", data.columns)

            # Wilcoxon testinin yapÄ±lmasÄ±
            st.subheader("Wilcoxon Testi SonuÃ§larÄ±")
            stat, p_value = wilcoxon(data[group1], data[group2])
            st.write("Test Ä°statistiÄŸi:", stat)
            st.write("P-deÄŸeri:", p_value)

            # SonuÃ§larÄ±n yorumlanmasÄ±
            if p_value < 0.05:
                st.write("P-deÄŸeri 0.05 anlamlÄ±lÄ±k dÃ¼zeyinden kÃ¼Ã§Ã¼k olduÄŸu iÃ§in, gruplar arasÄ±nda istatistiksel olarak anlamlÄ± bir fark vardÄ±r.")
            else:
                st.write("P-deÄŸeri 0.05 anlamlÄ±lÄ±k dÃ¼zeyinden bÃ¼yÃ¼k olduÄŸu iÃ§in, gruplar arasÄ±nda istatistiksel olarak anlamlÄ± bir fark yoktur.")

    if __name__ == "__main__":
        main()

    
    
elif page == "CART (Classification and Regression Trees)":
    
    st.title("CART (SÄ±nÄ±flandÄ±rma ve Regresyon AÄŸaÃ§larÄ±) ğŸ“ŠğŸ”")
    import streamlit as st
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split
    from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, mean_squared_error, mean_absolute_error
    from sklearn.metrics import confusion_matrix
    import matplotlib.pyplot as plt
    from sklearn.model_selection import GridSearchCV

    # Ä°zin verilen dosya formatlarÄ±
    allowed_formats = ["csv", "txt", "xls", "xlsx"]

    # KullanÄ±cÄ±dan veri yÃ¼kleme
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

    # Veri yÃ¼klendi mi kontrolÃ¼ ve iÅŸlemler
    if upload is not None:
        # YÃ¼klenen dosyanÄ±n formatÄ±na gÃ¶re veriyi okuma
        if "csv" in upload.name.lower():
            df = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            df = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            df = pd.read_excel(upload)
        
        
        
        # SÄ±nÄ±flandÄ±rma veya regresyon seÃ§imi
        problem_type = st.radio("Problemi SeÃ§in:", ("SÄ±nÄ±flandÄ±rma", "Regresyon"))

        # SÄ±nÄ±flandÄ±rma iÅŸlemleri
        if problem_type == "SÄ±nÄ±flandÄ±rma":
            # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri seÃ§me
            st.subheader("BaÄŸÄ±msÄ±z ve BaÄŸÄ±mlÄ± DeÄŸiÅŸkenleri SeÃ§me")
            X_options = df.select_dtypes(include=['number', 'float', 'int']).columns.tolist()  # SayÄ±sal deÄŸiÅŸkenleri seÃ§
            y_options = df.select_dtypes(include=['object', 'number', 'float', 'int']).columns.tolist()  # Kategorik deÄŸiÅŸkenleri seÃ§
            X_selected = st.multiselect("BaÄŸÄ±msÄ±z DeÄŸiÅŸkenleri SeÃ§in", X_options)
            y_selected = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§in", y_options)

            # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±rma
            X = df[X_selected]
            y = df[y_selected]

            # Test verisi yÃ¼zdesi ve random state deÄŸeri giriÅŸi
            test_size = st.slider("Test verisi yÃ¼zdesi:", 0.1, 0.5, 0.2, 0.01)
            random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
            st.write("----")
            
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # CART sÄ±nÄ±flandÄ±rma modeli oluÅŸturma ve eÄŸitme
            cart_model = DecisionTreeClassifier().fit(X_train, y_train)
            y_pred = cart_model.predict(X_test)

            # AUC-ROC
            st.subheader("ROC EÄŸrisi ve AUC DeÄŸeri")
            cart_roc_auc = roc_auc_score(y_test, cart_model.predict_proba(X_test)[:, 1])
            fpr, tpr, thresholds = roc_curve(y_test, cart_model.predict_proba(X_test)[:,1])

            fig, ax = plt.subplots()
            ax.plot(fpr, tpr, label='AUC (area = %0.2f)' % cart_roc_auc)
            ax.plot([0, 1], [0, 1],'r--')
            ax.set_xlim([0.0, 1.0])
            ax.set_ylim([0.0, 1.05])
            ax.set_xlabel('False Positive OranÄ±')
            ax.set_ylabel('True Positive OranÄ±')
            ax.set_title('ROC')
            st.pyplot(fig)

            st.write("AUC DeÄŸeri:", cart_roc_auc)

            # DoÄŸruluk (Accuracy)
            accuracy = accuracy_score(y_test, y_pred)
            st.write("DoÄŸruluk (Accuracy):", accuracy)

            # Hassasiyet (Precision)
            precision = precision_score(y_test, y_pred)
            st.write("Hassasiyet (Precision):", precision)

            # Geri Ã‡aÄŸÄ±rma (Recall)
            recall = recall_score(y_test, y_pred)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall):", recall)

            # F1-Skor
            f1 = f1_score(y_test, y_pred)
            st.write("F1-Skor:", f1)

            # Confusion Matrix
            st.subheader("KarmaÅŸÄ±klÄ±k Matrisi:")
            conf_matrix = confusion_matrix(y_test, y_pred)
            conf_matrix_df = pd.DataFrame(conf_matrix, 
                                        columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                        index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
            st.write(conf_matrix_df)


        # Regresyon iÅŸlemleri
        elif problem_type == "Regresyon":
            # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri seÃ§me
            st.subheader("BaÄŸÄ±msÄ±z ve BaÄŸÄ±mlÄ± DeÄŸiÅŸkenleri SeÃ§me")
            X_options = df.select_dtypes(include=['number', 'float', 'int']).columns.tolist()  
            y_options = df.select_dtypes(include=['number', 'float']).columns.tolist()  
            X_selected = st.multiselect("BaÄŸÄ±msÄ±z DeÄŸiÅŸkenleri SeÃ§in", X_options)
            y_selected = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§in", y_options)

            # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±rma
            X = df[X_selected]
            y = df[y_selected]

            # Veri kÃ¼mesini eÄŸitim ve test kÃ¼melerine ayÄ±rma
            test_size = st.slider("Test verisi yÃ¼zdesi:", 0.1, 0.5, 0.2, 0.01)
            random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
            st.write("----")

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # CART regresyon modeli oluÅŸturma
            cart_model = DecisionTreeRegressor()
            cart_model.fit(X_train, y_train)

            y_pred = cart_model.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            rmse = mean_squared_error(y_test, y_pred, squared=False)
            st.write("Model ortalama kare hatasÄ± (MSE):", mse)
            st.write("Model ortalama mutlak hatasÄ± (MAE):", mae)
            st.write("Model kÃ¶k ortalama kare hatasÄ± (RMSE):", rmse)

            # Model hiperparametre optimizasyonu
            cart_params = {
                'max_depth': [3, 5, 7],
                'min_samples_split': [2, 5, 10]
            }
            cart = DecisionTreeRegressor()
            cart_cv_model = GridSearchCV(cart, cart_params, cv=3, n_jobs=-1, verbose=2)
            cart_cv_model.fit(X_train, y_train)
            best_params = cart_cv_model.best_params_
            st.write("En iyi parametreler:", best_params)

            # Optimize edilmiÅŸ modeli kullanma
            cart_tuned = DecisionTreeRegressor(**best_params)
            cart_tuned.fit(X_train, y_train)
            y_pred_tuned = cart_tuned.predict(X_test)
            mse_tuned = mean_squared_error(y_test, y_pred_tuned)
            mae_tuned = mean_absolute_error(y_test, y_pred_tuned)
            rmse_tuned = mean_squared_error(y_test, y_pred_tuned, squared=False)
            st.write("Optimize edilmiÅŸ model ortalama kare hatasÄ± (MSE):", mse_tuned)
            st.write("Optimize edilmiÅŸ model ortalama mutlak hatasÄ± (MAE):", mae_tuned)
            st.write("Optimize edilmiÅŸ model kÃ¶k ortalama kare hatasÄ± (RMSE):", rmse_tuned)
    
    
    
elif page == "CatBoost":
    import streamlit as st
    import pandas as pd
    from sklearn.model_selection import train_test_split, GridSearchCV
    from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error,precision_score,recall_score, f1_score, roc_auc_score, confusion_matrix,roc_curve
    from catboost import CatBoostClassifier, CatBoostRegressor
    import matplotlib.pyplot as plt
    
    
    st.title("Catboost ğŸ”¢")
    # Ä°zin verilen dosya formatlarÄ±
    allowed_formats = ["csv", "txt", "xls", "xlsx"]

    # KullanÄ±cÄ±dan veri yÃ¼kleme
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

    # Veri yÃ¼klendi mi kontrolÃ¼ ve iÅŸlemler
    if upload is not None:
        if "csv" in upload.name.lower():
            df = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            df = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            df = pd.read_excel(upload)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri seÃ§me
        st.subheader("BaÄŸÄ±msÄ±z ve BaÄŸÄ±mlÄ± DeÄŸiÅŸkenleri SeÃ§me")
        X_options = df.select_dtypes(include=['number', 'float', 'int']).columns.tolist()  # SayÄ±sal deÄŸiÅŸkenleri seÃ§
        y_options = df.select_dtypes(include=['object', 'number', 'float', 'int']).columns.tolist()  # Kategorik deÄŸiÅŸkenleri seÃ§
        X_selected = st.multiselect("BaÄŸÄ±msÄ±z DeÄŸiÅŸkenleri SeÃ§in", X_options)
        y_selected = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§in", y_options)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±rma
        X = df[X_selected]
        y = df[y_selected]

        # Test verisi yÃ¼zdesi ve random state deÄŸeri giriÅŸi
        test_size = st.slider("Test verisi yÃ¼zdesi:", 0.1, 0.5, 0.2, 0.01)
        random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
        st.write("----")
        
        # SÄ±nÄ±flandÄ±rma veya regresyon seÃ§imi
        problem_type = st.radio("Problemi SeÃ§in:", ("SÄ±nÄ±flandÄ±rma", "Regresyon"))

        # SÄ±nÄ±flandÄ±rma iÅŸlemleri
        if problem_type == "SÄ±nÄ±flandÄ±rma":
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # CatBoost sÄ±nÄ±flandÄ±rma modeli oluÅŸturma ve eÄŸitme
            cat_model = CatBoostClassifier().fit(X_train, y_train)
            y_pred = cat_model.predict(X_test)


            # AUC-ROC
            st.subheader("ROC EÄŸrisi ve AUC DeÄŸeri")
            cat_roc_auc = roc_auc_score(y_test, cat_model.predict_proba(X_test)[:, 1])
            fpr, tpr, thresholds = roc_curve(y_test, cat_model.predict_proba(X_test)[:,1])

            fig, ax = plt.subplots()
            ax.plot(fpr, tpr, label='AUC (area = %0.2f)' % cat_roc_auc)
            ax.plot([0, 1], [0, 1],'r--')
            ax.set_xlim([0.0, 1.0])
            ax.set_ylim([0.0, 1.05])
            ax.set_xlabel('False Positive OranÄ±')
            ax.set_ylabel('True Positive OranÄ±')
            ax.set_title('ROC')
            st.pyplot(fig)

            st.write("AUC DeÄŸeri:", cat_roc_auc)

            # DoÄŸruluk (Accuracy)
            accuracy = accuracy_score(y_test, y_pred)
            st.write("DoÄŸruluk (Accuracy):", accuracy)

            # Hassasiyet (Precision)
            precision = precision_score(y_test, y_pred)
            st.write("Hassasiyet (Precision):", precision)

            # Geri Ã‡aÄŸÄ±rma (Recall)
            recall = recall_score(y_test, y_pred)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall):", recall)

            # F1-Skor
            f1 = f1_score(y_test, y_pred)
            st.write("F1-Skor:", f1)
            
            
            
            # Confusion Matrix
            st.subheader("KarmaÅŸÄ±klÄ±k Matrisi:")
            conf_matrix = confusion_matrix(y_test, y_pred)
            conf_matrix_df = pd.DataFrame(conf_matrix, 
                                        columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                        index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
            st.write(conf_matrix_df)

        # Regresyon iÅŸlemleri
        elif problem_type == "Regresyon":
            # Veri kÃ¼mesini eÄŸitim ve test kÃ¼melerine ayÄ±rma
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # CatBoost regresyon modeli oluÅŸturma
            cat_model = CatBoostRegressor().fit(X_train, y_train)
            y_pred = cat_model.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            rmse = mean_squared_error(y_test, y_pred, squared=False)
            st.write("Model ortalama kare hatasÄ± (MSE):", mse)
            st.write("Model ortalama mutlak hatasÄ± (MAE):", mae)
            st.write("Model kÃ¶k ortalama kare hatasÄ± (RMSE):", rmse)

            # Model hiperparametre optimizasyonu
            cat_params = {
                'iterations': [100, 500, 1000],
                'learning_rate': [0.01, 0.05, 0.1],
                'depth': [3, 5, 7]
            }
            cat = CatBoostRegressor()
            cat_cv_model = GridSearchCV(cat, cat_params, cv=5, n_jobs=-1, verbose=2)
            cat_cv_model.fit(X_train, y_train)
            best_params = cat_cv_model.best_params_
            st.write("En iyi parametreler:", best_params)

            # Optimize edilmiÅŸ modeli kullanma
            cat_tuned = CatBoostRegressor(**best_params)
            cat_tuned.fit(X_train, y_train)
            y_pred_tuned = cat_tuned.predict(X_test)
            mse_tuned = mean_squared_error(y_test, y_pred_tuned)
            mae_tuned = mean_absolute_error(y_test, y_pred_tuned)
            rmse_tuned = mean_squared_error(y_test, y_pred_tuned, squared=False)
            st.write("Optimize edilmiÅŸ model ortalama kare hatasÄ± (MSE):", mse_tuned)
            st.write("Optimize edilmiÅŸ model ortalama mutlak hatasÄ± (MAE):", mae_tuned)
            st.write("Optimize edilmiÅŸ model kÃ¶k ortalama kare hatasÄ± (RMSE):", rmse_tuned)


    
elif page == "Gaussian Naive Bayes":
    import streamlit as st
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.naive_bayes import GaussianNB
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,roc_curve, roc_auc_score
    from sklearn.model_selection import cross_val_score
    import matplotlib.pyplot as plt
    
    # Sayfa baÅŸlÄ±ÄŸÄ±
    st.title("Gaussian Naive Bayes ğŸ”¢")

    # Desteklenen dosya formatlarÄ±
    allowed_formats = ["csv", "txt", "xls", "xlsx"]

    # KullanÄ±cÄ±dan veri yÃ¼kleme
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyin", type=allowed_formats)

    # Veri yÃ¼klendi mi kontrolÃ¼ ve iÅŸlemler
    if upload is not None:
        # YÃ¼klenen dosyanÄ±n formatÄ±na gÃ¶re veriyi okuma
        if "csv" in upload.name.lower():
            df = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            df = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            df = pd.read_excel(upload)
        
        
        st.write("YÃ¼klenen Veri Seti:")
        st.write(df.head())

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri seÃ§me bÃ¶lÃ¼mÃ¼
        st.header("BaÄŸÄ±msÄ±z ve BaÄŸÄ±mlÄ± DeÄŸiÅŸkenleri SeÃ§me")
        X_cols = st.multiselect("LÃ¼tfen baÄŸÄ±msÄ±z deÄŸiÅŸkenleri seÃ§in", df.columns)
        y_col = st.selectbox("LÃ¼tfen baÄŸÄ±mlÄ± deÄŸiÅŸkeni seÃ§in", df.columns)
        st.write("----")
        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±rma
        X = df[X_cols]
        y = df[y_col]

        # Test verisi yÃ¼zdesi ve random state deÄŸeri giriÅŸi
        test_size = st.slider("Test verisi yÃ¼zdesi:", 0.1, 0.5, 0.2, 0.01)
        random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
        st.write("----")
        # Veri kÃ¼mesini eÄŸitim ve test kÃ¼melerine ayÄ±rma
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

        # Gaussian Naive Bayes modelini oluÅŸturma ve eÄŸitme
        st.header("Gaussian Naive Bayes Modeli OluÅŸturma")
        nb = GaussianNB()
        nb_model = nb.fit(X_train, y_train)

        # Modeli deÄŸerlendirme
        st.header("Model DeÄŸerlendirme")
        y_pred = nb_model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        st.write("DoÄŸruluk:", accuracy)
        st.write("----")
        # Confusion Matrix
        st.subheader("KarmaÅŸÄ±klÄ±k Matrisi:")
        conf_matrix = confusion_matrix(y_test, y_pred)
        conf_matrix_df = pd.DataFrame(conf_matrix, 
                                    columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                    index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
        st.write(conf_matrix_df)
        st.write("----")
        # SÄ±nÄ±flandÄ±rma Raporu
        st.subheader("SÄ±nÄ±flandÄ±rma Raporu")
        class_report = classification_report(y_test, y_pred, output_dict=True)
        class_report_df = pd.DataFrame(class_report).transpose()
        st.write(class_report_df)
        # AUC-ROC
        st.subheader("ROC EÄŸrisi ve AUC DeÄŸeri")
        cat_roc_auc = roc_auc_score(y_test, nb_model.predict_proba(X_test)[:, 1])
        fpr, tpr, thresholds = roc_curve(y_test, nb_model.predict_proba(X_test)[:,1])

        fig, ax = plt.subplots()
        ax.plot(fpr, tpr, label='AUC (area = %0.2f)' % cat_roc_auc)
        ax.plot([0, 1], [0, 1],'r--')
        ax.set_xlim([0.0, 1.0])
        ax.set_ylim([0.0, 1.05])
        ax.set_xlabel('False Positive OranÄ±')
        ax.set_ylabel('True Positive OranÄ±')
        ax.set_title('ROC')
        st.pyplot(fig)

        st.write("AUC DeÄŸeri:", cat_roc_auc)

        st.write("----")

        # Cross validation
        st.header("Ã‡apraz DoÄŸrulama")
        cv_scores = cross_val_score(nb_model, X, y, cv=10).mean()
        st.write("Ã‡apraz DoÄŸrulama Skoru:", cv_scores)

    
    
elif page == "Gradient Boosting Machines":
    import streamlit as st
    import pandas as pd
    from sklearn.model_selection import train_test_split, GridSearchCV
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve
    from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor
    import matplotlib.pyplot as plt
    from sklearn.metrics import mean_squared_error, mean_absolute_error

    st.title("Gradient Boosting Machine ğŸ”¢")

    # Ä°zin verilen dosya formatlarÄ±
    allowed_formats = ["csv", "txt", "xls", "xlsx"]

    # KullanÄ±cÄ±dan veri yÃ¼kleme
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

    # Veri yÃ¼klendi mi kontrolÃ¼ ve iÅŸlemler
    if upload is not None:
        if "csv" in upload.name.lower():
            df = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            df = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            df = pd.read_excel(upload)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri seÃ§me
        st.subheader("BaÄŸÄ±msÄ±z ve BaÄŸÄ±mlÄ± DeÄŸiÅŸkenleri SeÃ§me")
        X_options = df.select_dtypes(include=['number', 'float', 'int']).columns.tolist()  # SayÄ±sal deÄŸiÅŸkenleri seÃ§
        y_options = df.select_dtypes(include=['object', 'number', 'float', 'int']).columns.tolist()  # Kategorik deÄŸiÅŸkenleri seÃ§
        X_selected = st.multiselect("BaÄŸÄ±msÄ±z DeÄŸiÅŸkenleri SeÃ§in", X_options)
        y_selected = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§in", y_options)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±rma
        X = df[X_selected]
        y = df[y_selected]

        # Test verisi yÃ¼zdesi ve random state deÄŸeri giriÅŸi
        test_size = st.slider("Test verisi yÃ¼zdesi:", 0.1, 0.5, 0.2, 0.01)
        random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
        st.write("----")
        
        # SÄ±nÄ±flandÄ±rma veya regresyon seÃ§imi
        problem_type = st.radio("Problemi SeÃ§in:", ("SÄ±nÄ±flandÄ±rma", "Regresyon"))

        # SÄ±nÄ±flandÄ±rma iÅŸlemleri
        if problem_type == "SÄ±nÄ±flandÄ±rma":
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # GBM sÄ±nÄ±flandÄ±rma modeli oluÅŸturma
            gbm = GradientBoostingClassifier()

            # Hiperparametre aralÄ±klarÄ±
            params = {
                'n_estimators': [100, 500, 1000],
                'learning_rate': [0.01, 0.05, 0.1],
                'max_depth': [3, 5, 7]
            }

            # Hiperparametre optimizasyonu
            grid_search = GridSearchCV(gbm, params, cv=5, n_jobs=-1, verbose=2)
            grid_search.fit(X_train, y_train)
            best_params = grid_search.best_params_

            st.write("En iyi parametreler:", best_params)

            # En iyi parametrelerle modeli tekrar eÄŸitme
            gbm_model = GradientBoostingClassifier(**best_params)
            gbm_model.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme
            y_pred = gbm_model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            st.write("DoÄŸruluk (Accuracy):", accuracy)

            # DiÄŸer performans metriklerini hesaplama ve gÃ¶rselleÅŸtirme
            precision = precision_score(y_test, y_pred)
            st.write("Hassasiyet (Precision):", precision)

            recall = recall_score(y_test, y_pred)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall):", recall)

            f1 = f1_score(y_test, y_pred)
            st.write("F1-Skor:", f1)

            roc_auc = roc_auc_score(y_test, y_pred)
            st.write("ROC AUC Skoru:", roc_auc)

            conf_matrix = confusion_matrix(y_test, y_pred)
            conf_matrix_df = pd.DataFrame(conf_matrix, 
                                        columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                        index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
            st.subheader("KarmaÅŸÄ±klÄ±k Matrisi:")
            st.write(conf_matrix_df)

            # ROC EÄŸrisi ve AUC DeÄŸeri
            fpr, tpr, thresholds = roc_curve(y_test, y_pred)
            plt.figure()
            plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
            plt.plot([0, 1], [0, 1], 'k--')
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('False Positive OranÄ±')
            plt.ylabel('True Positive OranÄ±')
            plt.title('ROC EÄŸrisi')
            plt.legend(loc="lower right")
            st.pyplot(plt)

        # Regresyon iÅŸlemleri
        elif problem_type == "Regresyon":
            # Veri kÃ¼mesini eÄŸitim ve test kÃ¼melerine ayÄ±rma
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # GBM regresyon modeli oluÅŸturma
            gbm = GradientBoostingRegressor()
            gbm.fit(X_train, y_train)  # Hiperparametre optimizasyonu Ã¶ncesi modeli eÄŸitme

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme
            y_pred = gbm.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin ortalama kare hatasÄ± (MSE):", mse)

            mae = mean_absolute_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin ortalama mutlak hatasÄ± (MAE):", mae)

            rmse = mean_squared_error(y_test, y_pred, squared=False)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin kÃ¶k ortalama kare hatasÄ± (RMSE):", rmse)

            # Hiperparametre aralÄ±klarÄ±
            params = {
                'n_estimators': [100, 500, 1000],
                'learning_rate': [0.01, 0.05, 0.1],
                'max_depth': [3, 5, 7]
            }

            # Hiperparametre optimizasyonu
            grid_search = GridSearchCV(gbm, params, cv=5, n_jobs=-1, verbose=2)
            grid_search.fit(X_train, y_train)
            best_params = grid_search.best_params_

            st.write("En iyi parametreler:", best_params)

            # En iyi parametrelerle modeli tekrar eÄŸitme
            gbm_model = GradientBoostingRegressor(**best_params)
            gbm_model.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme
            y_pred = gbm_model.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin ortalama kare hatasÄ± (MSE):", mse)

            mae = mean_absolute_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin ortalama mutlak hatasÄ± (MAE):", mae)

            rmse = mean_squared_error(y_test, y_pred, squared=False)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin kÃ¶k ortalama kare hatasÄ± (RMSE):", rmse)


    
    
elif page == "K-En YakÄ±n KomÅŸu (KNN)":
    import streamlit as st
    import pandas as pd
    from sklearn.model_selection import train_test_split, GridSearchCV
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve
    from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor
    import matplotlib.pyplot as plt
    from sklearn.metrics import mean_squared_error, mean_absolute_error

    st.title("Gradient Boosting Machine ğŸ”¢")

    # Ä°zin verilen dosya formatlarÄ±
    allowed_formats = ["csv", "txt", "xls", "xlsx"]

    # KullanÄ±cÄ±dan veri yÃ¼kleme
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

    # Veri yÃ¼klendi mi kontrolÃ¼ ve iÅŸlemler
    if upload is not None:
        if "csv" in upload.name.lower():
            df = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            df = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            df = pd.read_excel(upload)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri seÃ§me
        st.subheader("BaÄŸÄ±msÄ±z ve BaÄŸÄ±mlÄ± DeÄŸiÅŸkenleri SeÃ§me")
        X_options = df.select_dtypes(include=['number', 'float', 'int']).columns.tolist()  # SayÄ±sal deÄŸiÅŸkenleri seÃ§
        y_options = df.select_dtypes(include=['object', 'number', 'float', 'int']).columns.tolist()  # Kategorik deÄŸiÅŸkenleri seÃ§
        X_selected = st.multiselect("BaÄŸÄ±msÄ±z DeÄŸiÅŸkenleri SeÃ§in", X_options)
        y_selected = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§in", y_options)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±rma
        X = df[X_selected]
        y = df[y_selected]

        # Test verisi yÃ¼zdesi ve random state deÄŸeri giriÅŸi
        test_size = st.slider("Test verisi yÃ¼zdesi:", 0.1, 0.5, 0.2, 0.01)
        random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
        st.write("----")

        # SÄ±nÄ±flandÄ±rma veya regresyon seÃ§imi
        problem_type = st.radio("Problemi SeÃ§in:", ("SÄ±nÄ±flandÄ±rma", "Regresyon"))

        # SÄ±nÄ±flandÄ±rma iÅŸlemleri
        if problem_type == "SÄ±nÄ±flandÄ±rma":
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # GBM sÄ±nÄ±flandÄ±rma modeli oluÅŸturma
            gbm = GradientBoostingClassifier()
            gbm.fit(X_train, y_train)  # Hiperparametre optimizasyonu Ã¶ncesi modeli eÄŸitme

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu Ã¶ncesi)
            y_pred = gbm.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            st.write("DoÄŸruluk (Accuracy) (Hiperparametre Ã¶ncesi):", accuracy)

            precision = precision_score(y_test, y_pred)
            st.write("Hassasiyet (Precision) (Hiperparametre Ã¶ncesi):", precision)

            recall = recall_score(y_test, y_pred)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall) (Hiperparametre Ã¶ncesi):", recall)

            f1 = f1_score(y_test, y_pred)
            st.write("F1-Skor (Hiperparametre Ã¶ncesi):", f1)

            roc_auc = roc_auc_score(y_test, y_pred)
            st.write("ROC AUC Skoru (Hiperparametre Ã¶ncesi):", roc_auc)

            conf_matrix = confusion_matrix(y_test, y_pred)
            conf_matrix_df = pd.DataFrame(conf_matrix,
                                        columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                        index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
            st.subheader("KarmaÅŸÄ±klÄ±k Matrisi (Hiperparametre Ã¶ncesi):")
            st.write(conf_matrix_df)

            # ROC EÄŸrisi ve AUC DeÄŸeri (Hiperparametre Ã¶ncesi)
            fpr, tpr, thresholds = roc_curve(y_test, y_pred)
            plt.figure()
            plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
            plt.plot([0, 1], [0, 1], 'k--')
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('False Positive OranÄ±')
            plt.ylabel('True Positive OranÄ±')
            plt.title('ROC EÄŸrisi (Hiperparametre Ã¶ncesi)')
            plt.legend(loc="lower right")
            st.pyplot(plt)

            # Hiperparametre aralÄ±klarÄ±
            params = {
                'n_estimators': [100, 500, 1000],
                'learning_rate': [0.01, 0.05, 0.1],
                'max_depth': [3, 5, 7]
            }

            # Hiperparametre optimizasyonu
            grid_search = GridSearchCV(gbm, params, cv=5, n_jobs=-1, verbose=2)
            grid_search.fit(X_train, y_train)
            best_params = grid_search.best_params_

            st.write("En iyi parametreler:", best_params)

            # En iyi parametrelerle modeli tekrar eÄŸitme
            gbm_model = GradientBoostingClassifier(**best_params)
            gbm_model.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu sonrasÄ±)
            y_pred = gbm_model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            st.write("DoÄŸruluk (Accuracy) (Hiperparametre sonrasÄ±):", accuracy)

            precision = precision_score(y_test, y_pred)
            st.write("Hassasiyet (Precision) (Hiperparametre sonrasÄ±):", precision)

            recall = recall_score(y_test, y_pred)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall) (Hiperparametre sonrasÄ±):", recall)

            f1 = f1_score(y_test, y_pred)
            st.write("F1-Skor (Hiperparametre sonrasÄ±):", f1)

            roc_auc = roc_auc_score(y_test, y_pred)
            st.write("ROC AUC Skoru (Hiperparametre sonrasÄ±):", roc_auc)

            conf_matrix = confusion_matrix(y_test, y_pred)
            conf_matrix_df = pd.DataFrame(conf_matrix,
                                        columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                        index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
            st.subheader("KarmaÅŸÄ±klÄ±k Matrisi (Hiperparametre sonrasÄ±):")
            st.write(conf_matrix_df)

            # ROC EÄŸrisi ve AUC DeÄŸeri (Hiperparametre sonrasÄ±)
            fpr, tpr, thresholds = roc_curve(y_test, y_pred)
            plt.figure()
            plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
            plt.plot([0, 1], [0, 1], 'k--')
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('False Positive OranÄ±')
            plt.ylabel('True Positive OranÄ±')
            plt.title('ROC EÄŸrisi (Hiperparametre sonrasÄ±)')
            plt.legend(loc="lower right")
            st.pyplot(plt)

        # Regresyon iÅŸlemleri
        elif problem_type == "Regresyon":
            # Veri kÃ¼mesini eÄŸitim ve test kÃ¼melerine ayÄ±rma
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # GBM regresyon modeli oluÅŸturma
            gbm = GradientBoostingRegressor()
            gbm.fit(X_train, y_train)  # Hiperparametre optimizasyonu Ã¶ncesi modeli eÄŸitme

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu Ã¶ncesi)
            y_pred = gbm.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin ortalama kare hatasÄ± (MSE):", mse)

            mae = mean_absolute_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin ortalama mutlak hatasÄ± (MAE):", mae)

            rmse = mean_squared_error(y_test, y_pred, squared=False)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin kÃ¶k ortalama kare hatasÄ± (RMSE):", rmse)

            # Hiperparametre aralÄ±klarÄ±
            params = {
                'n_estimators': [100, 500, 1000],
                'learning_rate': [0.01, 0.05, 0.1],
                'max_depth': [3, 5, 7]
            }

            # Hiperparametre optimizasyonu
            grid_search = GridSearchCV(gbm, params, cv=5, n_jobs=-1, verbose=2)
            grid_search.fit(X_train, y_train)
            best_params = grid_search.best_params_

            st.write("En iyi parametreler:", best_params)

            # En iyi parametrelerle modeli tekrar eÄŸitme
            gbm_model = GradientBoostingRegressor(**best_params)
            gbm_model.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu sonrasÄ±)
            y_pred = gbm_model.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin ortalama kare hatasÄ± (MSE):", mse)

            mae = mean_absolute_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin ortalama mutlak hatasÄ± (MAE):", mae)

            rmse = mean_squared_error(y_test, y_pred, squared=False)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin kÃ¶k ortalama kare hatasÄ± (RMSE):", rmse)

        
    
elif page == "LightGBM":
    import streamlit as st
    import pandas as pd
    from sklearn.model_selection import train_test_split, GridSearchCV
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve
    from lightgbm import LGBMClassifier, LGBMRegressor
    import matplotlib.pyplot as plt
    from sklearn.metrics import mean_squared_error, mean_absolute_error

    st.title("LightGBM ğŸ”¢")

    # Ä°zin verilen dosya formatlarÄ±
    allowed_formats = ["csv", "txt", "xls", "xlsx"]

    # KullanÄ±cÄ±dan veri yÃ¼kleme
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

    # Veri yÃ¼klendi mi kontrolÃ¼ ve iÅŸlemler
    if upload is not None:
        if "csv" in upload.name.lower():
            df = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            df = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            df = pd.read_excel(upload)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri seÃ§me
        st.subheader("BaÄŸÄ±msÄ±z ve BaÄŸÄ±mlÄ± DeÄŸiÅŸkenleri SeÃ§me")
        X_options = df.select_dtypes(include=['number', 'float', 'int']).columns.tolist()  # SayÄ±sal deÄŸiÅŸkenleri seÃ§
        y_options = df.select_dtypes(include=['object', 'number', 'float', 'int']).columns.tolist()  # Kategorik deÄŸiÅŸkenleri seÃ§
        X_selected = st.multiselect("BaÄŸÄ±msÄ±z DeÄŸiÅŸkenleri SeÃ§in", X_options)
        y_selected = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§in", y_options)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±rma
        X = df[X_selected]
        y = df[y_selected]

        # Test verisi yÃ¼zdesi ve random state deÄŸeri giriÅŸi
        test_size = st.slider("Test verisi yÃ¼zdesi:", 0.1, 0.5, 0.2, 0.01)
        random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
        st.write("----")

        # SÄ±nÄ±flandÄ±rma veya regresyon seÃ§imi
        problem_type = st.radio("Problemi SeÃ§in:", ("SÄ±nÄ±flandÄ±rma", "Regresyon"))

        # SÄ±nÄ±flandÄ±rma iÅŸlemleri
        if problem_type == "SÄ±nÄ±flandÄ±rma":
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # LightGBM sÄ±nÄ±flandÄ±rma modeli oluÅŸturma
            lgbm = LGBMClassifier()
            lgbm.fit(X_train, y_train)  # Hiperparametre optimizasyonu Ã¶ncesi modeli eÄŸitme

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu Ã¶ncesi)
            y_pred = lgbm.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            st.write("DoÄŸruluk (Accuracy) (Hiperparametre Ã¶ncesi):", accuracy)

            precision = precision_score(y_test, y_pred)
            st.write("Hassasiyet (Precision) (Hiperparametre Ã¶ncesi):", precision)

            recall = recall_score(y_test, y_pred)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall) (Hiperparametre Ã¶ncesi):", recall)

            f1 = f1_score(y_test, y_pred)
            st.write("F1-Skor (Hiperparametre Ã¶ncesi):", f1)

            roc_auc = roc_auc_score(y_test, y_pred)
            st.write("ROC AUC Skoru (Hiperparametre Ã¶ncesi):", roc_auc)

            conf_matrix = confusion_matrix(y_test, y_pred)
            conf_matrix_df = pd.DataFrame(conf_matrix,
                                        columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                        index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
            st.subheader("KarmaÅŸÄ±klÄ±k Matrisi (Hiperparametre Ã¶ncesi):")
            st.write(conf_matrix_df)

            # ROC EÄŸrisi ve AUC DeÄŸeri (Hiperparametre Ã¶ncesi)
            fpr, tpr, thresholds = roc_curve(y_test, y_pred)
            plt.figure()
            plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
            plt.plot([0, 1], [0, 1], 'k--')
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('False Positive OranÄ±')
            plt.ylabel('True Positive OranÄ±')
            plt.title('ROC EÄŸrisi (Hiperparametre Ã¶ncesi)')
            plt.legend(loc="lower right")
            st.pyplot(plt)

            # Hiperparametre aralÄ±klarÄ±
            params = {
                'n_estimators': [100, 500, 1000],
                'learning_rate': [0.01, 0.05, 0.1],
                'max_depth': [3, 5, 7]
            }

            # Hiperparametre optimizasyonu
            grid_search = GridSearchCV(lgbm, params, cv=5, n_jobs=-1, verbose=2)
            grid_search.fit(X_train, y_train)
            best_params = grid_search.best_params_

            st.write("En iyi parametreler:", best_params)

            # En iyi parametrelerle modeli tekrar eÄŸitme
            lgbm_model = LGBMClassifier(**best_params)
            lgbm_model.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu sonrasÄ±)
            y_pred = lgbm_model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            st.write("DoÄŸruluk (Accuracy) (Hiperparametre sonrasÄ±):", accuracy)

            precision = precision_score(y_test, y_pred)
            st.write("Hassasiyet (Precision) (Hiperparametre sonrasÄ±):", precision)

            recall = recall_score(y_test, y_pred)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall) (Hiperparametre sonrasÄ±):", recall)

            f1 = f1_score(y_test, y_pred)
            st.write("F1-Skor (Hiperparametre sonrasÄ±):", f1)

            roc_auc = roc_auc_score(y_test, y_pred)
            st.write("ROC AUC Skoru (Hiperparametre sonrasÄ±):", roc_auc)

            conf_matrix = confusion_matrix(y_test, y_pred)
            conf_matrix_df = pd.DataFrame(conf_matrix,
                                        columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                        index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
            st.subheader("KarmaÅŸÄ±klÄ±k Matrisi (Hiperparametre sonrasÄ±):")
            st.write(conf_matrix_df)

            # ROC EÄŸrisi ve AUC DeÄŸeri (Hiperparametre sonrasÄ±)
            fpr, tpr, thresholds = roc_curve(y_test, y_pred)
            plt.figure()
            plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
            plt.plot([0, 1], [0, 1], 'k--')
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('False Positive OranÄ±')
            plt.ylabel('True Positive OranÄ±')
            plt.title('ROC EÄŸrisi (Hiperparametre sonrasÄ±)')
            plt.legend(loc="lower right")
            st.pyplot(plt)

        # Regresyon iÅŸlemleri
        elif problem_type == "Regresyon":
            # Veri kÃ¼mesini eÄŸitim ve test kÃ¼melerine ayÄ±rma
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # LightGBM regresyon modeli oluÅŸturma
            lgbm = LGBMRegressor()
            lgbm.fit(X_train, y_train)  # Hiperparametre optimizasyonu Ã¶ncesi modeli eÄŸitme

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu Ã¶ncesi)
            y_pred = lgbm.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin ortalama kare hatasÄ± (MSE):", mse)

            mae = mean_absolute_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin ortalama mutlak hatasÄ± (MAE):", mae)

            rmse = mean_squared_error(y_test, y_pred, squared=False)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin kÃ¶k ortalama kare hatasÄ± (RMSE):", rmse)

            # Hiperparametre aralÄ±klarÄ±
            params = {
                'n_estimators': [100, 500, 1000],
                'learning_rate': [0.01, 0.05, 0.1],
                'max_depth': [3, 5, 7]
            }

            # Hiperparametre optimizasyonu
            grid_search = GridSearchCV(lgbm, params, cv=5, n_jobs=-1, verbose=2)
            grid_search.fit(X_train, y_train)
            best_params = grid_search.best_params_

            st.write("En iyi parametreler:", best_params)

            # En iyi parametrelerle modeli tekrar eÄŸitme
            lgbm_model = LGBMRegressor(**best_params)
            lgbm_model.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu sonrasÄ±)
            y_pred = lgbm_model.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin ortalama kare hatasÄ± (MSE):", mse)

            mae = mean_absolute_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin ortalama mutlak hatasÄ± (MAE):", mae)

            rmse = mean_squared_error(y_test, y_pred, squared=False)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin kÃ¶k ortalama kare hatasÄ± (RMSE):", rmse)

    
    
elif page == "Lojistik Regresyon":
    import streamlit as st
    import pandas as pd
    from sklearn.model_selection import train_test_split, GridSearchCV
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve
    from sklearn.linear_model import LogisticRegression
    import matplotlib.pyplot as plt

    st.title("Lojistik Regresyon ğŸ”¢")

    # Ä°zin verilen dosya formatlarÄ±
    allowed_formats = ["csv", "txt", "xls", "xlsx"]

    # KullanÄ±cÄ±dan veri yÃ¼kleme
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

    # Veri yÃ¼klendi mi kontrolÃ¼ ve iÅŸlemler
    if upload is not None:
        if "csv" in upload.name.lower():
            df = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            df = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            df = pd.read_excel(upload)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri seÃ§me
        st.subheader("BaÄŸÄ±msÄ±z ve BaÄŸÄ±mlÄ± DeÄŸiÅŸkenleri SeÃ§me")
        X_options = df.select_dtypes(include=['number', 'float', 'int']).columns.tolist()  # SayÄ±sal deÄŸiÅŸkenleri seÃ§
        y_options = df.select_dtypes(include=['object', 'number', 'float', 'int']).columns.tolist()  # Kategorik deÄŸiÅŸkenleri seÃ§
        X_selected = st.multiselect("BaÄŸÄ±msÄ±z DeÄŸiÅŸkenleri SeÃ§in", X_options)
        y_selected = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§in", y_options)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±rma
        X = df[X_selected]
        y = df[y_selected]

        # Test verisi yÃ¼zdesi ve random state deÄŸeri giriÅŸi
        test_size = st.slider("Test verisi yÃ¼zdesi:", 0.1, 0.5, 0.2, 0.01)
        random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
        st.write("----")

        # SÄ±nÄ±flandÄ±rma iÅŸlemleri
        if st.radio("Problemi SeÃ§in:", ("SÄ±nÄ±flandÄ±rma", "Regresyon")) == "SÄ±nÄ±flandÄ±rma":
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # Lojistik Regresyon modeli oluÅŸturma
            logreg = LogisticRegression()
            logreg.fit(X_train, y_train)  # Hiperparametre optimizasyonu Ã¶ncesi modeli eÄŸitme

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu Ã¶ncesi)
            y_pred = logreg.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            st.write("DoÄŸruluk (Accuracy) (Hiperparametre Ã¶ncesi):", accuracy)

            precision = precision_score(y_test, y_pred)
            st.write("Hassasiyet (Precision) (Hiperparametre Ã¶ncesi):", precision)

            recall = recall_score(y_test, y_pred)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall) (Hiperparametre Ã¶ncesi):", recall)

            f1 = f1_score(y_test, y_pred)
            st.write("F1-Skor (Hiperparametre Ã¶ncesi):", f1)

            roc_auc = roc_auc_score(y_test, y_pred)
            st.write("ROC AUC Skoru (Hiperparametre Ã¶ncesi):", roc_auc)

            conf_matrix = confusion_matrix(y_test, y_pred)
            conf_matrix_df = pd.DataFrame(conf_matrix,
                                        columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                        index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
            st.subheader("KarmaÅŸÄ±klÄ±k Matrisi (Hiperparametre Ã¶ncesi):")
            st.write(conf_matrix_df)

            # ROC EÄŸrisi ve AUC DeÄŸeri (Hiperparametre Ã¶ncesi)
            fpr, tpr, thresholds = roc_curve(y_test, y_pred)
            plt.figure()
            plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
            plt.plot([0, 1], [0, 1], 'k--')
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('False Positive OranÄ±')
            plt.ylabel('True Positive OranÄ±')
            plt.title('ROC EÄŸrisi (Hiperparametre Ã¶ncesi)')
            plt.legend(loc="lower right")
            st.pyplot(plt)

            # Hiperparametre aralÄ±klarÄ±
            params = {
                'C': [0.001, 0.01, 0.1, 1, 10, 100],
                'penalty': ['l1', 'l2']
            }

            # Hiperparametre optimizasyonu
            grid_search = GridSearchCV(logreg, params, cv=5, n_jobs=-1, verbose=2)
            grid_search.fit(X_train, y_train)
            best_params = grid_search.best_params_

            st.write("En iyi parametreler:", best_params)

            # En iyi parametrelerle modeli tekrar eÄŸitme
            logreg_model = LogisticRegression(**best_params)
            logreg_model.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu sonrasÄ±)
            y_pred = logreg_model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            st.write("DoÄŸruluk (Accuracy) (Hiperparametre sonrasÄ±):", accuracy)

            precision = precision_score(y_test, y_pred)
            st.write("Hassasiyet (Precision) (Hiperparametre sonrasÄ±):", precision)

            recall = recall_score(y_test, y_pred)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall) (Hiperparametre sonrasÄ±):", recall)

            f1 = f1_score(y_test, y_pred)
            st.write("F1-Skor (Hiperparametre sonrasÄ±):", f1)

            roc_auc = roc_auc_score(y_test, y_pred)
            st.write("ROC AUC Skoru (Hiperparametre sonrasÄ±):", roc_auc)

            conf_matrix = confusion_matrix(y_test, y_pred)
            conf_matrix_df = pd.DataFrame(conf_matrix,
                                        columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                        index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
            st.subheader("KarmaÅŸÄ±klÄ±k Matrisi (Hiperparametre sonrasÄ±):")
            st.write(conf_matrix_df)

            # ROC EÄŸrisi ve AUC DeÄŸeri (Hiperparametre sonrasÄ±)
            fpr, tpr, thresholds = roc_curve(y_test, y_pred)
            plt.figure()
            plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
            plt.plot([0, 1], [0, 1], 'k--')
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('False Positive OranÄ±')
            plt.ylabel('True Positive OranÄ±')
            plt.title('ROC EÄŸrisi (Hiperparametre sonrasÄ±)')
            plt.legend(loc="lower right")
            st.pyplot(plt)

        # Regresyon iÅŸlemleri
        else:
            # Veri kÃ¼mesini eÄŸitim ve test kÃ¼melerine ayÄ±rma
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            st.write("Lojistik regresyon kullanarak regresyon yapmak uygun deÄŸildir. LÃ¼tfen baÅŸka bir algoritma seÃ§in.")


    
    
elif page == "Mann-Whitney U Testi":
    import streamlit as st
    import pandas as pd
    from scipy.stats import mannwhitneyu

    
    def main():
        st.title("Mann Whitney U Testi ğŸ“Š(Ä°ki Ã–rnekli Wilcoxon Testi)")

        # Veri setini yÃ¼kle
        allowed_formats = ["csv", "txt", "xls", "xlsx"]
        upload = st.file_uploader("Ä°ki Ã¶rnekli veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyin", type=allowed_formats)

        if upload is not None:
            if "csv" in upload.name.lower():
                data = pd.read_csv(upload)
            elif "txt" in upload.name.lower():
                data = pd.read_csv(upload, delimiter='\t')
            elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
                data = pd.read_excel(upload)

            st.write("Veri Ã–rneÄŸi:")
            st.write(data)

            # Ä°ki Ã¶rnekli Wilcoxon testi iÃ§in grup seÃ§imi
            st.subheader("Ä°ki Ã–rnekli Wilcoxon Testi iÃ§in Gruplar")
            group1 = st.selectbox("LÃ¼tfen birinci grubu seÃ§in:", data.columns)
            group2 = st.selectbox("LÃ¼tfen ikinci grubu seÃ§in:", data.columns)

            # Mann-Whitney U testinin yapÄ±lmasÄ±
            st.subheader("Mann-Whitney U Testi SonuÃ§larÄ±")
            stat, p_value = mannwhitneyu(data[group1], data[group2])
            st.write("Test Ä°statistiÄŸi:", stat)
            st.write("P-deÄŸeri:", p_value)

            # SonuÃ§larÄ±n yorumlanmasÄ±
            if p_value < 0.05:
                st.write("P-deÄŸeri 0.05 anlamlÄ±lÄ±k dÃ¼zeyinden kÃ¼Ã§Ã¼k olduÄŸu iÃ§in, gruplar arasÄ±nda istatistiksel olarak anlamlÄ± bir fark vardÄ±r.")
            else:
                st.write("P-deÄŸeri 0.05 anlamlÄ±lÄ±k dÃ¼zeyinden bÃ¼yÃ¼k olduÄŸu iÃ§in, gruplar arasÄ±nda istatistiksel olarak anlamlÄ± bir fark yoktur.")

    if __name__ == "__main__":
        main()

    
    
elif page == "Random Forest":
    import streamlit as st
    import pandas as pd
    from sklearn.model_selection import train_test_split, GridSearchCV
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve
    from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
    import matplotlib.pyplot as plt
    from sklearn.metrics import mean_squared_error, mean_absolute_error

    st.title("Random Forest ğŸ”¢")

    # Ä°zin verilen dosya formatlarÄ±
    allowed_formats = ["csv", "txt", "xls", "xlsx"]

    # KullanÄ±cÄ±dan veri yÃ¼kleme
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

    # Veri yÃ¼klendi mi kontrolÃ¼ ve iÅŸlemler
    if upload is not None:
        if "csv" in upload.name.lower():
            df = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            df = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            df = pd.read_excel(upload)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri seÃ§me
        st.subheader("BaÄŸÄ±msÄ±z ve BaÄŸÄ±mlÄ± DeÄŸiÅŸkenleri SeÃ§me")
        X_options = df.select_dtypes(include=['number', 'float', 'int']).columns.tolist()  # SayÄ±sal deÄŸiÅŸkenleri seÃ§
        y_options = df.select_dtypes(include=['object', 'number', 'float', 'int']).columns.tolist()  # Kategorik deÄŸiÅŸkenleri seÃ§
        X_selected = st.multiselect("BaÄŸÄ±msÄ±z DeÄŸiÅŸkenleri SeÃ§in", X_options)
        y_selected = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§in", y_options)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±rma
        X = df[X_selected]
        y = df[y_selected]

        # Test verisi yÃ¼zdesi ve random state deÄŸeri giriÅŸi
        test_size = st.slider("Test verisi yÃ¼zdesi:", 0.1, 0.5, 0.2, 0.01)
        random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
        st.write("----")

        # SÄ±nÄ±flandÄ±rma veya regresyon seÃ§imi
        problem_type = st.radio("Problemi SeÃ§in:", ("SÄ±nÄ±flandÄ±rma", "Regresyon"))

        # SÄ±nÄ±flandÄ±rma iÅŸlemleri
        if problem_type == "SÄ±nÄ±flandÄ±rma":
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # Random Forest sÄ±nÄ±flandÄ±rma modeli oluÅŸturma
            rf = RandomForestClassifier()
            rf.fit(X_train, y_train)  # Hiperparametre optimizasyonu Ã¶ncesi modeli eÄŸitme

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu Ã¶ncesi)
            y_pred = rf.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            st.write("DoÄŸruluk (Accuracy) (Hiperparametre Ã¶ncesi):", accuracy)

            precision = precision_score(y_test, y_pred)
            st.write("Hassasiyet (Precision) (Hiperparametre Ã¶ncesi):", precision)

            recall = recall_score(y_test, y_pred)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall) (Hiperparametre Ã¶ncesi):", recall)

            f1 = f1_score(y_test, y_pred)
            st.write("F1-Skor (Hiperparametre Ã¶ncesi):", f1)

            roc_auc = roc_auc_score(y_test, y_pred)
            st.write("ROC AUC Skoru (Hiperparametre Ã¶ncesi):", roc_auc)

            conf_matrix = confusion_matrix(y_test, y_pred)
            conf_matrix_df = pd.DataFrame(conf_matrix,
                                        columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                        index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
            st.subheader("KarmaÅŸÄ±klÄ±k Matrisi (Hiperparametre Ã¶ncesi):")
            st.write(conf_matrix_df)

            # ROC EÄŸrisi ve AUC DeÄŸeri (Hiperparametre Ã¶ncesi)
            fpr, tpr, thresholds = roc_curve(y_test, y_pred)
            plt.figure()
            plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
            plt.plot([0, 1], [0, 1], 'k--')
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('False Positive OranÄ±')
            plt.ylabel('True Positive OranÄ±')
            plt.title('ROC EÄŸrisi (Hiperparametre Ã¶ncesi)')
            plt.legend(loc="lower right")
            st.pyplot(plt)

            # Hiperparametre aralÄ±klarÄ±
            params = {
                'n_estimators': [100, 500, 1000],
                'max_depth': [3, 5, 7]
            }

            # Hiperparametre optimizasyonu
            grid_search = GridSearchCV(rf, params, cv=5, n_jobs=-1, verbose=2)
            grid_search.fit(X_train, y_train)
            best_params = grid_search.best_params_

            st.write("En iyi parametreler:", best_params)

            # En iyi parametrelerle modeli tekrar eÄŸitme
            rf_model = RandomForestClassifier(**best_params)
            rf_model.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu sonrasÄ±)
            y_pred = rf_model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            st.write("DoÄŸruluk (Accuracy) (Hiperparametre sonrasÄ±):", accuracy)

            precision = precision_score(y_test, y_pred)
            st.write("Hassasiyet (Precision) (Hiperparametre sonrasÄ±):", precision)

            recall = recall_score(y_test, y_pred)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall) (Hiperparametre sonrasÄ±):", recall)

            f1 = f1_score(y_test, y_pred)
            st.write("F1-Skor (Hiperparametre sonrasÄ±):", f1)

            roc_auc = roc_auc_score(y_test, y_pred)
            st.write("ROC AUC Skoru (Hiperparametre sonrasÄ±):", roc_auc)

            conf_matrix = confusion_matrix(y_test, y_pred)
            conf_matrix_df = pd.DataFrame(conf_matrix,
                                        columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                        index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
            st.subheader("KarmaÅŸÄ±klÄ±k Matrisi (Hiperparametre sonrasÄ±):")
            st.write(conf_matrix_df)

            # ROC EÄŸrisi ve AUC DeÄŸeri (Hiperparametre sonrasÄ±)
            fpr, tpr, thresholds = roc_curve(y_test, y_pred)
            plt.figure()
            plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
            plt.plot([0, 1], [0, 1], 'k--')
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('False Positive OranÄ±')
            plt.ylabel('True Positive OranÄ±')
            plt.title('ROC EÄŸrisi (Hiperparametre sonrasÄ±)')
            plt.legend(loc="lower right")
            st.pyplot(plt)

        # Regresyon iÅŸlemleri
        elif problem_type == "Regresyon":
            # Veri kÃ¼mesini eÄŸitim ve test kÃ¼melerine ayÄ±rma
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # Random Forest regresyon modeli oluÅŸturma
            rf = RandomForestRegressor()
            rf.fit(X_train, y_train)  # Hiperparametre optimizasyonu Ã¶ncesi modeli eÄŸitme

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu Ã¶ncesi)
            y_pred = rf.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin ortalama kare hatasÄ± (MSE):", mse)

            mae = mean_absolute_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin ortalama mutlak hatasÄ± (MAE):", mae)

            rmse = mean_squared_error(y_test, y_pred, squared=False)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin kÃ¶k ortalama kare hatasÄ± (RMSE):", rmse)

            # Hiperparametre aralÄ±klarÄ±
            params = {
                'n_estimators': [100, 500, 1000],
                'max_depth': [3, 5, 7]
            }

            # Hiperparametre optimizasyonu
            grid_search = GridSearchCV(rf, params, cv=5, n_jobs=-1, verbose=2)
            grid_search.fit(X_train, y_train)
            best_params = grid_search.best_params_

            st.write("En iyi parametreler:", best_params)

            # En iyi parametrelerle modeli tekrar eÄŸitme
            rf_model = RandomForestRegressor(**best_params)
            rf_model.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu sonrasÄ±)
            y_pred = rf_model.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin ortalama kare hatasÄ± (MSE):", mse)

            mae = mean_absolute_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin ortalama mutlak hatasÄ± (MAE):", mae)

            rmse = mean_squared_error(y_test, y_pred, squared=False)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin kÃ¶k ortalama kare hatasÄ± (RMSE):", rmse)

    
    
    
elif page == "RBF SVM (Radial Basis Function Support Vector Machine)":
    import streamlit as st
    import pandas as pd
    from sklearn.model_selection import train_test_split, GridSearchCV
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve
    from sklearn.svm import SVC
    import matplotlib.pyplot as plt

    st.title("RBF SVM (Radial Basis Function Support Vector Machine)ğŸ’¹")

    # Ä°zin verilen dosya formatlarÄ±
    allowed_formats = ["csv", "txt", "xls", "xlsx"]

    # KullanÄ±cÄ±dan veri yÃ¼kleme
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

    # Veri yÃ¼klendi mi kontrolÃ¼ ve iÅŸlemler
    if upload is not None:
        if "csv" in upload.name.lower():
            df = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            df = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            df = pd.read_excel(upload)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri seÃ§me
        st.subheader("BaÄŸÄ±msÄ±z ve BaÄŸÄ±mlÄ± DeÄŸiÅŸkenleri SeÃ§me")
        X_options = df.select_dtypes(include=['number', 'float', 'int']).columns.tolist()  # SayÄ±sal deÄŸiÅŸkenleri seÃ§
        y_options = df.select_dtypes(include=['object', 'number', 'float', 'int']).columns.tolist()  # Kategorik deÄŸiÅŸkenleri seÃ§
        X_selected = st.multiselect("BaÄŸÄ±msÄ±z DeÄŸiÅŸkenleri SeÃ§in", X_options)
        y_selected = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§in", y_options)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±rma
        X = df[X_selected]
        y = df[y_selected]

        # Test verisi yÃ¼zdesi ve random state deÄŸeri giriÅŸi
        test_size = st.slider("Test verisi yÃ¼zdesi:", 0.1, 0.5, 0.2, 0.01)
        random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
        st.write("----")

        # SÄ±nÄ±flandÄ±rma iÅŸlemleri
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

        # RBF SVM sÄ±nÄ±flandÄ±rma modeli oluÅŸturma
        svm = SVC(kernel='rbf', probability=True)
        svm.fit(X_train, y_train)  # Hiperparametre optimizasyonu Ã¶ncesi modeli eÄŸitme

        # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme
        y_pred = svm.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        st.write("DoÄŸruluk (Accuracy):", accuracy)

        precision = precision_score(y_test, y_pred)
        st.write("Hassasiyet (Precision):", precision)

        recall = recall_score(y_test, y_pred)
        st.write("Geri Ã‡aÄŸÄ±rma (Recall):", recall)

        f1 = f1_score(y_test, y_pred)
        st.write("F1-Skor:", f1)

        roc_auc = roc_auc_score(y_test, y_pred)
        st.write("ROC AUC Skoru:", roc_auc)

        conf_matrix = confusion_matrix(y_test, y_pred)
        conf_matrix_df = pd.DataFrame(conf_matrix,
                                    columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                    index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
        st.subheader("KarmaÅŸÄ±klÄ±k Matrisi:")
        st.write(conf_matrix_df)

        # ROC EÄŸrisi ve AUC DeÄŸeri
        fpr, tpr, thresholds = roc_curve(y_test, y_pred)
        plt.figure()
        plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive OranÄ±')
        plt.ylabel('True Positive OranÄ±')
        plt.title('ROC EÄŸrisi')
        plt.legend(loc="lower right")
        st.pyplot(plt)

    
    
    
    
elif page == "SVC (Support Vector Classification)":
    import streamlit as st
    import pandas as pd
    from sklearn.model_selection import train_test_split, GridSearchCV
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve
    from sklearn.svm import SVC
    import matplotlib.pyplot as plt

    st.title("SVC (Support Vector Classification)ğŸ’¹")

    # Ä°zin verilen dosya formatlarÄ±
    allowed_formats = ["csv", "txt", "xls", "xlsx"]

    # KullanÄ±cÄ±dan veri yÃ¼kleme
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

    # Veri yÃ¼klendi mi kontrolÃ¼ ve iÅŸlemler
    if upload is not None:
        if "csv" in upload.name.lower():
            df = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            df = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            df = pd.read_excel(upload)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri seÃ§me
        st.subheader("BaÄŸÄ±msÄ±z ve BaÄŸÄ±mlÄ± DeÄŸiÅŸkenleri SeÃ§me")
        X_options = df.select_dtypes(include=['number', 'float', 'int']).columns.tolist()  # SayÄ±sal deÄŸiÅŸkenleri seÃ§
        y_options = df.select_dtypes(include=['object', 'number', 'float', 'int']).columns.tolist()  # Kategorik deÄŸiÅŸkenleri seÃ§
        X_selected = st.multiselect("BaÄŸÄ±msÄ±z DeÄŸiÅŸkenleri SeÃ§in", X_options)
        y_selected = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§in", y_options)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±rma
        X = df[X_selected]
        y = df[y_selected]

        # Test verisi yÃ¼zdesi ve random state deÄŸeri giriÅŸi
        test_size = st.slider("Test verisi yÃ¼zdesi:", 0.1, 0.5, 0.2, 0.01)
        random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
        st.write("----")

        # SÄ±nÄ±flandÄ±rma iÅŸlemleri
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

        # SVC sÄ±nÄ±flandÄ±rma modeli oluÅŸturma
        svc = SVC(probability=True)
        svc.fit(X_train, y_train)  # Hiperparametre optimizasyonu Ã¶ncesi modeli eÄŸitme

        # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme
        y_pred = svc.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        st.write("DoÄŸruluk (Accuracy):", accuracy)

        precision = precision_score(y_test, y_pred)
        st.write("Hassasiyet (Precision):", precision)

        recall = recall_score(y_test, y_pred)
        st.write("Geri Ã‡aÄŸÄ±rma (Recall):", recall)

        f1 = f1_score(y_test, y_pred)
        st.write("F1-Skor:", f1)

        roc_auc = roc_auc_score(y_test, y_pred)
        st.write("ROC AUC Skoru:", roc_auc)

        conf_matrix = confusion_matrix(y_test, y_pred)
        conf_matrix_df = pd.DataFrame(conf_matrix,
                                    columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                    index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
        st.subheader("KarmaÅŸÄ±klÄ±k Matrisi:")
        st.write(conf_matrix_df)

        # ROC EÄŸrisi ve AUC DeÄŸeri
        fpr, tpr, thresholds = roc_curve(y_test, y_pred)
        plt.figure()
        plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive OranÄ±')
        plt.ylabel('True Positive OranÄ±')
        plt.title('ROC EÄŸrisi')
        plt.legend(loc="lower right")
        st.pyplot(plt)


    
    
    
elif page == "XGBoost":
    import streamlit as st
    import pandas as pd
    from sklearn.model_selection import train_test_split, GridSearchCV
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve
    from xgboost import XGBClassifier, XGBRegressor
    import matplotlib.pyplot as plt
    from sklearn.metrics import mean_squared_error, mean_absolute_error

    st.title("XGBoost ğŸ“ˆ")

    # Ä°zin verilen dosya formatlarÄ±
    allowed_formats = ["csv", "txt", "xls", "xlsx"]

    # KullanÄ±cÄ±dan veri yÃ¼kleme
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

    # Veri yÃ¼klendi mi kontrolÃ¼ ve iÅŸlemler
    if upload is not None:
        if "csv" in upload.name.lower():
            df = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            df = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            df = pd.read_excel(upload)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri seÃ§me
        st.subheader("BaÄŸÄ±msÄ±z ve BaÄŸÄ±mlÄ± DeÄŸiÅŸkenleri SeÃ§me")
        X_options = df.select_dtypes(include=['number', 'float', 'int']).columns.tolist()  # SayÄ±sal deÄŸiÅŸkenleri seÃ§
        y_options = df.select_dtypes(include=['object', 'number', 'float', 'int']).columns.tolist()  # Kategorik deÄŸiÅŸkenleri seÃ§
        X_selected = st.multiselect("BaÄŸÄ±msÄ±z DeÄŸiÅŸkenleri SeÃ§in", X_options)
        y_selected = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§in", y_options)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±rma
        X = df[X_selected]
        y = df[y_selected]

        # Test verisi yÃ¼zdesi ve random state deÄŸeri giriÅŸi
        test_size = st.slider("Test verisi yÃ¼zdesi:", 0.1, 0.5, 0.2, 0.01)
        random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
        st.write("----")

        # SÄ±nÄ±flandÄ±rma veya regresyon seÃ§imi
        problem_type = st.radio("Problemi SeÃ§in:", ("SÄ±nÄ±flandÄ±rma", "Regresyon"))

        # SÄ±nÄ±flandÄ±rma iÅŸlemleri
        if problem_type == "SÄ±nÄ±flandÄ±rma":
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # XGBoost sÄ±nÄ±flandÄ±rma modeli oluÅŸturma
            xgb = XGBClassifier()
            xgb.fit(X_train, y_train)  # Hiperparametre optimizasyonu Ã¶ncesi modeli eÄŸitme

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu Ã¶ncesi)
            y_pred = xgb.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            st.write("DoÄŸruluk (Accuracy) (Hiperparametre Ã¶ncesi):", accuracy)

            precision = precision_score(y_test, y_pred)
            st.write("Hassasiyet (Precision) (Hiperparametre Ã¶ncesi):", precision)

            recall = recall_score(y_test, y_pred)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall) (Hiperparametre Ã¶ncesi):", recall)

            f1 = f1_score(y_test, y_pred)
            st.write("F1-Skor (Hiperparametre Ã¶ncesi):", f1)

            roc_auc = roc_auc_score(y_test, y_pred)
            st.write("ROC AUC Skoru (Hiperparametre Ã¶ncesi):", roc_auc)

            conf_matrix = confusion_matrix(y_test, y_pred)
            conf_matrix_df = pd.DataFrame(conf_matrix,
                                        columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                        index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
            st.subheader("KarmaÅŸÄ±klÄ±k Matrisi (Hiperparametre Ã¶ncesi):")
            st.write(conf_matrix_df)

            # ROC EÄŸrisi ve AUC DeÄŸeri (Hiperparametre Ã¶ncesi)
            fpr, tpr, thresholds = roc_curve(y_test, y_pred)
            plt.figure()
            plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
            plt.plot([0, 1], [0, 1], 'k--')
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('False Positive OranÄ±')
            plt.ylabel('True Positive OranÄ±')
            plt.title('ROC EÄŸrisi (Hiperparametre Ã¶ncesi)')
            plt.legend(loc="lower right")
            st.pyplot(plt)

            # Hiperparametre aralÄ±klarÄ±
            params = {
                'n_estimators': [100, 500, 1000],
                'learning_rate': [0.01, 0.05, 0.1],
                'max_depth': [3, 5, 7]
            }

            # Hiperparametre optimizasyonu
            grid_search = GridSearchCV(xgb, params, cv=5, n_jobs=-1, verbose=2)
            grid_search.fit(X_train, y_train)
            best_params = grid_search.best_params_

            st.write("En iyi parametreler:", best_params)

            # En iyi parametrelerle modeli tekrar eÄŸitme
            xgb_model = XGBClassifier(**best_params)
            xgb_model.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu sonrasÄ±)
            y_pred = xgb_model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            st.write("DoÄŸruluk (Accuracy) (Hiperparametre sonrasÄ±):", accuracy)

            precision = precision_score(y_test, y_pred)
            st.write("Hassasiyet (Precision) (Hiperparametre sonrasÄ±):", precision)

            recall = recall_score(y_test, y_pred)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall) (Hiperparametre sonrasÄ±):", recall)

            f1 = f1_score(y_test, y_pred)
            st.write("F1-Skor (Hiperparametre sonrasÄ±):", f1)

            roc_auc = roc_auc_score(y_test, y_pred)
            st.write("ROC AUC Skoru (Hiperparametre sonrasÄ±):", roc_auc)

            conf_matrix = confusion_matrix(y_test, y_pred)
            conf_matrix_df = pd.DataFrame(conf_matrix,
                                        columns=['Tahmin Edilen Negatif (0)', 'Tahmin Edilen Pozitif (1)'],
                                        index=['GerÃ§ek Negatif (0)', 'GerÃ§ek Pozitif (1)'])
            st.subheader("KarmaÅŸÄ±klÄ±k Matrisi (Hiperparametre sonrasÄ±):")
            st.write(conf_matrix_df)

            # ROC EÄŸrisi ve AUC DeÄŸeri (Hiperparametre sonrasÄ±)
            fpr, tpr, thresholds = roc_curve(y_test, y_pred)
            plt.figure()
            plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
            plt.plot([0, 1], [0, 1], 'k--')
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('False Positive OranÄ±')
            plt.ylabel('True Positive OranÄ±')
            plt.title('ROC EÄŸrisi (Hiperparametre sonrasÄ±)')
            plt.legend(loc="lower right")
            st.pyplot(plt)

        # Regresyon iÅŸlemleri
        elif problem_type == "Regresyon":
            # Veri kÃ¼mesini eÄŸitim ve test kÃ¼melerine ayÄ±rma
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            # XGBoost regresyon modeli oluÅŸturma
            xgb = XGBRegressor()
            xgb.fit(X_train, y_train)  # Hiperparametre optimizasyonu Ã¶ncesi modeli eÄŸitme

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu Ã¶ncesi)
            y_pred = xgb.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin ortalama kare hatasÄ± (MSE):", mse)

            mae = mean_absolute_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin ortalama mutlak hatasÄ± (MAE):", mae)

            rmse = mean_squared_error(y_test, y_pred, squared=False)
            st.write("Hiperparametre optimizasyonu Ã¶ncesi modelin kÃ¶k ortalama kare hatasÄ± (RMSE):", rmse)

            # Hiperparametre aralÄ±klarÄ±
            params = {
                'n_estimators': [100, 500, 1000],
                'learning_rate': [0.01, 0.05, 0.1],
                'max_depth': [3, 5, 7]
            }

            # Hiperparametre optimizasyonu
            grid_search = GridSearchCV(xgb, params, cv=5, n_jobs=-1, verbose=2)
            grid_search.fit(X_train, y_train)
            best_params = grid_search.best_params_

            st.write("En iyi parametreler:", best_params)

            # En iyi parametrelerle modeli tekrar eÄŸitme
            xgb_model = XGBRegressor(**best_params)
            xgb_model.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre optimizasyonu sonrasÄ±)
            y_pred = xgb_model.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin ortalama kare hatasÄ± (MSE):", mse)

            mae = mean_absolute_error(y_test, y_pred)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin ortalama mutlak hatasÄ± (MAE):", mae)

            rmse = mean_squared_error(y_test, y_pred, squared=False)
            st.write("Hiperparametre optimizasyonu sonrasÄ± modelin kÃ¶k ortalama kare hatasÄ± (RMSE):", rmse)


    
    
    
elif page == "Yapay Sinir AÄŸlarÄ±":
    import streamlit as st
    import pandas as pd
    from sklearn.model_selection import train_test_split, GridSearchCV
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve
    import matplotlib.pyplot as plt
    from sklearn.preprocessing import StandardScaler
    from sklearn.neural_network import MLPClassifier, MLPRegressor
    from sklearn.metrics import mean_squared_error, mean_absolute_error

    st.title("Yapay Sinir AÄŸlarÄ± ğŸ§ ğŸ•¸ï¸")

    # Ä°zin verilen dosya formatlarÄ±
    allowed_formats = ["csv", "txt", "xls", "xlsx"]

    # KullanÄ±cÄ±dan veri yÃ¼kleme
    upload = st.file_uploader("Veri setinizi CSV, TXT veya Excel formatÄ±nda yÃ¼kleyiniz.", type=allowed_formats)

    # Veri yÃ¼klendi mi kontrolÃ¼ ve iÅŸlemler
    if upload is not None:
        if "csv" in upload.name.lower():
            df = pd.read_csv(upload)
        elif "txt" in upload.name.lower():
            df = pd.read_csv(upload, delimiter='\t')
        elif "xls" in upload.name.lower() or "xlsx" in upload.name.lower():
            df = pd.read_excel(upload)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri seÃ§me
        st.subheader("BaÄŸÄ±msÄ±z ve BaÄŸÄ±mlÄ± DeÄŸiÅŸkenleri SeÃ§me")
        X_options = df.select_dtypes(include=['number', 'float', 'int']).columns.tolist()  # SayÄ±sal deÄŸiÅŸkenleri seÃ§
        y_options = df.select_dtypes(include=['object', 'number', 'float', 'int']).columns.tolist()  # Kategorik deÄŸiÅŸkenleri seÃ§
        X_selected = st.multiselect("BaÄŸÄ±msÄ±z DeÄŸiÅŸkenleri SeÃ§in", X_options)
        y_selected = st.selectbox("BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni SeÃ§in", y_options)

        # BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±rma
        X = df[X_selected]
        y = df[y_selected]

        # Verilerin Ã¶lÃ§eklendirilmesi
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # Test verisi yÃ¼zdesi ve random state deÄŸeri giriÅŸi
        test_size = st.slider("Test verisi yÃ¼zdesi:", 0.1, 0.5, 0.2, 0.01)
        random_state = st.number_input("Random state deÄŸeri:", 0, 1000, 42, 1)
        st.write("----")

        # SÄ±nÄ±flandÄ±rma veya regresyon seÃ§imi
        problem_type = st.radio("Problemi SeÃ§in:", ("SÄ±nÄ±flandÄ±rma", "Regresyon"))

        # SÄ±nÄ±flandÄ±rma iÅŸlemleri
        if problem_type == "SÄ±nÄ±flandÄ±rma":
            # Veri kÃ¼mesini eÄŸitim ve test kÃ¼melerine ayÄ±rma
            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, random_state=random_state)

            # Yapay Sinir AÄŸÄ± sÄ±nÄ±flandÄ±rma modeli oluÅŸturma
            ann = MLPClassifier(random_state=random_state)
            ann.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre Ã¶ncesi)
            y_pred = ann.predict(X_test)
            accuracy_pre = accuracy_score(y_test, y_pred)
            precision_pre = precision_score(y_test, y_pred)
            recall_pre = recall_score(y_test, y_pred)
            f1_pre = f1_score(y_test, y_pred)
            roc_auc_pre = roc_auc_score(y_test, y_pred)

            # Hiperparametre aralÄ±klarÄ±
            params = {
                'hidden_layer_sizes': [(100,), (50, 100), (50, 50, 50)],
                'activation': ['identity', 'logistic', 'tanh', 'relu'],
                'solver': ['lbfgs', 'sgd', 'adam']
            }

            # Hiperparametre optimizasyonu
            grid_search = GridSearchCV(ann, params, cv=5, n_jobs=-1, verbose=2)
            grid_search.fit(X_train, y_train)
            best_params = grid_search.best_params_

            st.write("En iyi parametreler:", best_params)

            # En iyi parametrelerle modeli tekrar eÄŸitme
            ann_model = MLPClassifier(**best_params, random_state=random_state)
            ann_model.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre sonrasÄ±)
            y_pred = ann_model.predict(X_test)
            accuracy_post = accuracy_score(y_test, y_pred)
            precision_post = precision_score(y_test, y_pred)
            recall_post = recall_score(y_test, y_pred)
            f1_post = f1_score(y_test, y_pred)
            roc_auc_post = roc_auc_score(y_test, y_pred)

            # SonuÃ§larÄ± gÃ¶sterme
            st.write("DoÄŸruluk (Accuracy) (Hiperparametre Ã¶ncesi):", accuracy_pre)
            st.write("Hassasiyet (Precision) (Hiperparametre Ã¶ncesi):", precision_pre)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall) (Hiperparametre Ã¶ncesi):", recall_pre)
            st.write("F1-Skor (Hiperparametre Ã¶ncesi):", f1_pre)
            st.write("ROC AUC Skoru (Hiperparametre Ã¶ncesi):", roc_auc_pre)

            st.write("----")

            st.write("DoÄŸruluk (Accuracy) (Hiperparametre sonrasÄ±):", accuracy_post)
            st.write("Hassasiyet (Precision) (Hiperparametre sonrasÄ±):", precision_post)
            st.write("Geri Ã‡aÄŸÄ±rma (Recall) (Hiperparametre sonrasÄ±):", recall_post)
            st.write("F1-Skor (Hiperparametre sonrasÄ±):", f1_post)
            st.write("ROC AUC Skoru (Hiperparametre sonrasÄ±):", roc_auc_post)

        # Regresyon iÅŸlemleri
        elif problem_type == "Regresyon":
            # Veri kÃ¼mesini eÄŸitim ve test kÃ¼melerine ayÄ±rma
            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, random_state=random_state)

            # Yapay Sinir AÄŸÄ± regresyon modeli oluÅŸturma
            ann = MLPRegressor(random_state=random_state)
            ann.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre Ã¶ncesi)
            y_pred = ann.predict(X_test)
            mse_pre = mean_squared_error(y_test, y_pred)
            mae_pre = mean_absolute_error(y_test, y_pred)
            rmse_pre = mean_squared_error(y_test, y_pred, squared=False)

            # Hiperparametre aralÄ±klarÄ±
            params = {
                'hidden_layer_sizes': [(100,), (50, 100), (50, 50, 50)],
                'activation': ['identity', 'logistic', 'tanh', 'relu'],
                'solver': ['lbfgs', 'sgd', 'adam']
            }

            # Hiperparametre optimizasyonu
            grid_search = GridSearchCV(ann, params, cv=5, n_jobs=-1, verbose=2)
            grid_search.fit(X_train, y_train)
            best_params = grid_search.best_params_

            st.write("En iyi parametreler:", best_params)

            # En iyi parametrelerle modeli tekrar eÄŸitme
            ann_model = MLPRegressor(**best_params, random_state=random_state)
            ann_model.fit(X_train, y_train)

            # Test verisi Ã¼zerinde modelin performansÄ±nÄ± deÄŸerlendirme (hiperparametre sonrasÄ±)
            y_pred = ann_model.predict(X_test)
            mse_post = mean_squared_error(y_test, y_pred)
            mae_post = mean_absolute_error(y_test, y_pred)
            rmse_post = mean_squared_error(y_test, y_pred, squared=False)

            # SonuÃ§larÄ± gÃ¶sterme
            st.write("Ortalama Kare Hata (MSE) (Hiperparametre Ã¶ncesi):", mse_pre)
            st.write("Ortalama Mutlak Hata (MAE) (Hiperparametre Ã¶ncesi):", mae_pre)
            st.write("KÃ¶k Ortalama Kare Hata (RMSE) (Hiperparametre Ã¶ncesi):", rmse_pre)

            st.write("----")

            st.write("Ortalama Kare Hata (MSE) (Hiperparametre sonrasÄ±):", mse_post)
            st.write("Ortalama Mutlak Hata (MAE) (Hiperparametre sonrasÄ±):", mae_post)
            st.write("KÃ¶k Ortalama Kare Hata (RMSE) (Hiperparametre sonrasÄ±):", rmse_post)



